[
  {
    "objectID": "finetuning.html",
    "href": "finetuning.html",
    "title": "Finetuning",
    "section": "",
    "text": "import os\nimport numpy as np\nimport sys\nimport torch\nfrom gcn_reid.newt import get_newt_dataset, get_cropping_image_dataset\nfrom wildlife_datasets import splits\nimport timm\nimport itertools\nfrom torch.optim import SGD\nfrom wildlife_tools.train import ArcFaceLoss, BasicTrainer\nfrom wildlife_tools.train import set_seed\nfrom torchvision import transforms as T\nfrom wildlife_tools.features import DeepFeatures\nfrom wildlife_tools.inference import TopkClassifier\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom transformers import AutoModel",
    "crumbs": [
      "Finetuning"
    ]
  },
  {
    "objectID": "finetuning.html#create-traintest-split",
    "href": "finetuning.html#create-traintest-split",
    "title": "Finetuning",
    "section": "Create Train/Test Split",
    "text": "Create Train/Test Split\n\ndef create_train_test_split(df, split_ratio=0.5):\n    disjoint_splitter = splits.DisjointSetSplit(split_ratio)\n    for idx_train, idx_test in disjoint_splitter.split(df):\n        df_train, df_test = df.loc[idx_train], df.loc[idx_test]\n        splits.analyze_split(df, idx_train, idx_test)\n    return df_train, df_test\n\ndf_train, df_test = create_train_test_split(dataset.df, split_ratio=0.5)\ndf_test, df_val = create_train_test_split(df_test, split_ratio=0.5)\n\nprint(f\"Train: {len(df_train)}, Test: {len(df_test)}, Validation: {len(df_val)}\")",
    "crumbs": [
      "Finetuning"
    ]
  },
  {
    "objectID": "finetuning.html#closed-set-split-for-database-and-query-sets",
    "href": "finetuning.html#closed-set-split-for-database-and-query-sets",
    "title": "Finetuning",
    "section": "Closed Set Split (for database and query sets)",
    "text": "Closed Set Split (for database and query sets)\n\ndef create_database_query_split(df, split_ratio=0.9):\n    splitter = splits.ClosedSetSplit(split_ratio)\n    for idx_database, idx_query in splitter.split(df):\n        df_database, df_query = df.loc[idx_database], df.loc[idx_query]\n        splits.analyze_split(df, idx_database, idx_query)\n    return df_database, df_query\n\ndf_test_database, df_test_query = create_database_query_split(df_test, split_ratio=0.9)\nprint(f\"Test Database: {len(df_test_database)}, Test Query: {len(df_test_query)}\\n\\n\\n\")\n\ndf_val_database, df_val_query = create_database_query_split(df_val, split_ratio=0.9)\nprint(f\"Validation Database: {len(df_val_database)}, Validation Query: {len(df_val_query)}\\n\\n\\n\")\n\ndf_train_database, df_train_query = create_database_query_split(df_train, split_ratio=0.9)\nprint(f\"Train Database: {len(df_train_database)}, Train Query: {len(df_train_query)}\\n\\n\\n\")",
    "crumbs": [
      "Finetuning"
    ]
  },
  {
    "objectID": "finetuning.html#megadescriptor-on-test-set",
    "href": "finetuning.html#megadescriptor-on-test-set",
    "title": "Finetuning",
    "section": "MegaDescriptor on Test Set",
    "text": "MegaDescriptor on Test Set\n\nmega_descriptor_results = evaluate(model=backbone, \n         df_query=df_test_query, \n         df_database=df_test_database, \n         data_root=dataset_path, \n         transform=val_transform, \n         crop_out=True, \n         batch_size=32, \n         num_workers=4, \n         device=device)\n\nprint(\"MegaDescriptor Results:\", mega_descriptor_results)",
    "crumbs": [
      "Finetuning"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "gcn-reid",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "gcn-reid"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "gcn-reid",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall gcn_reid in Development mode\n# make sure gcn_reid package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to gcn_reid\n$ nbdev_prepare",
    "crumbs": [
      "gcn-reid"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "gcn-reid",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/mshahoyi/gcn-reid.git\nor from conda\n$ conda install -c mshahoyi gcn_reid\nor from pypi\n$ pip install gcn_reid\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "gcn-reid"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "gcn-reid",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "gcn-reid"
    ]
  },
  {
    "objectID": "splits.html",
    "href": "splits.html",
    "title": "Splits",
    "section": "",
    "text": "import os\nimport sys\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom wildlife_datasets import analysis, datasets, splits\nimport pycocotools.mask as mask_util\nfrom wildlife_tools.data import ImageDataset\nfrom sklearn.metrics import average_precision_score\nimport numpy as np\nimport timm\nfrom transformers import AutoModel\nimport torch\nimport numpy as np\nfrom wildlife_tools.inference import TopkClassifier, KnnClassifier\nfrom wildlife_tools.features import DeepFeatures\nimport torchvision.transforms as T\nfrom PIL import Image\nimport kaggle\nimport pandas as pd\nfrom wildlife_tools.data import ImageDataset\nfrom gcn_reid.segmentation import decode_rle_mask\nfrom gcn_reid.newt_dataset import upload_to_kaggle\nfrom pathlib import Path\nfrom gcn_reid.newt_dataset import download_kaggle_dataset\nfrom tqdm import tqdm\nfrom transformers import AutoImageProcessor, AutoModel\ndataset_name = 'mshahoyi/newts-segmented-new'\ndataset_path = Path('data/newts-segmented-new')\ndownload_kaggle_dataset(dataset_name, dataset_path)",
    "crumbs": [
      "Splits"
    ]
  },
  {
    "objectID": "splits.html#download-and-ready-both-models",
    "href": "splits.html#download-and-ready-both-models",
    "title": "Splits",
    "section": "Download and ready both models",
    "text": "Download and ready both models\n\ndevice = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\ndinov2_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\ndinov2_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)",
    "crumbs": [
      "Splits"
    ]
  },
  {
    "objectID": "splits.html#run-both-models-on-all-images-and-save-the-results",
    "href": "splits.html#run-both-models-on-all-images-and-save-the-results",
    "title": "Splits",
    "section": "Run both models on all images and save the results",
    "text": "Run both models on all images and save the results\nArtifacts are a dataframe like the newt dataframe but that contains two new columns representing the mega and miewid embeddings.\n\ndf_original = pd.read_csv(dataset_path / 'metadata.csv')\ndf = df_original.copy()\ndf = df[~df.is_video].reset_index(drop=True)\ndf\n\n\nartifacts_path = Path('artifacts')\nartifacts_path.mkdir(exist_ok=True)\nartifacts_name = 'metadata_with_features.csv'\n\n\nif not (artifacts_path/artifacts_name).exists():\n    batch_size = 64\n    batches = [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n    for i, batch in tqdm(enumerate(batches), total=len(batches)):\n        images = [Image.open(dataset_path / row['file_path']) for _, row in batch.iterrows()]\n        inputs = dinov2_processor(images=images, return_tensors=\"pt\").to(device)\n        with torch.no_grad():\n            outputs = dinov2_model(**inputs)\n            last_hidden_states = outputs.last_hidden_state[:, 0, :] # select the CLS token embedding\n        features = pd.Series(last_hidden_states.cpu().tolist(), index=batch.index)\n        df.loc[batch.index, 'dinov2_features'] = features\n    df.to_csv(artifacts_path/artifacts_name, index=False)\nelse: \n    df = pd.read_csv(artifacts_path/artifacts_name)\n    df['dinov2_features'] = df['dinov2_features'].apply(eval)",
    "crumbs": [
      "Splits"
    ]
  },
  {
    "objectID": "splits.html#get-all-cosine-similarities-and-save-the-highest-correct-match-and-the-highest-incorrect-match-scores-and-indices",
    "href": "splits.html#get-all-cosine-similarities-and-save-the-highest-correct-match-and-the-highest-incorrect-match-scores-and-indices",
    "title": "Splits",
    "section": "Get all cosine similarities and save the highest correct match and the highest incorrect match scores and indices",
    "text": "Get all cosine similarities and save the highest correct match and the highest incorrect match scores and indices\nWe will have 8 new columns: mega_highest_correct_score, mega_highest_correct_idx, mega_highest_incorrect_score, mega_highest_incorrect_idx, miewid_highest_correct_score, miewid_highest_correct_idx, miewid_highest_incorrect_score, miewid_highest_incorrect_idx Convert string representation of features back to arrays\n\ndinov2_features = np.array(df['dinov2_features'].tolist())\n\n# Calculate cosine similarities manually\ndef cosine_similarity(a, b):\n    # Normalize the vectors\n    a_norm = a / np.linalg.norm(a, axis=1)[:, np.newaxis]\n    b_norm = b / np.linalg.norm(b, axis=1)[:, np.newaxis]\n    # Calculate similarity matrix\n    return np.dot(a_norm, b_norm.T)\n\ndinov2_similarities = cosine_similarity(dinov2_features, dinov2_features)\n\ndinov2_similarities.shape\n\n\ndef get_highest_correct_and_incorrect_matches(df, similarities, i, row):\n    other_indices = np.arange(len(df))\n\n    # Get current newt ID\n    current_newt_id = row['identity']\n    \n    # Get similarities for this image\n    sims = similarities[i]\n\n    # Get masks for correct and incorrect matches\n    correct_mask = df['identity'] == current_newt_id\n    incorrect_mask = df['identity'] != current_newt_id\n\n    # Remove self from correct matches\n    correct_mask[i] = False\n\n    # Get highest correct and incorrect similarities\n    correct_sims = sims[correct_mask]\n    incorrect_sims = sims[incorrect_mask]\n\n    if correct_sims.size &gt; 0:\n        highest_correct_idx = other_indices[correct_mask][np.argmax(correct_sims)]\n        highest_correct_score = np.max(correct_sims)\n    else:\n        highest_correct_idx = np.nan\n        highest_correct_score = np.nan\n\n    highest_incorrect_idx = other_indices[incorrect_mask][np.argmax(incorrect_sims)]\n    highest_incorrect_score = np.max(incorrect_sims)\n\n    return highest_correct_idx, highest_correct_score, highest_incorrect_idx, highest_incorrect_score\n\n\n# Test the get_highest_correct_and_incorrect_matches function\ndef test_get_highest_correct_and_incorrect_matches():\n    # Create a small test dataset\n    test_df = pd.DataFrame({\n        'identity': ['A', 'A', 'A', 'B', 'B', 'C'],\n    })\n    \n    # Create a test similarity matrix\n    # Each row represents similarities to all other images\n    test_similarities = np.array([\n        [1.0, 0.8, 0.7, 0.9, 0.3, 0.2],  # Image 0 similarities\n        [0.8, 1.0, 0.9, 0.4, 0.5, 0.3],  # Image 1 similarities \n        [0.7, 0.9, 1.0, 0.3, 0.4, 0.6],  # Image 2 similarities\n        [0.9, 0.4, 0.3, 1.0, 0.8, 0.4],  # Image 3 similarities\n        [0.3, 0.5, 0.4, 0.8, 1.0, 0.5],  # Image 4 similarities\n        [0.2, 0.3, 0.6, 0.4, 0.5, 1.0],  # Image 5 similarities\n    ])\n    \n    # Test cases\n    test_cases = [\n        {\n            'idx': 0,  # Testing first image (identity A)\n            'expected': {\n                'correct_idx': 1,  # Should match with image 1 (identity A)\n                'correct_score': 0.8,\n                'incorrect_idx': 3,  # Should match with image 3 (identity B) \n                'incorrect_score': 0.9\n            }\n        },\n        {\n            'idx': 3,  # Testing fourth image (identity B)\n            'expected': {\n                'correct_idx': 4,  # Should match with image 4 (identity B)\n                'correct_score': 0.8,\n                'incorrect_idx': 0,  # Should match with image 0 (identity A)\n                'incorrect_score': 0.9\n            }\n        }\n    ]\n    \n    for test in test_cases:\n        idx = test['idx']\n        expected = test['expected']\n        \n        correct_idx, correct_score, incorrect_idx, incorrect_score = get_highest_correct_and_incorrect_matches(\n            test_df, test_similarities, idx, test_df.iloc[idx]\n        )\n        \n        # Assert the results match expected values\n        assert correct_idx == expected['correct_idx'], f\"Test failed for idx {idx}: Expected correct_idx {expected['correct_idx']}, got {correct_idx}\"\n        assert np.isclose(correct_score, expected['correct_score']), f\"Test failed for idx {idx}: Expected correct_score {expected['correct_score']}, got {correct_score}\"\n        assert incorrect_idx == expected['incorrect_idx'], f\"Test failed for idx {idx}: Expected incorrect_idx {expected['incorrect_idx']}, got {incorrect_idx}\"\n        assert np.isclose(incorrect_score, expected['incorrect_score']), f\"Test failed for idx {idx}: Expected incorrect_score {expected['incorrect_score']}, got {incorrect_score}\"\n    \n    print(\"All tests passed!\")\n\n# Run the tests\ntest_get_highest_correct_and_incorrect_matches()\n\n\nfor i, (k, row) in tqdm(enumerate(df.iterrows()), total=len(df)):\n    # Get current newt ID\n    dinov2_highest_correct_idx, dinov2_highest_correct_score, dinov2_highest_incorrect_idx, dinov2_highest_incorrect_score = get_highest_correct_and_incorrect_matches(df, dinov2_similarities, i, row)\n    \n    df.at[k, 'highest_correct_score'] = dinov2_highest_correct_score\n    df.at[k, 'highest_correct_idx'] = dinov2_highest_correct_idx\n    df.at[k, 'highest_incorrect_score'] = dinov2_highest_incorrect_score\n    df.at[k, 'highest_incorrect_idx'] = dinov2_highest_incorrect_idx",
    "crumbs": [
      "Splits"
    ]
  },
  {
    "objectID": "splits.html#calculate-the-rightness-score-for-each-image-and-model.",
    "href": "splits.html#calculate-the-rightness-score-for-each-image-and-model.",
    "title": "Splits",
    "section": "Calculate the rightness score for each image and model.",
    "text": "Calculate the rightness score for each image and model.\n\ndf['rightness_score'] = df['highest_correct_score'] - df['highest_incorrect_score']\n\n\ndf.highest_correct_score.hist(bins=50)\n\n\n# Plot the 5 least correct images with their matches\nnum_images = 1\n\nsorted_df = df.sort_values(by=['rightness_score'], ascending=True).reset_index(drop=True)\nfor i, row in tqdm(sorted_df[:num_images].iterrows(), total=num_images):\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n    # Plot query image\n    query_path = dataset_path / row['file_path']\n    print(query_path)\n    axes[0].imshow(plt.imread(query_path))\n    axes[0].set_title(f'Query\\nID: {row[\"identity\"]} - {row.file_name}\\n{row.creation_date}')\n    axes[0].axis('off')\n\n    # Define matches to plot\n    matches = [\n        {'type': 'DINOv2 Correct', 'score_col': 'highest_correct_score', 'idx_col': 'highest_correct_idx', 'ax_idx': 1},\n        {'type': 'DINOv2 Incorrect', 'score_col': 'highest_incorrect_score', 'idx_col': 'highest_incorrect_idx', 'ax_idx': 2},\n    ]\n\n    # Plot each match\n    for match in matches:\n        match_row = df.iloc[int(row[match['idx_col']])]\n        match_path = dataset_path / match_row['file_path']\n        ax = axes[match['ax_idx']]\n        ax.imshow(plt.imread(match_path))\n        ax.set_title(f'{match[\"type\"]}\\nScore: {row[match[\"score_col\"]]:.3f}\\n{match_row.identity}/{match_row.file_name}\\n{row.creation_date}', fontsize=10)\n        ax.axis('off')\n\n    fig.tight_layout()\n    fig.savefig(artifacts_path/f'least_correct_matches_rightness_score_{i}.png')\n    plt.close(fig)",
    "crumbs": [
      "Splits"
    ]
  },
  {
    "objectID": "splits.html#sort-images-by-rightness-score-in-an-ascending-order",
    "href": "splits.html#sort-images-by-rightness-score-in-an-ascending-order",
    "title": "Splits",
    "section": "Sort images by rightness score in an ascending order",
    "text": "Sort images by rightness score in an ascending order",
    "crumbs": [
      "Splits"
    ]
  },
  {
    "objectID": "splits.html#mark-query-and-database-images",
    "href": "splits.html#mark-query-and-database-images",
    "title": "Splits",
    "section": "Mark query and database images",
    "text": "Mark query and database images\nStarting with the least right images, mark the query and database images. Skip images that are already marked (this means they are the database for another image).\n\nn_ind_test = 30\nn_ind_val = 30\n\ndf_original['is_hard_test_query'] = pd.NA\ndf_original['is_hard_val_query'] = pd.NA\n\nsorted_df = df.loc[df.groupby('identity')['rightness_score'].idxmin()].sort_values(by=['rightness_score'], ascending=True).head(n_ind_test + n_ind_val)\nsorted_df.identity.nunique()\n\n\nfor count, (i, row) in enumerate(sorted_df.iterrows()):\n    col = 'is_hard_test_query' if count &lt; n_ind_test else 'is_hard_val_query'\n\n    # Make other images of the same newt a database\n    df_original.loc[df_original['identity'] == row['identity'], col] = False\n\n    # Make the newt itself a query\n    df_original.loc[(df_original['identity'] == row['identity']) & (df_original.file_name == row['file_name']), col] = True\n\n\ndf_original.is_hard_test_query.value_counts()\n\n\ndf_original.is_hard_val_query.value_counts()",
    "crumbs": [
      "Splits"
    ]
  },
  {
    "objectID": "bsl_exp.html",
    "href": "bsl_exp.html",
    "title": "BSL Experiment",
    "section": "",
    "text": "import os\nimport sys\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport timm\nfrom pathlib import Path\nimport kaggle\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nfrom wildlife_datasets import loader, datasets, splits\nfrom wildlife_tools.data import ImageDataset\nfrom wildlife_tools.features import DeepFeatures\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom wildlife_tools.inference import KnnClassifier\nfrom wildlife_tools.train import ArcFaceLoss, set_seed\nfrom tqdm import tqdm\nimport random\nfrom gcn_reid.segmentation import decode_rle_mask, visualize_segmentation, visualize_segmentation_from_metadata\nfrom gcn_reid.attribution import my_occlusion_sensitivity\nimport itertools\n\nprint(\"All imports successful!\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\n\n\n# Download and verify dataset\ndef download_newt_dataset():\n    dataset_name = \"mshahoyi/barhill-newts-segmented\"\n    download_path = \"data/newt_dataset\"\n    \n    if not os.path.exists(download_path):\n        os.makedirs(download_path, exist_ok=True)\n        kaggle.api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n        print(f\"Dataset downloaded to {download_path}\")\n    else:\n        print(f\"Dataset already exists at {download_path}\")\n    \n    return download_path\n\ndataset_path = download_newt_dataset()\n\n# Verify dataset structure\nprint(f\"\\nDataset path: {dataset_path}\")\nprint(\"Dataset contents:\")\nfor item in os.listdir(dataset_path):\n    print(f\"  {item}\")\n\n\n# Load and examine metadata\nmetadata_path = os.path.join(dataset_path, \"metadata.csv\")\ndf = pd.read_csv(metadata_path)\n\nprint(f\"Dataset contains {len(df)} images\")\nprint(f\"Number of unique newts: {df['newt_id'].nunique()}\")\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\nprint(\"\\nFirst few rows:\")\nprint(df.head())\n\nprint(\"\\nNewt ID distribution:\")\nprint(df['newt_id'].value_counts().head(10))\n\n# Test RLE decoding with a sample\nsample_row = df.iloc[0]\nprint(f\"Testing RLE decoding with sample:\")\nprint(f\"Image path: {sample_row['image_path']}\")\nprint(f\"Newt ID: {sample_row['newt_id']}\")\n\n# Load sample image to get dimensions\nsample_img_path = Path(dataset_path) / sample_row['image_path']\nsample_img = Image.open(sample_img_path)\nprint(f\"Image size: {sample_img.size}\")\n\n# Decode mask\nh, w = sample_img.size[1], sample_img.size[0]\nmask = decode_rle_mask(sample_row['segmentation_mask_rle'])\nprint(f\"Mask shape: {mask.shape}\")\nprint(f\"Mask unique values: {np.unique(mask)}\")\nprint(f\"Mask coverage: {mask.sum() / mask.size:.2%}\")\n\n# Visualize sample\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\naxes[0].imshow(sample_img)\naxes[0].set_title('Original Image')\naxes[0].axis('off')\n\naxes[1].imshow(mask, cmap='gray')\naxes[1].set_title('Segmentation Mask')\naxes[1].axis('off')\n\naxes[2].imshow(sample_img)\naxes[2].imshow(mask, alpha=0.5, cmap='Reds')\naxes[2].set_title('Image + Mask Overlay')\naxes[2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n# Create and test dataset splits\ndef create_newt_splits(df, train_ratio=0.8, random_state=42):\n    \"\"\"Create disjoint splits ensuring each newt appears in only one split\"\"\"\n    unique_newts = df['newt_id'].unique()\n    \n    train_newts, test_newts = train_test_split(\n        unique_newts, \n        train_size=train_ratio, \n        random_state=random_state,\n        stratify=None\n    )\n    \n    df_train = df[df['newt_id'].isin(train_newts)].copy()\n    df_test = df[df['newt_id'].isin(test_newts)].copy()\n    \n    print(f\"Train split: {len(df_train)} images from {len(train_newts)} newts\")\n    print(f\"Test split: {len(df_test)} images from {len(test_newts)} newts\")\n    \n    return df_train, df_test\n\ndf_train, df_test = create_newt_splits(df)\n\n# Verify no overlap between train and test\ntrain_newts = set(df_train['newt_id'].unique())\ntest_newts = set(df_test['newt_id'].unique())\noverlap = train_newts.intersection(test_newts)\nprint(f\"Overlap between train and test newts: {len(overlap)} (should be 0)\")\n\nprint(\"\\nTrain newt distribution (top 10):\")\nprint(df_train['newt_id'].value_counts().head(10))\n\nprint(\"\\nTest newt distribution (top 10):\")\nprint(df_test['newt_id'].value_counts().head(10))\n\n\n# Create and test custom dataset class\nclass NewtDataset(Dataset):\n    def __init__(self, dataframe, root_path, transform=None, return_mask=True):\n        self.df = dataframe.reset_index(drop=True)\n        self.root_path = Path(root_path)\n        self.transform = transform\n        self.return_mask = return_mask\n        self.labels_string = self.df['newt_id'].astype(str).tolist()\n        \n        # Create label mapping\n        unique_labels = sorted(self.df['newt_id'].unique())\n        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n        self.labels = [self.label_to_idx[label] for label in self.df['newt_id']]\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Load image\n        img_path = self.root_path / row['image_path']\n        image = Image.open(img_path).convert('RGB')\n        \n        # Get label\n        label = self.labels[idx]\n        \n        # Decode segmentation mask\n        mask = None\n        if self.return_mask and 'segmentation_mask_rle' in row:\n            h, w = image.size[1], image.size[0]\n            try:\n                decoded_mask = decode_rle_mask(row['segmentation_mask_rle'])\n                if decoded_mask is not None:\n                    mask = Image.fromarray(decoded_mask * 255).convert('L')\n                else:\n                    # Create a default mask (all foreground) when RLE decoding fails\n                    mask = Image.fromarray(np.ones((h, w), dtype=np.uint8) * 255).convert('L')\n            except Exception as e:\n                # Create a default mask if there's any error in decoding\n                h, w = image.size[1], image.size[0]\n                mask = Image.fromarray(np.ones((h, w), dtype=np.uint8) * 255).convert('L')\n                print(f\"Warning: Error decoding mask for image {idx}: {e}, using default full mask\")\n        \n        # Apply transforms\n        if self.transform:\n            if mask is not None:\n                # Apply same transform to both image and mask\n                seed = np.random.randint(2147483647)\n                \n                random.seed(seed)\n                torch.manual_seed(seed)\n                image = self.transform(image)\n                \n                random.seed(seed)\n                torch.manual_seed(seed)\n                mask = T.ToTensor()(mask)\n                mask = T.Resize(image.shape[-2:])(mask)\n            else:\n                image = self.transform(image)\n        \n        if mask is not None:\n            return image, label, mask.squeeze(0)\n        else:\n            return image, label\n\n# Test dataset creation\ntransform_test = T.Compose([\n    T.Resize([224, 224]),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset_small = NewtDataset(df_train.head(10), dataset_path, transform=transform_test, return_mask=True)\n\nprint(f\"Test dataset size: {len(test_dataset_small)}\")\nprint(f\"Number of classes in test: {len(test_dataset_small.label_to_idx)}\")\nprint(f\"Label mapping: {test_dataset_small.label_to_idx}\")\n\n# Test loading a sample\nsample_data = test_dataset_small[0]\nprint(f\"Sample data shapes:\")\nprint(f\"  Image: {sample_data[0].shape}\")\nprint(f\"  Label: {sample_data[1]}\")\nprint(f\"  Mask: {sample_data[2].shape}\")\n\n\n# Create full datasets with sanity checks\ntransform_train = T.Compose([\n    T.Resize([224, 224]),\n    T.RandomHorizontalFlip(p=0.5),\n    T.RandomRotation(degrees=180),\n    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = NewtDataset(df_train, dataset_path, transform=transform_train, return_mask=True)\ntest_dataset = NewtDataset(df_test, dataset_path, transform=transform_test, return_mask=True)\n\nprint(f\"Training dataset: {len(train_dataset)} samples\")\nprint(f\"Test dataset: {len(test_dataset)} samples\")\nprint(f\"Number of classes: {len(train_dataset.label_to_idx)}\")\n\n# Verify datasets\ntrain_sample = train_dataset[0]\ntest_sample = test_dataset[0]\n\nprint(f\"\\nTrain sample shapes: image={train_sample[0].shape}, label={train_sample[1]}, mask={train_sample[2].shape}\")\nprint(f\"Test sample shapes: image={test_sample[0].shape}, label={test_sample[1]}, mask={test_sample[2].shape}\")\n\n# Check label consistency\nprint(f\"Train labels range: {min(train_dataset.labels)} to {max(train_dataset.labels)}\")\nprint(f\"Test labels range: {min(test_dataset.labels)} to {max(test_dataset.labels)}\")\n\n\n# Test model loading and feature extraction\ndef test_megadescriptor_loading():\n    print(\"Testing MegaDescriptor loading...\")\n    \n    # Test loading the model\n    model_name = 'hf-hub:BVRA/MegaDescriptor-T-224'\n    backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n    \n    # Test forward pass\n    with torch.no_grad():\n        dummy_input = torch.randn(2, 3, 224, 224)\n        features = backbone(dummy_input)\n        print(f\"Model loaded successfully!\")\n        print(f\"Input shape: {dummy_input.shape}\")\n        print(f\"Output features shape: {features.shape}\")\n        print(f\"Feature dimension: {features.shape[1]}\")\n    \n    return backbone, features.shape[1]\n\nbackbone, embedding_size = test_megadescriptor_loading()\nbackbone\n\n\n# Create and test ArcFace loss\ndef test_arcface_loss():\n    print(\"Testing ArcFace loss...\")\n    \n    num_classes = len(train_dataset.label_to_idx)\n    \n    # Create ArcFace loss\n    arcface_loss = ArcFaceLoss(\n        num_classes=num_classes,\n        embedding_size=embedding_size,\n        margin=0.5,\n        scale=64\n    )\n    \n    print(f\"ArcFace loss created for {num_classes} classes, embedding size {embedding_size}\")\n    \n    # Test forward pass\n    with torch.no_grad():\n        dummy_embeddings = torch.randn(4, embedding_size)\n        dummy_labels = torch.randint(0, num_classes, (4,))\n        \n        loss = arcface_loss(dummy_embeddings, dummy_labels)\n        print(f\"Test loss: {loss.item():.4f}\")\n        print(\"ArcFace loss working correctly!\")\n        \n    return arcface_loss\n\narcface_loss = test_arcface_loss()\n\n\n# Define Background Suppression ArcFace Loss\nclass BackgroundSuppressionArcFaceLoss(nn.Module):\n    \"\"\"\n    Custom loss that combines ArcFace loss with background suppression\n    Uses segmentation masks to focus learning on the newt regions\n    \"\"\"\n    \n    def __init__(self, num_classes, embedding_size, margin=0.5, scale=64, alpha=1.0, beta=0.5):\n        super().__init__()\n        self.arcface_loss = ArcFaceLoss(\n            num_classes=num_classes,\n            embedding_size=embedding_size,\n            margin=margin,\n            scale=scale\n        )\n        self.alpha = alpha  # Weight for ArcFace loss\n        self.beta = beta    # Weight for background suppression loss\n        \n    def forward(self, embeddings, labels, masks, patch_features=None):\n        \"\"\"\n        Args:\n            embeddings: Output embeddings from the backbone [B, embedding_size]\n            labels: Ground truth labels [B]\n            masks: Binary segmentation masks (1 for newt, 0 for background) [B, H, W]\n            patch_features: Intermediate feature maps for background suppression [B, C, Hf, Wf]\n        \"\"\"\n        # ArcFace loss on embeddings\n        arcface_loss = self.arcface_loss(embeddings, labels)\n        \n        # Background suppression loss\n        background_penalty = torch.tensor(0.0, device=embeddings.device)\n        \n        if patch_features is not None and masks is not None:\n            B, C, Hf, Wf = patch_features.shape\n\n            print(f\"Patch features shape: {patch_features.shape}\")\n            \n            # Resize masks to match feature map size\n            masks_resized = F.interpolate(\n                masks.unsqueeze(1).float(), \n                size=(Hf, Wf), \n                mode='nearest'\n            ).squeeze(1)\n            \n            # Background mask (1 for background, 0 for foreground)\n            background_mask = 1.0 - masks_resized\n            \n            # Compute L2 norm of patch features\n            patch_norm = patch_features.pow(2).sum(1).sqrt()  # [B, Hf, Wf]\n            \n            # Background suppression: penalize high activations in background regions\n            background_penalty = (patch_norm * background_mask).mean()\n        \n        total_loss = self.alpha * arcface_loss + self.beta * background_penalty\n        \n        return total_loss, arcface_loss, background_penalty\n\n# Test BSL Loss\ndef test_bsl_loss():\n    print(\"Testing Background Suppression ArcFace Loss...\")\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    num_classes = len(train_dataset.label_to_idx)\n    \n    bsl_loss = BackgroundSuppressionArcFaceLoss(\n        num_classes=num_classes,\n        embedding_size=embedding_size,\n        margin=0.5,\n        scale=64,\n        alpha=1.0,\n        beta=0.5\n    ).to(device)\n    \n    # Test with dummy data\n    with torch.no_grad():\n        # Get real data samples from training dataset\n        sample_batch = next(iter(DataLoader(train_dataset, batch_size=2, shuffle=True)))\n        images, labels, masks = sample_batch\n        images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n        \n        # Get embeddings and patch features from model\n        model.eval()\n        embeddings = model(images)\n        patch_features = model.patch_features\n        \n        total_loss, arcface_loss, bg_loss = bsl_loss(\n            embeddings, labels, masks, patch_features\n        )\n        \n        print(f\"Total loss: {total_loss.item():.4f}\")\n        print(f\"ArcFace loss: {arcface_loss.item():.4f}\")\n        print(f\"Background loss: {bg_loss.item():.4f}\")\n        \n    return bsl_loss\n\nbsl_loss = test_bsl_loss()\n\n\nmodel = timm.create_model('hf-hub:BVRA/MegaDescriptor-T-224', pretrained=True, num_classes=0)\nmodel\n\n\n# Create model with feature extraction hooks\nclass MegaDescriptorWithBSL(nn.Module):\n    def __init__(self, num_classes, model_name='hf-hub:BVRA/MegaDescriptor-T-224'):\n        super().__init__()\n        \n        # Load pretrained MegaDescriptor backbone\n        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n        \n        # Get feature dimension\n        with torch.no_grad():\n            dummy_input = torch.randn(1, 3, 224, 224)\n            features = self.backbone(dummy_input)\n            self.embedding_size = features.shape[1]\n        \n        # Store intermediate features for BSL\n        self.patch_features = None\n        \n        # Register hook to capture intermediate features\n        self._register_hooks()\n        \n    def _register_hooks(self):\n        \"\"\"Register hooks to capture intermediate feature maps\"\"\"\n        def hook_fn(module, input, output):\n            # Swin Transformer outputs features in [B, H, W, C] format\n            if len(output.shape) == 4:\n                B, H, W, C = output.shape\n                # Convert to [B, C, H, W] format for compatibility\n                self.patch_features = output.permute(0, 3, 1, 2)\n            elif len(output.shape) == 3:\n                # Some layers might output [B, N, C], try to reshape\n                B, N, C = output.shape\n                H = W = int(np.sqrt(N))\n                if H * W == N:\n                    self.patch_features = output.view(B, H, W, C).permute(0, 3, 1, 2)\n        \n        # Hook into one of the later Swin Transformer stages\n        # Stage 2 has 384 channels and good spatial resolution\n        # Stage 3 has 768 channels (final) but lower spatial resolution\n        \n        # Try to hook into stage 2 (layers.2) - 384 channels\n        if hasattr(self.backbone, 'layers') and len(self.backbone.layers) &gt; 2:\n            target_stage = self.backbone.layers[2]  # Stage 2\n            print(f\"Hooking to Swin stage 2 with {384} channels\")\n            target_stage.register_forward_hook(hook_fn)\n            return\n        \n        # Fallback: try to hook into any layer with 'layers' in the name\n        hooked = False\n        for name, module in self.backbone.named_modules():\n            if 'layers.2' in name and not hooked:  # Prefer stage 2\n                print(f\"Hooking to layer: {name}\")\n                module.register_forward_hook(hook_fn)\n                hooked = True\n                break\n            elif 'layers.1' in name and not hooked:  # Fallback to stage 1\n                print(f\"Hooking to layer: {name}\")\n                module.register_forward_hook(hook_fn)\n                hooked = True\n                break\n        \n        if not hooked:\n            print(\"Warning: Could not find suitable Swin Transformer layer to hook\")\n        \n    def forward(self, x):\n        # Reset patch features\n        self.patch_features = None\n        \n        # Forward through backbone\n        embeddings = self.backbone(x)\n        \n        return embeddings\n    \n    def get_patch_features(self):\n        \"\"\"Get the stored patch features for background suppression\"\"\"\n        return self.patch_features\n\n# Test model creation\ndef test_model_creation():\n    print(\"Testing model creation...\")\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    num_classes = len(train_dataset.label_to_idx)\n    \n    model = MegaDescriptorWithBSL(num_classes).to(device)\n    \n    print(f\"Model created with {model.embedding_size} embedding size\")\n    \n    # Test forward pass\n    with torch.no_grad():\n        dummy_input = torch.randn(2, 3, 224, 224).to(device)\n        embeddings = model(dummy_input)\n        patch_features = model.get_patch_features()\n        \n        print(f\"Input shape: {dummy_input.shape}\")\n        print(f\"Embeddings shape: {embeddings.shape}\")\n        \n        if patch_features is not None:\n            print(f\"Patch features shape: {patch_features.shape}\")\n        else:\n            print(\"Warning: No patch features captured\")\n    \n    return model\n\nmodel = test_model_creation()\n\n\n# Test data loading with actual data\ndef test_data_loading():\n    print(\"Testing data loading...\")\n    \n    # Create small data loaders for testing\n    small_train_dataset = NewtDataset(df_train.head(20), dataset_path, transform=transform_train, return_mask=True)\n    train_loader = DataLoader(small_train_dataset, batch_size=4, shuffle=True, num_workers=0)\n    \n    # Test loading one batch\n    for batch_idx, batch in enumerate(train_loader):\n        if len(batch) == 3:\n            images, labels, masks = batch\n            print(f\"Batch {batch_idx}:\")\n            print(f\"  Images shape: {images.shape}\")\n            print(f\"  Labels: {labels}\")\n            print(f\"  Masks shape: {masks.shape}\")\n            print(f\"  Mask value ranges: {masks.min().item():.3f} to {masks.max().item():.3f}\")\n            \n            # Visualize one sample from batch\n            img = images[0]\n            mask = masks[0]\n            \n            # Denormalize image for visualization\n            img_denorm = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n            img_denorm = torch.clamp(img_denorm, 0, 1)\n            \n            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n            axes[0].imshow(img_denorm.permute(1, 2, 0))\n            axes[0].set_title(f'Image (Label: {labels[0].item()})')\n            axes[0].axis('off')\n            \n            axes[1].imshow(mask, cmap='gray')\n            axes[1].set_title('Mask')\n            axes[1].axis('off')\n            \n            plt.tight_layout()\n            plt.show()\n            \n            break\n    \n    return train_loader\n\ntest_loader = test_data_loading()\n\n\n# Test full training setup\ndef test_training_setup():\n    print(\"Testing full training setup...\")\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Model\n    num_classes = len(train_dataset.label_to_idx)\n    model = MegaDescriptorWithBSL(num_classes).to(device)\n    \n    # Loss function\n    bsl_loss = BackgroundSuppressionArcFaceLoss(\n        num_classes=num_classes,\n        embedding_size=model.embedding_size,\n        margin=0.5,\n        scale=64,\n        alpha=1.0,\n        beta=0.5\n    ).to(device)\n    \n    # Optimizer\n    params = itertools.chain(model.parameters(), bsl_loss.parameters())\n    optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=1e-4)\n    \n    # Test one training step\n    model.train()\n    bsl_loss.train()\n    \n    # Get a small batch\n    small_dataset = NewtDataset(df_train.head(8), dataset_path, transform=transform_train, return_mask=True)\n    loader = DataLoader(small_dataset, batch_size=4, shuffle=True, num_workers=0)\n    \n    for batch in loader:\n        images, labels, masks = batch\n        images = images.to(device)\n        labels = labels.to(device)\n        masks = masks.to(device)\n        \n        print(f\"Batch shapes - Images: {images.shape}, Labels: {labels.shape}, Masks: {masks.shape}\")\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        embeddings = model(images)\n        patch_features = model.get_patch_features()\n        \n        print(f\"Embeddings shape: {embeddings.shape}\")\n        if patch_features is not None:\n            print(f\"Patch features shape: {patch_features.shape}\")\n        \n        # Compute loss\n        loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n        \n        print(f\"Losses - Total: {loss.item():.4f}, ArcFace: {arcface_loss.item():.4f}, BG: {bg_loss.item():.4f}\")\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        print(\"Training step completed successfully!\")\n        break\n    \n    return model, bsl_loss, optimizer\n\nmodel, bsl_loss, optimizer = test_training_setup()\n\n\n# Now we can proceed with the actual training\nprint(\"Setup complete! Ready for full training...\")\nprint(f\"Total training samples: {len(train_dataset)}\")\nprint(f\"Total test samples: {len(test_dataset)}\")\nprint(f\"Number of classes: {len(train_dataset.label_to_idx)}\")\nprint(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n\n\n# Test and define training epoch function with sanity checks\ndef train_epoch(model, train_loader, bsl_loss, optimizer, device, epoch):\n    model.train()\n    bsl_loss.train()\n    \n    total_loss = 0\n    total_arcface_loss = 0\n    total_bg_loss = 0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n    \n    for batch_idx, batch in enumerate(pbar):\n        if len(batch) == 3:  # With masks\n            images, labels, masks = batch\n            masks = masks.to(device)\n        else:  # Without masks\n            images, labels = batch\n            masks = torch.ones(images.shape[0], images.shape[2], images.shape[3]).to(device)\n        \n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        embeddings = model(images)\n        patch_features = model.get_patch_features()\n        \n        # Compute BSL loss with ArcFace\n        loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        # Statistics\n        total_loss += loss.item()\n        total_arcface_loss += arcface_loss.item()\n        total_bg_loss += bg_loss.item()\n        \n        # For accuracy calculation, get predictions from ArcFace weights\n        with torch.no_grad():\n            # Access the classifier weights from the pytorch_metric_learning ArcFace loss\n            W = bsl_loss.arcface_loss.loss.W  # The classifier weights\n            # Normalize embeddings and weights for cosine similarity\n            embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n            W_norm = F.normalize(W, p=2, dim=0)\n            # Compute logits as cosine similarity * scale\n            logits = F.linear(embeddings_norm, W_norm.T) * bsl_loss.arcface_loss.loss.scale\n            \n            _, predicted = logits.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n        \n        # Update progress bar\n        pbar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Arc': f'{arcface_loss.item():.4f}',\n            'BG': f'{bg_loss.item():.4f}',\n            'Acc': f'{100.*correct/total:.2f}%'\n        })\n    \n    avg_loss = total_loss / len(train_loader)\n    avg_arcface_loss = total_arcface_loss / len(train_loader)\n    avg_bg_loss = total_bg_loss / len(train_loader)\n    accuracy = 100. * correct / total\n    \n    return avg_loss, avg_arcface_loss, avg_bg_loss, accuracy\n\n# Test the training epoch function with a tiny dataset\nprint(\"Testing training epoch function...\")\n\n# Create a tiny test dataset\ntiny_dataset = NewtDataset(df_train.head(16), dataset_path, transform=transform_train, return_mask=True)\ntiny_loader = DataLoader(tiny_dataset, batch_size=4, shuffle=True, num_workers=0)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Test training epoch\ntest_loss, test_arcface, test_bg, test_acc = train_epoch(\n    model, tiny_loader, bsl_loss, optimizer, device, epoch=0\n)\n\nprint(f\"✅ Training epoch test passed!\")\nprint(f\"   Loss: {test_loss:.4f} (ArcFace: {test_arcface:.4f}, BG: {test_bg:.4f})\")\nprint(f\"   Accuracy: {test_acc:.2f}%\")\n\n\n# Test and define evaluation function\ndef evaluate(model, test_loader, bsl_loss, device):\n    model.eval()\n    bsl_loss.eval()\n    \n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc='Evaluating'):\n            if len(batch) == 3:  # With masks\n                images, labels, _ = batch\n            else:  # Without masks\n                images, labels = batch\n            \n            images, labels = images.to(device), labels.to(device)\n            \n            # Get embeddings\n            embeddings = model(images)\n            \n            # Get predictions from ArcFace weights\n            W = bsl_loss.arcface_loss.loss.W  # The classifier weights\n            # Normalize embeddings and weights for cosine similarity\n            embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n            W_norm = F.normalize(W, p=2, dim=0)\n            # Compute logits as cosine similarity * scale\n            logits = F.linear(embeddings_norm, W_norm.T) * bsl_loss.arcface_loss.loss.scale\n            \n            _, predicted = logits.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    accuracy = 100. * correct / total\n    return accuracy\n\n# Test evaluation function\nprint(\"Testing evaluation function...\")\n\ntiny_test_dataset = NewtDataset(df_test.head(16), dataset_path, transform=transform_test, return_mask=True)\ntiny_test_loader = DataLoader(tiny_test_dataset, batch_size=4, shuffle=False, num_workers=0)\n\neval_acc = evaluate(model, tiny_test_loader, bsl_loss, device)\nprint(f\"✅ Evaluation test passed!\")\nprint(f\"   Test accuracy: {eval_acc:.2f}%\")\n\n\n# Test occlusion sensitivity function with detailed checks\ndef run_occlusion_sensitivity_test(model, bsl_loss, dataset, device, epoch, save_dir):\n    \"\"\"Run occlusion sensitivity on pairs of different newts to test similarity\"\"\"\n    print(f\"Starting occlusion sensitivity test for epoch {epoch}\")\n    \n    model.eval()\n    bsl_loss.eval()\n    \n    # Create save directory\n    epoch_dir = Path(save_dir) / f\"epoch_{epoch:03d}\"\n    epoch_dir.mkdir(parents=True, exist_ok=True)\n    print(f\"Created directory: {epoch_dir}\")\n    \n    # Find pairs of different newts\n    newt_indices_by_id = {}\n    for idx in range(len(dataset)):\n        newt_id = dataset.labels_string[idx]\n        if newt_id not in newt_indices_by_id:\n            newt_indices_by_id[newt_id] = []\n        newt_indices_by_id[newt_id].append(idx)\n    \n    # Select 2 pairs of different newts\n    newt_ids = list(newt_indices_by_id.keys())\n    if len(newt_ids) &lt; 2:\n        print(\"Not enough different newts for similarity testing\")\n        return\n    \n    # Create similarity model function\n    def similarity_model(image1, image2):\n        \"\"\"\n        Compute cosine similarity between two images using the trained model\n        \n        Args:\n            image1: First image tensor [1, C, H, W]\n            image2: Second image tensor [1, C, H, W] \n            \n        Returns:\n            Cosine similarity score as tensor\n        \"\"\"\n        with torch.no_grad():\n            # Get embeddings for both images\n            emb1 = model(image1)\n            emb2 = model(image2)\n            \n            # Compute cosine similarity\n            emb1_norm = F.normalize(emb1, p=2, dim=1)\n            emb2_norm = F.normalize(emb2, p=2, dim=1)\n            similarity = F.cosine_similarity(emb1_norm, emb2_norm, dim=1)\n            \n            return similarity\n    \n    # Test 2 pairs\n    for pair_idx in range(2):\n        try:\n            # Select two different newts\n            newt_id1, newt_id2 = random.sample(newt_ids, 2)\n            \n            # Get one image from each newt\n            idx1 = random.choice(newt_indices_by_id[newt_id1])\n            idx2 = random.choice(newt_indices_by_id[newt_id2])\n            \n            print(f\"  Processing pair {pair_idx+1}: Newt {newt_id1} (idx {idx1}) vs Newt {newt_id2} (idx {idx2})\")\n            \n            # Get the images\n            if len(dataset[idx1]) == 3:\n                image1, label1, _ = dataset[idx1]\n            else:\n                image1, label1 = dataset[idx1]\n                \n            if len(dataset[idx2]) == 3:\n                image2, label2, _ = dataset[idx2]\n            else:\n                image2, label2 = dataset[idx2]\n            \n            print(f\"    Image1: {image1.shape}, Label1: {label1}\")\n            print(f\"    Image2: {image2.shape}, Label2: {label2}\")\n            \n            # Convert images to tensors for similarity computation (add batch dimension)\n            image1_tensor = image1.unsqueeze(0).to(device)  # [1, C, H, W]\n            image2_tensor = image2.unsqueeze(0).to(device)  # [1, C, H, W]\n            \n            # Test baseline similarity\n            baseline_similarity = similarity_model(image1_tensor, image2_tensor).item()\n            print(f\"    Baseline similarity: {baseline_similarity:.4f}\")\n            \n            # Run occlusion sensitivity using your function with tensors\n            print(f\"    Running occlusion sensitivity...\")\n            occlusion_map = my_occlusion_sensitivity(\n                similarity_model, \n                image1_tensor, \n                image2_tensor, \n                patch_size=16, \n                stride=8, \n                occlusion_value=0.5, \n                device=device\n            )\n            print(f\"    Occlusion map shape: {occlusion_map.shape}, range [{occlusion_map.min():.3f}, {occlusion_map.max():.3f}]\")\n            \n            # Convert images to numpy for visualization only\n            img1_np = image1.cpu().numpy().transpose(1, 2, 0)\n            img1_np = (img1_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n            img1_np = np.clip(img1_np, 0, 1)\n            \n            img2_np = image2.cpu().numpy().transpose(1, 2, 0)\n            img2_np = (img2_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n            img2_np = np.clip(img2_np, 0, 1)\n            \n            # Save visualization\n            save_path = epoch_dir / f\"similarity_pair_{pair_idx+1}_newt_{newt_id1}_vs_{newt_id2}.png\"\n            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n            \n            # Original images\n            axes[0,0].imshow(img1_np)\n            axes[0,0].set_title(f'Image 1: Newt {newt_id1}\\n(Index {idx1})')\n            axes[0,0].axis('off')\n            \n            axes[0,1].imshow(img2_np)\n            axes[0,1].set_title(f'Image 2: Newt {newt_id2}\\n(Index {idx2})')\n            axes[0,1].axis('off')\n            \n            # Occlusion sensitivity overlay\n            axes[1,0].imshow(img1_np)\n            axes[1,0].imshow(occlusion_map, cmap='hot', alpha=0.6)\n            axes[1,0].set_title(f'Occlusion Sensitivity on Image 1\\n(Similarity: {baseline_similarity:.3f})')\n            axes[1,0].axis('off')\n            \n            # Pure occlusion map\n            im = axes[1,1].imshow(occlusion_map, cmap='hot')\n            axes[1,1].set_title('Occlusion Sensitivity Map')\n            axes[1,1].axis('off')\n            plt.colorbar(im, ax=axes[1,1])\n            \n            plt.tight_layout()\n            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n            plt.close()\n            \n            print(f\"    ✅ Saved similarity occlusion test to {save_path}\")\n            \n        except Exception as e:\n            print(f\"    ❌ Error in similarity occlusion test for pair {pair_idx}: {e}\")\n            import traceback\n            traceback.print_exc()\n    \n    print(f\"Completed occlusion sensitivity test for epoch {epoch}\")\n    model.train()\n    bsl_loss.train()\n\n# Test occlusion sensitivity function\nprint(\"Testing occlusion sensitivity function...\")\n\ntest_occlusion_dir = Path(\"data/test_occlusion\")\ntest_occlusion_dir.mkdir(parents=True, exist_ok=True)\n\nrun_occlusion_sensitivity_test(\n    model, bsl_loss, tiny_test_dataset, device, epoch=-1, save_dir=test_occlusion_dir\n)\n\nprint(\"✅ Occlusion sensitivity test completed!\")\n\n\n# Set up full training configuration with verification\ndef setup_full_training():\n    print(\"Setting up full training configuration...\")\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Set seed for reproducibility\n    set_seed(42)\n    print(\"✅ Seed set for reproducibility\")\n    \n    # Model\n    num_classes = len(train_dataset.label_to_idx)\n    model = MegaDescriptorWithBSL(num_classes).to(device)\n    print(f\"✅ Model created with {model.embedding_size} embedding size for {num_classes} classes\")\n    \n    # Loss function with ArcFace + Background suppression\n    bsl_loss = BackgroundSuppressionArcFaceLoss(\n        num_classes=num_classes,\n        embedding_size=model.embedding_size,\n        margin=0.5,\n        scale=64,\n        alpha=1.0,    # ArcFace weight\n        beta=0.5      # Background suppression weight\n    ).to(device)\n    print(f\"✅ BSL loss created (alpha={1.0}, beta={0.5})\")\n    \n    # Optimizer for both model and ArcFace parameters\n    params = itertools.chain(model.parameters(), bsl_loss.parameters())\n    optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=1e-4)\n    print(f\"✅ Optimizer created with lr=1e-4\")\n    \n    # Learning rate scheduler\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n    print(\"✅ Cosine annealing scheduler created\")\n    \n    # Data loaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=16, \n        shuffle=True, \n        num_workers=2,\n        pin_memory=True if device.type == 'cuda' else False\n    )\n    \n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=16, \n        shuffle=False, \n        num_workers=2,\n        pin_memory=True if device.type == 'cuda' else False\n    )\n    print(f\"✅ Data loaders created: {len(train_loader)} train batches, {len(test_loader)} test batches\")\n    \n    # Create directories for saving\n    os.makedirs(\"data\", exist_ok=True)\n    occlusion_dir = Path(\"data/occlusion_maps\")\n    occlusion_dir.mkdir(parents=True, exist_ok=True)\n    print(f\"✅ Directories created: data/, {occlusion_dir}\")\n    \n    # Test one forward pass with real data\n    print(\"Testing forward pass with real data...\")\n    with torch.no_grad():\n        for batch in train_loader:\n            images, labels, masks = batch\n            images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n            \n            embeddings = model(images)\n            patch_features = model.get_patch_features()\n            loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n            \n            print(f\"✅ Forward pass successful:\")\n            print(f\"   Batch shape: {images.shape}\")\n            print(f\"   Embeddings: {embeddings.shape}\")\n            print(f\"   Patch features: {patch_features.shape if patch_features is not None else None}\")\n            print(f\"   Losses: total={loss.item():.4f}, arcface={arcface_loss.item():.4f}, bg={bg_loss.item():.4f}\")\n            break\n    \n    return model, bsl_loss, optimizer, scheduler, train_loader, test_loader, device, occlusion_dir\n\n# Setup training with verification\nmodel, bsl_loss, optimizer, scheduler, train_loader, test_loader, device, occlusion_dir = setup_full_training()\n\n\n# Test one complete epoch to verify everything works\nprint(\"=\" * 60)\nprint(\"TESTING ONE COMPLETE EPOCH\")\nprint(\"=\" * 60)\n\n# Initialize best accuracy for testing\nbest_acc = 0\n\n# Create a subset for testing\ntest_train_dataset = NewtDataset(df_train.head(64), dataset_path, transform=transform_train, return_mask=True)\ntest_train_loader = DataLoader(test_train_dataset, batch_size=8, shuffle=True, num_workers=0)\n\ntest_test_dataset = NewtDataset(df_test.head(32), dataset_path, transform=transform_test, return_mask=True)\ntest_test_loader = DataLoader(test_test_dataset, batch_size=8, shuffle=False, num_workers=0)\n\nprint(\"Running test training epoch...\")\ntrain_loss, arcface_loss, bg_loss, train_acc = train_epoch(\n    model, test_train_loader, bsl_loss, optimizer, device, epoch=0\n)\n\nprint(\"Running test evaluation...\")\ntest_acc = evaluate(model, test_test_loader, bsl_loss, device)\n\nprint(\"Testing scheduler step...\")\nold_lr = optimizer.param_groups[0]['lr']\nscheduler.step()\nnew_lr = optimizer.param_groups[0]['lr']\n\nprint(f\"✅ Complete epoch test passed!\")\nprint(f\"   Train Loss: {train_loss:.4f} (ArcFace: {arcface_loss:.4f}, BG: {bg_loss:.4f})\")\nprint(f\"   Train Acc:  {train_acc:.2f}%\")\nprint(f\"   Test Acc:   {test_acc:.2f}% {'🌟 BEST!' if test_acc &gt; best_acc else ''}\")\nprint(f\"   Best Acc:   {best_acc:.2f}%\")\nprint(f\"   LR:         {old_lr:.2e} → {new_lr:.2e}\")\n\n\n# Test training visualization with actual results\ndef test_training_visualization_with_actual_results(train_loss, arcface_loss, bg_loss, train_acc, test_acc, lr):\n    print(\"Testing training visualization with actual results...\")\n    \n    # Use actual training results\n    epochs = [0]  # Just one epoch for testing\n    train_losses = [train_loss]\n    arcface_losses = [arcface_loss]\n    bg_losses = [bg_loss]\n    train_accs = [train_acc]\n    test_accs = [test_acc]\n    lrs = [lr]\n    \n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    \n    # Loss curves\n    axes[0,0].plot(epochs, train_losses, label='Total Loss', marker='o', markersize=8)\n    axes[0,0].plot(epochs, arcface_losses, label='ArcFace Loss', marker='s', markersize=8)\n    axes[0,0].plot(epochs, bg_losses, label='Background Loss', marker='^', markersize=8)\n    axes[0,0].set_title('Training Losses (Actual Results)')\n    axes[0,0].legend()\n    axes[0,0].grid(True)\n    axes[0,0].set_xlabel('Epoch')\n    axes[0,0].set_ylabel('Loss')\n    axes[0,0].set_xlim(-0.1, 0.1)\n    \n    # Accuracy curves\n    axes[0,1].plot(epochs, train_accs, label='Train Acc', marker='o', markersize=8)\n    axes[0,1].plot(epochs, test_accs, label='Test Acc', marker='s', markersize=8)\n    axes[0,1].set_title('Accuracy (Actual Results)')\n    axes[0,1].legend()\n    axes[0,1].grid(True)\n    axes[0,1].set_xlabel('Epoch')\n    axes[0,1].set_ylabel('Accuracy (%)')\n    axes[0,1].set_xlim(-0.1, 0.1)\n    \n    # Loss breakdown\n    axes[1,0].plot(epochs, arcface_losses, label='ArcFace', marker='o', markersize=8)\n    axes[1,0].plot(epochs, bg_losses, label='Background Suppression', marker='s', markersize=8)\n    axes[1,0].set_title('Loss Components (Actual Results)')\n    axes[1,0].legend()\n    axes[1,0].grid(True)\n    axes[1,0].set_xlabel('Epoch')\n    axes[1,0].set_ylabel('Loss')\n    axes[1,0].set_xlim(-0.1, 0.1)\n    \n    # Learning rate\n    axes[1,1].plot(epochs, lrs, marker='o', markersize=8)\n    axes[1,1].set_title('Learning Rate (Actual)')\n    axes[1,1].grid(True)\n    axes[1,1].set_xlabel('Epoch')\n    axes[1,1].set_ylabel('Learning Rate')\n    axes[1,1].set_xlim(-0.1, 0.1)\n    \n    # Add actual values as text - fix the max() calls\n    max_loss = max(train_loss, arcface_loss, bg_loss)  # Compare actual values, not lists\n    max_acc = max(train_acc, test_acc)  # Compare actual values, not lists\n    \n    axes[0,0].text(0, max_loss, f'Total: {train_loss:.4f}\\nArcFace: {arcface_loss:.4f}\\nBG: {bg_loss:.4f}', \n                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n    axes[0,1].text(0, max_acc, f'Train: {train_acc:.2f}%\\nTest: {test_acc:.2f}%', \n                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n    \n    plt.tight_layout()\n    plt.savefig('data/actual_training_test_results.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(\"✅ Training visualization with actual results completed!\")\n    print(f\"   Results saved to: data/actual_training_test_results.png\")\n    print(f\"   Train Loss: {train_loss:.4f} (ArcFace: {arcface_loss:.4f}, BG: {bg_loss:.4f})\")\n    print(f\"   Accuracies: Train {train_acc:.2f}%, Test {test_acc:.2f}%\")\n    print(f\"   Learning Rate: {lr:.2e}\")\n\n# Test with actual results from the training epoch\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTING VISUALIZATION WITH ACTUAL RESULTS\")\nprint(\"=\"*60)\n\ntest_training_visualization_with_actual_results(\n    train_loss=train_loss,\n    arcface_loss=arcface_loss, \n    bg_loss=bg_loss,\n    train_acc=train_acc,\n    test_acc=test_acc,\n    lr=new_lr  # Use the learning rate after scheduler step\n)\n\n\n# Main training function with comprehensive testing\ndef train_newt_reid_with_bsl():\n    print(\"🚀 STARTING COMPREHENSIVE TRAINING\")\n    print(\"=\" * 70)\n    \n    num_epochs = 5\n    best_acc = 0\n    train_history = []\n    \n    # Initial sanity check\n    print(\"Performing initial sanity checks...\")\n    with torch.no_grad():\n        for batch in train_loader:\n            images, labels, masks = batch\n            images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n            embeddings = model(images)\n            patch_features = model.get_patch_features()\n            loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n            print(f\"✅ Initial forward pass: Loss={loss.item():.4f}\")\n            break\n    \n    print(\"Starting training loop...\")\n    \n    for epoch in range(num_epochs):\n        print(f\"\\n{'='*20} EPOCH {epoch+1}/{num_epochs} {'='*20}\")\n        \n        # Training\n        print(\"Training...\")\n        train_loss, arcface_loss, bg_loss, train_acc = train_epoch(\n            model, train_loader, bsl_loss, optimizer, device, epoch\n        )\n        \n        # Evaluation\n        print(\"Evaluating...\")\n        test_acc = evaluate(model, test_loader, bsl_loss, device)\n        \n        # Learning rate scheduling\n        old_lr = optimizer.param_groups[0]['lr']\n        scheduler.step()\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        # Save training history\n        epoch_data = {\n            'epoch': epoch,\n            'train_loss': train_loss,\n            'arcface_loss': arcface_loss,\n            'bg_loss': bg_loss,\n            'train_acc': train_acc,\n            'test_acc': test_acc,\n            'lr': current_lr\n        }\n        train_history.append(epoch_data)\n        \n        # Occlusion sensitivity testing every 5 epochs\n        if epoch % 5 == 0:\n            print(f\"Running occlusion sensitivity test...\")\n            run_occlusion_sensitivity_test(model, bsl_loss, test_dataset, device, epoch, occlusion_dir)\n        \n        # Save best model\n        is_best = test_acc &gt; best_acc\n        if is_best:\n            best_acc = test_acc\n            checkpoint = {\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'loss_state_dict': bsl_loss.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'best_acc': best_acc,\n                'embedding_size': model.embedding_size,\n                'num_classes': len(train_dataset.label_to_idx),\n                'train_history': train_history\n            }\n            torch.save(checkpoint, 'data/best_newt_reid_bsl_model.pth')\n            print(f\"💾 NEW BEST MODEL SAVED! Accuracy: {best_acc:.2f}%\")\n        \n        # Print epoch summary\n        print(f\"\\n📊 EPOCH {epoch} SUMMARY:\")\n        print(f\"   Train Loss: {train_loss:.4f} (ArcFace: {arcface_loss:.4f}, BG: {bg_loss:.4f})\")\n        print(f\"   Train Acc:  {train_acc:.2f}%\")\n        print(f\"   Test Acc:   {test_acc:.2f}% {'🌟 BEST!' if is_best else ''}\")\n        print(f\"   Best Acc:   {best_acc:.2f}%\")\n        print(f\"   LR:         {old_lr:.2e} → {current_lr:.2e}\")\n        \n        # Visualization every 5 epochs\n        if epoch &gt; 0 and epoch % 5 == 0:\n            print(\"Creating training visualizations...\")\n            \n            epochs = [h['epoch'] for h in train_history]\n            train_losses = [h['train_loss'] for h in train_history]\n            arcface_losses = [h['arcface_loss'] for h in train_history]\n            bg_losses = [h['bg_loss'] for h in train_history]\n            train_accs = [h['train_acc'] for h in train_history]\n            test_accs = [h['test_acc'] for h in train_history]\n            lrs = [h['lr'] for h in train_history]\n            \n            fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n            \n            # Loss curves\n            axes[0,0].plot(epochs, train_losses, label='Total Loss', marker='o')\n            axes[0,0].plot(epochs, arcface_losses, label='ArcFace Loss', marker='s')\n            axes[0,0].plot(epochs, bg_losses, label='Background Loss', marker='^')\n            axes[0,0].set_title('Training Losses')\n            axes[0,0].legend()\n            axes[0,0].grid(True)\n            \n            # Accuracy curves\n            axes[0,1].plot(epochs, train_accs, label='Train Acc', marker='o')\n            axes[0,1].plot(epochs, test_accs, label='Test Acc', marker='s')\n            axes[0,1].set_title('Accuracy')\n            axes[0,1].legend()\n            axes[0,1].grid(True)\n            \n            # Loss breakdown\n            axes[1,0].plot(epochs, arcface_losses, label='ArcFace', marker='o')\n            axes[1,0].plot(epochs, bg_losses, label='Background Suppression', marker='s')\n            axes[1,0].set_title('Loss Components')\n            axes[1,0].legend()\n            axes[1,0].grid(True)\n            \n            # Learning rate\n            axes[1,1].plot(epochs, lrs, marker='o')\n            axes[1,1].set_title('Learning Rate')\n            axes[1,1].set_yscale('log')\n            axes[1,1].grid(True)\n            \n            plt.tight_layout()\n            plt.savefig(f'data/training_progress_epoch_{epoch}.png', dpi=150, bbox_inches='tight')\n            plt.show()\n    \n    print(f\"\\n🎉 TRAINING COMPLETED!\")\n    print(f\"📈 Best test accuracy: {best_acc:.2f}%\")\n    print(f\"💾 Model saved to: data/best_newt_reid_bsl_model.pth\")\n    print(f\"🔍 Occlusion maps saved to: {occlusion_dir}\")\n    \n    return model, bsl_loss, train_history\n\nprint(\"✅ All tests passed! Ready to start main training...\")\n\n\n# Final pre-training verification\nprint(\"FINAL PRE-TRAINING VERIFICATION\")\nprint(\"=\" * 50)\n\n# Check GPU memory if available\nif torch.cuda.is_available():\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    print(f\"GPU Memory Free: {torch.cuda.memory_reserved(0) / 1e9:.1f} GB\")\n\n# Check dataset sizes\nprint(f\"Training samples: {len(train_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\nprint(f\"Classes: {len(train_dataset.label_to_idx)}\")\nprint(f\"Batches per epoch: {len(train_loader)}\")\n\n# Final forward pass test\nprint(\"Final forward pass test...\")\nwith torch.no_grad():\n    test_batch = next(iter(train_loader))\n    images, labels, masks = test_batch\n    images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n    \n    embeddings = model(images)\n    patch_features = model.get_patch_features()\n    loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n    \n    print(f\"✅ Final test successful!\")\n    print(f\"   Batch size: {images.shape[0]}\")\n    print(f\"   Total loss: {loss.item():.4f}\")\n    print(f\"   Memory usage: {torch.cuda.memory_allocated(0) / 1e6:.1f} MB\" if torch.cuda.is_available() else \"CPU mode\")\n\nprint(\"\\n🚀 READY TO START TRAINING!\")\n\n\n# Start the actual training!\ntrained_model, trained_bsl_loss, history = train_newt_reid_with_bsl()",
    "crumbs": [
      "BSL Experiment"
    ]
  },
  {
    "objectID": "gcn_seg.html",
    "href": "gcn_seg.html",
    "title": "Newt Segmentation",
    "section": "",
    "text": "import os\nimport pathlib\n\ndata_path = pathlib.Path(\"./data/barhill-newts-all\")\n\nif not data_path.exists():\n    os.system(f\"kaggle datasets download -d mshahoyi/barhill-newts-all --unzip -p {data_path}\")\n\n\ntry:\n    import supervision\n    os.chdir(\"gsam2\")\nexcept:\n    os.system('git clone https://github.com/IDEA-Research/Grounded-SAM-2 gsam2')\n    os.chdir(\"gsam2\")\n    os.system('pip install -q -e . -e grounding_dino')\n    os.system('pip install -q supervision')\n\n/kaggle/working/gcn-reid/nbs/gsam2\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pycocotools.mask as mask_util\nfrom PIL import Image\nimport argparse\nimport os\nimport cv2\nimport json\nimport torch\nimport pandas as pd\nfrom gcn_reid.newt_dataset import upload_to_kaggle\nimport pathlib\nimport shutil\nfrom datetime import datetime\nimport subprocess\nimport tempfile\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport supervision as sv\nimport pycocotools.mask as mask_util\nfrom pathlib import Path\nfrom supervision.draw.color import ColorPalette\nfrom utils.supervision_utils import CUSTOM_COLOR_MAP\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sam2.build_sam import build_sam2\nfrom sam2.sam2_image_predictor import SAM2ImagePredictor\nfrom transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\nimport pandas as pd\n\n\nGROUNDING_MODEL = \"IDEA-Research/grounding-dino-base\"\nSAM2_CHECKPOINT = \"./checkpoints/sam2.1_hiera_large.pt\"\nSAM2_MODEL_CONFIG = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nOUTPUT_DIR = Path(\"outputs/test_sam2.1\")\nDUMP_JSON_RESULTS = True\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\nTEXT_PROMPT = \"newt amphibian reptile.\"\n\n\ntorch.autocast(device_type=DEVICE, dtype=torch.bfloat16).__enter__()\n\nif torch.cuda.get_device_properties(0).major &gt;= 8:\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n\nos.chdir(\"checkpoints\")\nos.system(\"bash download_ckpts.sh\")\nos.chdir(\"..\")\n\nsam2_checkpoint = SAM2_CHECKPOINT\nmodel_cfg = SAM2_MODEL_CONFIG\nsam2_model = build_sam2(model_cfg, sam2_checkpoint, device=DEVICE)\nsam2_predictor = SAM2ImagePredictor(sam2_model)\n\nmodel_id = GROUNDING_MODEL\nprocessor = AutoProcessor.from_pretrained(model_id)\ngrounding_model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(DEVICE)\n\nos.chdir(\"..\")\n\n\ndf = pd.read_csv(data_path / \"metadata.csv\")\ndf\n\n\nCreate Boudning Boxes\ndf[‘bbox’] = None\nfor i, row in tqdm(df[~df.is_video].iterrows()): # Process first 3 newts for demo image_path = data_path / row.file_path image_key = f”{row.identity}/{row.file_name}” image = cv2.imread(image_path) pil_image = Image.open(image_path) inputs = processor(images=pil_image, text=TEXT_PROMPT, return_tensors=“pt”).to(DEVICE) with torch.no_grad(): outputs = grounding_model(**inputs)\nresults = processor.post_process_grounded_object_detection(\n    outputs,\n    inputs.input_ids,\n    box_threshold=0.4,\n    text_threshold=0.3,\n    target_sizes=[(image.shape[0], image.shape[1])]\n)[0]  # Get first (and only) result\n\nbbox = results[\"boxes\"].cpu().numpy().tolist()\nif len(bbox) &gt; 0:\n    df.at[i, 'bbox'] = bbox[0]\nelse:\n    df.at[i, 'bbox'] = None\n\ndf.bbox.describe()\n\n\n\nAdd manual annotations\n\nwith open(\"manual_annotations.json\", \"r\") as f:\n    manual_annotations = json.load(f)\n\n\nfor annot in manual_annotations[\"images\"]:\n    image_name = annot[\"image\"]\n    bbox_dict = annot[\"annotations\"][0][\"boundingBox\"]\n    # Convert from XYWH to XYXY format\n    x, y, w, h = bbox_dict[\"x\"], bbox_dict[\"y\"], bbox_dict[\"width\"], bbox_dict[\"height\"]\n    bbox = [x, y, x + w, y + h]  # Convert to XYXY format\n    df.at[df[df.file_name == image_name].index[0], \"bbox\"] = bbox\n\n\ndf.bbox.describe()\n\n\n\nVisualise bounding boxes\n\nsource\n\nvisualize_bbox\n\n visualize_bbox (image_path, bbox, label)\n\n\ni = df[df.bbox.notna()].index[0]\nvisualize_bbox(data_path / df.iloc[i].file_path, df.iloc[i].bbox, \"newt\")\n\n\n\n\nCreate Segmentation Masks\n\ndf['segmentation_mask_rle'] = None\n\nfor i, row in tqdm(df[~df.is_video].iterrows()):\n    image_path = data_path / row.file_path\n    # image = cv2.imread(image_path)\n    pil_image = Image.open(image_path)\n    \n    box = np.array(row.bbox).reshape(1, 4)\n    sam_box = box.astype(int)\n    sam2_predictor.set_image(np.array(pil_image.convert(\"RGB\")))\n    masks, _, _ = sam2_predictor.predict(\n        box=sam_box,\n        multimask_output=False\n    )\n    mask = masks[0]  # Get the first (and only) mask\n    mask_uint8 = mask.astype(np.uint8, order='F')\n    rle = mask_util.encode(mask_uint8)\n    rle_string = rle['counts'].decode('utf-8') if isinstance(rle['counts'], bytes) else str(rle['counts'])\n\n    df.at[i, 'segmentation_mask_rle'] = f\"{rle['size'][0]}x{rle['size'][1]}:{rle_string}\"\n\n\ndf.segmentation_mask_rle.describe()\n\n\n\nVisualise Segmentation Masks\n\nsource\n\ndecode_rle_mask\n\n decode_rle_mask (rle_string)\n\nDecode RLE string back to binary mask\n\ni = df[df.segmentation_mask_rle.notna()].index[0]\nmask = decode_rle_mask(df.iloc[i].segmentation_mask_rle)\nplt.subplot(1, 2, 1)\nplt.imshow(mask)\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.imread(data_path / df.iloc[i].file_path))\nplt.axis('off')\nplt.show()\n\n\nsource\n\n\nvisualize_segmentation\n\n visualize_segmentation (image_path, mask, bbox, label)\n\n\ni = df[df.segmentation_mask_rle.notna()].index[0]\nmask = decode_rle_mask(df.iloc[i].segmentation_mask_rle)\nvisualize_segmentation(data_path / df.iloc[i].file_path, mask.reshape(1, mask.shape[0], mask.shape[1]), df.iloc[i].bbox, \"newt\")\n\nUpdated metadata saved to ./data/barhill/gallery_and_probes_with_masks.csv\nAdded segmentation masks for 998 out of 1253 images\n\n\n\n\n\nCreate sample visualisations\n\nos.makedirs(data_path / \"sample_visualisations\", exist_ok=True)\n\nfor i, row in tqdm(df[df.segmentation_mask_rle.notna()].sample(100).iterrows()):\n    mask = decode_rle_mask(row.segmentation_mask_rle)\n    mask = mask.reshape(1, mask.shape[0], mask.shape[1])\n    \n    plt.figure(figsize=(10, 10))\n    visualize_segmentation(data_path / row.file_path, mask, row.bbox, \"newt\")\n    plt.savefig(data_path / \"sample_visualisations\" / f\"{row.identity}-{row.file_name}\")\n    plt.close()\n\n\n\nCreate New Kaggle Dataset\nmetadata_dest = data_path / “metadata.csv” df.to_csv(metadata_dest, index=False)\n\n\nUpload to Kaggle\n\nupload_to_kaggle(user_id=\"mshahoyi\",\n                title=\"GCNs Segmented\", \n                id=\"newts-segmented-new\", \n                licenses=[{\"name\": \"CC0-1.0\"}], \n                keywords=[\"biology\", \"computer-vision\", \"animals\", \"great crested newts\"], \n                dataset_dir=data_path)",
    "crumbs": [
      "Newt Segmentation"
    ]
  },
  {
    "objectID": "artefacts.html",
    "href": "artefacts.html",
    "title": "Artefacts",
    "section": "",
    "text": "import os\nimport sys\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom wildlife_datasets import analysis, datasets, splits\nimport pycocotools.mask as mask_util\nfrom wildlife_tools.data import ImageDataset\nfrom sklearn.metrics import average_precision_score\nimport numpy as np\nimport timm\nfrom transformers import AutoModel\nimport torch\nimport numpy as np\nfrom wildlife_tools.inference import TopkClassifier, KnnClassifier\nfrom wildlife_tools.features import DeepFeatures\nimport torchvision.transforms as T\nfrom PIL import Image\nimport kaggle\nimport pandas as pd\nfrom wildlife_tools.data import ImageDataset, FeatureDataset, FeatureDatabase\nfrom gcn_reid.segmentation import decode_rle_mask\nfrom gcn_reid.newt_dataset import upload_to_kaggle\nfrom pathlib import Path\nfrom gcn_reid.newt_dataset import download_kaggle_dataset\nfrom tqdm import tqdm\nfrom transformers import AutoImageProcessor, AutoModel\nimport cv2\nfrom IPython import display\n\n2025-06-27 09:18:41.180455: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751015921.203058   14306 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751015921.210017   14306 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\n\n\ndataset_name = 'mshahoyi/gcn-id-2024'\ndataset_path = Path('data/gcn-id-2024')\ndownload_kaggle_dataset(dataset_name, dataset_path)\n\nDataset already exists at data/gcn-id-2024\n\n\nPosixPath('data/gcn-id-2024')\n\n\n\nmetadata = pd.read_csv(dataset_path / 'metadata.csv')\nmetadata\n\n\n\n\n\n\n\n\nreference_id\nfile_path\nfile_name\nis_video\nidentity\ncreation_date\nbbox\nsegmentation_mask_rle\nis_hard_test_query\nis_hard_val_query\nis_least_similar_test_query\nis_least_similar_val_query\nis_random_test_query\nis_random_val_query\n\n\n\n\n0\nGCN34-P3-S2\nnewts/1/IMG_2532.JPEG\nIMG_2532.JPEG\nFalse\n1\n2024-05-10 08:37:21+00:00\n[14.939163208007812, 507.19061279296875, 1066....\n2048x1536:Sd`03ko14N0000000bNKcRN0^O5om1KcRN1]...\nNaN\nFalse\nNaN\nNaN\nTrue\nNaN\n\n\n1\nGCN34-P3-S2\nnewts/1/IMG_2530.JPEG\nIMG_2530.JPEG\nFalse\n1\n2024-05-10 08:37:19+00:00\n[288.80975341796875, 363.1075439453125, 1062.7...\n2048x1536:[ajb03;31K_n1:YQN10O4Knm1h0lQN_O2O0M...\nNaN\nFalse\nNaN\nNaN\nFalse\nNaN\n\n\n2\nGCN34-P3-S2\nnewts/1/IMG_2531.JPEG\nIMG_2531.JPEG\nFalse\n1\n2024-05-10 08:37:20+00:00\n[288.86181640625, 521.5284423828125, 1159.4096...\n2048x1536:Pcdb07^o1d0D7H=E5K5L5J5K3M4M3M10001N...\nNaN\nFalse\nNaN\nNaN\nFalse\nNaN\n\n\n3\nGCN34-P3-S2\nnewts/1/IMG_2533.JPEG\nIMG_2533.JPEG\nFalse\n1\n2024-05-10 08:37:23+00:00\n[489.2838134765625, 169.9361572265625, 1132.72...\n2048x1536:X`Vo06do1;H;dNH]RN&gt;[m1e1]O5M4K4M3M3L...\nNaN\nFalse\nNaN\nNaN\nFalse\nNaN\n\n\n4\nGCN34-P3-S2\nnewts/1/IMG_2534.JPEG\nIMG_2534.JPEG\nFalse\n1\n2024-05-10 08:37:24+00:00\n[365.6585388183594, 454.51068115234375, 1005.9...\n2048x1536:SmZd03lo13M3M2O1O1N2`QNJTm16gRN3Vm1M...\nNaN\nTrue\nNaN\nNaN\nFalse\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2460\nGCN2-P4-S6\nnewts/206/IMG_3588.JPEG\nIMG_3588.JPEG\nFalse\n206\n2024-06-07 08:13:15+00:00\n[497.18017578125, 333.2651062011719, 1013.9716...\n2046x1538:Zido07bo17M2M2N2N2O1O1N2O1O0O2O1N2O1...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2461\nGCN2-P4-S6\nnewts/206/IMG_3583.MOV\nIMG_3583.MOV\nTrue\n206\n2024-06-07 14:48:31+00:00\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2462\nGCN2-P4-S6\nnewts/206/IMG_3583.JPEG\nIMG_3583.JPEG\nFalse\n206\n2024-06-07 08:13:06+00:00\n[3.999234437942505, 593.5800170898438, 1326.80...\n2046x1538:Z[1&gt;6`1Vm1`NjRN`1Vm1`NjRN`1Um1h0L6J5...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2463\nGCN2-P4-S6\nnewts/206/IMG_3588.MOV\nIMG_3588.MOV\nTrue\n206\n2024-06-07 14:48:27+00:00\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2464\nGCN2-P4-S6\nnewts/206/IMG_3586.MOV\nIMG_3586.MOV\nTrue\n206\n2024-06-07 14:48:20+00:00\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n2465 rows × 14 columns\n\n\n\n\nartifacts_path = Path('artifacts')\n\n\ndino_features_df = pd.read_csv(artifacts_path / 'metadata_with_features.csv')\ndino_features_df['dinov2_features'] = dino_features_df['dinov2_features'].apply(eval)\ndino_features_df\n\n\n\n\n\n\n\n\nreference_id\nfile_path\nfile_name\nis_video\nidentity\ncreation_date\nbbox\nsegmentation_mask_rle\ndinov2_features\n\n\n\n\n0\nGCN34-P3-S2\nnewts/1/IMG_2532.JPEG\nIMG_2532.JPEG\nFalse\n1\n2024-05-10 08:37:21+00:00\n[14.939163208007812, 507.19061279296875, 1066....\n2048x1536:Sd`03ko14N0000000bNKcRN0^O5om1KcRN1]...\n[0.15917837619781494, 1.008996844291687, -3.47...\n\n\n1\nGCN34-P3-S2\nnewts/1/IMG_2530.JPEG\nIMG_2530.JPEG\nFalse\n1\n2024-05-10 08:37:19+00:00\n[288.80975341796875, 363.1075439453125, 1062.7...\n2048x1536:[ajb03;31K_n1:YQN10O4Knm1h0lQN_O2O0M...\n[0.2540416121482849, -0.6189689636230469, -2.4...\n\n\n2\nGCN34-P3-S2\nnewts/1/IMG_2531.JPEG\nIMG_2531.JPEG\nFalse\n1\n2024-05-10 08:37:20+00:00\n[288.86181640625, 521.5284423828125, 1159.4096...\n2048x1536:Pcdb07^o1d0D7H=E5K5L5J5K3M4M3M10001N...\n[-0.3387486934661865, -0.4380609393119812, -1....\n\n\n3\nGCN34-P3-S2\nnewts/1/IMG_2533.JPEG\nIMG_2533.JPEG\nFalse\n1\n2024-05-10 08:37:23+00:00\n[489.2838134765625, 169.9361572265625, 1132.72...\n2048x1536:X`Vo06do1;H;dNH]RN&gt;[m1e1]O5M4K4M3M3L...\n[1.2573355436325073, 0.47167059779167175, -1.6...\n\n\n4\nGCN34-P3-S2\nnewts/1/IMG_2534.JPEG\nIMG_2534.JPEG\nFalse\n1\n2024-05-10 08:37:24+00:00\n[365.6585388183594, 454.51068115234375, 1005.9...\n2048x1536:SmZd03lo13M3M2O1O1N2`QNJTm16gRN3Vm1M...\n[0.5498214960098267, -0.217705637216568, -1.48...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1227\nGCN2-P4-S6\nnewts/206/IMG_3584.JPEG\nIMG_3584.JPEG\nFalse\n206\n2024-06-07 08:13:07+00:00\n[3.784446954727173, 689.7179565429688, 1264.17...\n2046x1538:Qc1=ao1000NU1lPN^Oik1GnSNn2\\k1o0L3L2...\n[0.47062012553215027, -0.17789024114608765, 0....\n\n\n1228\nGCN2-P4-S6\nnewts/206/IMG_3587.JPEG\nIMG_3587.JPEG\nFalse\n206\n2024-06-07 08:13:14+00:00\n[533.1634521484375, 384.0157165527344, 1025.15...\n2046x1538:ggjQ19co13M3M2O1N2N2N1O2O1N2O001N2N1...\n[1.1572446823120117, 0.08006935566663742, -1.5...\n\n\n1229\nGCN2-P4-S6\nnewts/206/IMG_3586.JPEG\nIMG_3586.JPEG\nFalse\n206\n2024-06-07 08:13:11+00:00\n[3.742919683456421, 945.6688842773438, 1264.32...\n2046x1538:ld7:`o1m0SO:I4M2M3N1N10001O001O0O100...\n[-0.28730177879333496, -1.254452109336853, -1....\n\n\n1230\nGCN2-P4-S6\nnewts/206/IMG_3588.JPEG\nIMG_3588.JPEG\nFalse\n206\n2024-06-07 08:13:15+00:00\n[497.18017578125, 333.2651062011719, 1013.9716...\n2046x1538:Zido07bo17M2M2N2N2O1O1N2O1O0O2O1N2O1...\n[0.8618399500846863, 0.15614207088947296, -2.5...\n\n\n1231\nGCN2-P4-S6\nnewts/206/IMG_3583.JPEG\nIMG_3583.JPEG\nFalse\n206\n2024-06-07 08:13:06+00:00\n[3.999234437942505, 593.5800170898438, 1326.80...\n2046x1538:Z[1&gt;6`1Vm1`NjRN`1Vm1`NjRN`1Um1h0L6J5...\n[0.4422491192817688, -0.05180462449789047, 0.1...\n\n\n\n\n1232 rows × 9 columns\n\n\n\n\ndeep_features_df = pd.read_csv(artifacts_path/'baseline_features.csv')\n\ndeep_features_df['mega_features'] = deep_features_df['mega_features'].apply(eval)\ndeep_features_df['miewid_features'] = deep_features_df['miewid_features'].apply(eval)\ndeep_features_df['mega_features_cropped'] = deep_features_df['mega_features_cropped'].apply(eval)\ndeep_features_df['miewid_features_cropped'] = deep_features_df['miewid_features_cropped'].apply(eval)\ndeep_features_df['mega_features_cropped_rotated'] = deep_features_df['mega_features_cropped_rotated'].apply(eval)\ndeep_features_df['miewid_features_cropped_rotated'] = deep_features_df['miewid_features_cropped_rotated'].apply(eval)\ndeep_features_df['mega_features_rotated'] = deep_features_df['mega_features_rotated'].apply(eval)\ndeep_features_df['miewid_features_rotated'] = deep_features_df['miewid_features_rotated'].apply(eval)\ndeep_features_df\n\n\n\n\n\n\n\n\nreference_id\npath\nimage_name\nis_video\nidentity\ncreation_date\nbbox\nsegmentation_mask_rle\nis_hard_test_query\nis_hard_val_query\n...\nis_random_test_query\nis_random_val_query\nmega_features\nmiewid_features\nmega_features_cropped\nmiewid_features_cropped\nmega_features_cropped_rotated\nmiewid_features_cropped_rotated\nmega_features_rotated\nmiewid_features_rotated\n\n\n\n\n0\nGCN34-P3-S2\nnewts/1/IMG_2532.JPEG\nIMG_2532.JPEG\nFalse\n1\n2024-05-10 08:37:21+00:00\n[14.939163208007812, 507.19061279296875, 1066....\n2048x1536:Sd`03ko14N0000000bNKcRN0^O5om1KcRN1]...\nNaN\nFalse\n...\nTrue\nNaN\n[-0.2315349131822586, -0.6071900129318237, 0.2...\n[-1.0500768423080444, 0.9018495678901672, 1.10...\n[-0.26754456758499146, -0.3176382780075073, -0...\n[-0.9890046119689941, -0.3878686726093292, 0.0...\n[-0.09139543771743774, -0.27838510274887085, -...\n[-2.282212018966675, -1.1495726108551025, 0.36...\n[0.03521648794412613, -0.27079200744628906, 0....\n[-0.6298500895500183, 1.3818387985229492, 0.42...\n\n\n1\nGCN34-P3-S2\nnewts/1/IMG_2530.JPEG\nIMG_2530.JPEG\nFalse\n1\n2024-05-10 08:37:19+00:00\n[288.80975341796875, 363.1075439453125, 1062.7...\n2048x1536:[ajb03;31K_n1:YQN10O4Knm1h0lQN_O2O0M...\nNaN\nFalse\n...\nFalse\nNaN\n[-0.26202958822250366, -0.36001867055892944, 0...\n[-0.7708876729011536, -0.0288423839956522, 2.0...\n[-0.1098005622625351, -0.8450853824615479, -0....\n[-0.9856569766998291, 0.9584597945213318, 0.01...\n[0.07837007194757462, -0.1861935257911682, 0.1...\n[-0.7282273769378662, 1.7479289770126343, 1.67...\n[0.11916843801736832, -0.4386592507362366, 0.3...\n[0.30683621764183044, -0.7263781428337097, 1.2...\n\n\n2\nGCN34-P3-S2\nnewts/1/IMG_2531.JPEG\nIMG_2531.JPEG\nFalse\n1\n2024-05-10 08:37:20+00:00\n[288.86181640625, 521.5284423828125, 1159.4096...\n2048x1536:Pcdb07^o1d0D7H=E5K5L5J5K3M4M3M10001N...\nNaN\nFalse\n...\nFalse\nNaN\n[-0.10255614668130875, -0.5083745718002319, 0....\n[-2.023824453353882, 1.434230089187622, 1.3461...\n[0.23407597839832306, -0.5330269932746887, -0....\n[-0.4053780734539032, 1.5312628746032715, 0.22...\n[0.010707120411098003, -0.2526978552341461, 0....\n[0.07896972447633743, -0.052093833684921265, -...\n[0.4626787602901459, -0.20769257843494415, 0.2...\n[0.3217676877975464, -0.014798182062804699, 0....\n\n\n3\nGCN34-P3-S2\nnewts/1/IMG_2533.JPEG\nIMG_2533.JPEG\nFalse\n1\n2024-05-10 08:37:23+00:00\n[489.2838134765625, 169.9361572265625, 1132.72...\n2048x1536:X`Vo06do1;H;dNH]RN&gt;[m1e1]O5M4K4M3M3L...\nNaN\nFalse\n...\nFalse\nNaN\n[0.08337608724832535, -0.6282830834388733, 0.7...\n[-0.5282672047615051, 0.8011835813522339, 3.37...\n[-0.23315174877643585, -0.11018437892198563, 0...\n[-1.0730949640274048, -1.6122236251831055, -0....\n[-0.11565772444009781, -0.22544527053833008, -...\n[-2.143435001373291, 0.8045357465744019, -0.56...\n[0.2420016974210739, -0.21130432188510895, 0.1...\n[-0.7259004712104797, 0.5267841219902039, 1.34...\n\n\n4\nGCN34-P3-S2\nnewts/1/IMG_2534.JPEG\nIMG_2534.JPEG\nFalse\n1\n2024-05-10 08:37:24+00:00\n[365.6585388183594, 454.51068115234375, 1005.9...\n2048x1536:SmZd03lo13M3M2O1O1N2`QNJTm16gRN3Vm1M...\nNaN\nTrue\n...\nFalse\nNaN\n[-0.09542281180620193, -0.17980623245239258, 0...\n[-1.5232231616973877, 1.9110876321792603, 0.73...\n[0.028459327295422554, -0.3369773328304291, -0...\n[-1.5894969701766968, 0.6951966285705566, 0.99...\n[0.13891857862472534, -0.7412286400794983, -0....\n[-1.5177595615386963, -0.8847625255584717, -0....\n[-0.048625629395246506, -0.1544991135597229, 0...\n[-1.8346766233444214, -1.370731234550476, -0.1...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n418\nGCN7-P3-S6\nnewts/202/IMG_3618.JPEG\nIMG_3618.JPEG\nFalse\n202\n2024-06-07 08:17:00+00:00\n[173.46243286132812, 251.09988403320312, 1007....\n2046x1538:]UV;2m18ek14RSNJ_O159;@8:j0KRe10^YN2...\nFalse\nNaN\n...\nNaN\nNaN\n[0.36045947670936584, -0.4749039113521576, -0....\n[0.7483136057853699, -0.9030152559280396, -0.4...\n[-0.004413387272506952, 0.20352308452129364, -...\n[1.0502841472625732, -0.22691012918949127, 3.3...\n[0.18683913350105286, -0.00535912811756134, -0...\n[0.6201332807540894, 1.0667979717254639, 1.559...\n[0.5556980967521667, -0.2275843620300293, -0.2...\n[-0.463854044675827, 0.08879463374614716, -0.2...\n\n\n419\nGCN7-P3-S6\nnewts/202/IMG_3617.JPEG\nIMG_3617.JPEG\nFalse\n202\n2024-06-07 08:16:56+00:00\n[333.4060974121094, 442.3371887207031, 1123.58...\n2046x1538:Rlde0g0km1G_RNDOQ1ol1POoRN\\2kl1`0J5T...\nFalse\nNaN\n...\nNaN\nNaN\n[0.11689276248216629, -0.6378297209739685, -0....\n[2.944108247756958, -1.1957786083221436, -0.55...\n[-0.05661837384104729, -0.5120153427124023, 0....\n[1.580594778060913, 0.3132788836956024, 0.5221...\n[-0.07758941501379013, -0.9480556845664978, -0...\n[0.2786090672016144, 0.957034170627594, 1.7876...\n[-0.39309993386268616, -0.5051690340042114, -0...\n[0.06167209893465042, -0.06622131168842316, 1....\n\n\n420\nGCN7-P3-S6\nnewts/202/IMG_3616.JPEG\nIMG_3616.JPEG\nFalse\n202\n2024-06-07 08:16:55+00:00\n[372.7743225097656, 699.0594482421875, 1003.42...\n2046x1538:k_lg0;4Kan1c1SO`0D;G8J7H7L4K5L4M4L3M...\nTrue\nNaN\n...\nNaN\nNaN\n[0.44931793212890625, -0.3496696650981903, -0....\n[0.3646894693374634, -0.7953448295593262, 0.17...\n[-0.0834624394774437, -0.4534577429294586, -0....\n[-1.7752217054367065, -1.4919720888137817, 2.1...\n[0.039754800498485565, -1.0401729345321655, -0...\n[-0.4306054413318634, 0.4130638539791107, -0.1...\n[-0.28096890449523926, -0.5068223476409912, -0...\n[1.842775583267212, 0.19924509525299072, -0.47...\n\n\n421\nGCN7-P3-S6\nnewts/202/IMG_3615.JPEG\nIMG_3615.JPEG\nFalse\n202\n2024-06-07 08:16:54+00:00\n[414.04083251953125, 1346.5162353515625, 966.7...\n2046x1538:Ph`j0&lt;So1h0B?[Oc0Al0WO8I9Bc0C&lt;C6K6I6...\nFalse\nNaN\n...\nNaN\nNaN\n[0.5203171372413635, -0.11299236863851547, -0....\n[1.9476923942565918, -0.48994749784469604, -0....\n[-0.16569338738918304, -0.04783319681882858, 0...\n[0.7953149080276489, 3.5982272624969482, 1.564...\n[-0.02434113249182701, 0.0037951553240418434, ...\n[-0.5937361121177673, -1.4422950744628906, 1.6...\n[0.3658801019191742, -0.36543792486190796, 0.0...\n[0.14535380899906158, -1.3468108177185059, 0.4...\n\n\n422\nGCN7-P3-S6\nnewts/202/IMG_3619.JPEG\nIMG_3619.JPEG\nFalse\n202\n2024-06-07 08:17:01+00:00\n[581.1024780273438, 81.09144592285156, 1273.64...\n2046x1538:nRlU12ao1n0POP1gjNaNk:l1gD[NR;k1iD[N...\nFalse\nNaN\n...\nNaN\nNaN\n[-0.35377237200737, -0.5530931949615479, -0.42...\n[0.6184273362159729, -0.3226028084754944, 0.39...\n[-0.12055592983961105, -0.40245503187179565, -...\n[0.23289822041988373, 0.8358160257339478, 1.84...\n[-0.04343392699956894, -0.38101255893707275, -...\n[0.9455059766769409, 3.2257723808288574, 0.252...\n[-0.49605798721313477, -0.2443748116493225, -0...\n[0.8435536026954651, -0.8342486023902893, 0.58...\n\n\n\n\n423 rows × 22 columns\n\n\n\n\nOutput least similar images\n\ndinov2_features = np.array(dino_features_df['dinov2_features'].tolist())\n\n\n# Calculate cosine similarities manually\ndef cosine_similarity(a, b):\n    # Normalize the vectors\n    a_norm = a / np.linalg.norm(a, axis=1)[:, np.newaxis]\n    b_norm = b / np.linalg.norm(b, axis=1)[:, np.newaxis]\n    # Calculate similarity matrix\n    return np.dot(a_norm, b_norm.T)\n\ndinov2_similarities = cosine_similarity(dinov2_features, dinov2_features)\n\ndinov2_similarities.shape\n\n(1232, 1232)\n\n\n\n# Here I will create a dataframe of all similarities for each image\ndino_features_df['id_and_image_name'] = dino_features_df['identity'].astype(str) + '_' + dino_features_df['file_name']\ndino_features_df['id_and_image_name']\n\n0         1_IMG_2532.JPEG\n1         1_IMG_2530.JPEG\n2         1_IMG_2531.JPEG\n3         1_IMG_2533.JPEG\n4         1_IMG_2534.JPEG\n              ...        \n1227    206_IMG_3584.JPEG\n1228    206_IMG_3587.JPEG\n1229    206_IMG_3586.JPEG\n1230    206_IMG_3588.JPEG\n1231    206_IMG_3583.JPEG\nName: id_and_image_name, Length: 1232, dtype: object\n\n\n\ndinov2_similarities_df = pd.DataFrame(dinov2_similarities, index=dino_features_df['id_and_image_name'], columns=dino_features_df['id_and_image_name'])\nplt.imshow(dinov2_similarities_df.to_numpy())\nplt.title('Dinov2 Similarities for all images')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\ndinov2_similarities_df.to_csv(artifacts_path/'dinov2_similarities.csv')\ndinov2_similarities_df\n\n\n\n\n\n\n\nid_and_image_name\n1_IMG_2532.JPEG\n1_IMG_2530.JPEG\n1_IMG_2531.JPEG\n1_IMG_2533.JPEG\n1_IMG_2534.JPEG\n2_IMG_2524.JPEG\n2_IMG_2527.JPEG\n2_IMG_2526.JPEG\n2_IMG_2525.JPEG\n2_IMG_2528.JPEG\n...\n205_IMG_3581.JPEG\n205_IMG_3577.JPEG\n205_IMG_3580.JPEG\n205_IMG_3578.JPEG\n206_IMG_3585.JPEG\n206_IMG_3584.JPEG\n206_IMG_3587.JPEG\n206_IMG_3586.JPEG\n206_IMG_3588.JPEG\n206_IMG_3583.JPEG\n\n\nid_and_image_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1_IMG_2532.JPEG\n1.000000\n0.813332\n0.879888\n0.850998\n0.813479\n0.746874\n0.724935\n0.698625\n0.748820\n0.658164\n...\n0.688525\n0.690578\n0.676408\n0.703017\n0.675177\n0.708753\n0.700074\n0.746665\n0.691813\n0.696542\n\n\n1_IMG_2530.JPEG\n0.813332\n1.000000\n0.833461\n0.800902\n0.729356\n0.712115\n0.643013\n0.600463\n0.681778\n0.600570\n...\n0.643940\n0.620823\n0.631780\n0.622667\n0.587712\n0.626577\n0.633139\n0.629304\n0.635964\n0.604534\n\n\n1_IMG_2531.JPEG\n0.879888\n0.833461\n1.000000\n0.834979\n0.795149\n0.716890\n0.702605\n0.676005\n0.727538\n0.634601\n...\n0.649514\n0.656397\n0.624289\n0.644107\n0.615615\n0.644176\n0.651721\n0.665901\n0.653605\n0.621452\n\n\n1_IMG_2533.JPEG\n0.850998\n0.800902\n0.834979\n1.000000\n0.780088\n0.756950\n0.668114\n0.640386\n0.732097\n0.651160\n...\n0.720670\n0.660763\n0.692657\n0.700327\n0.623296\n0.650449\n0.690462\n0.675733\n0.657201\n0.654708\n\n\n1_IMG_2534.JPEG\n0.813479\n0.729356\n0.795149\n0.780088\n1.000000\n0.730636\n0.732146\n0.680611\n0.724181\n0.726167\n...\n0.659030\n0.687106\n0.637938\n0.700483\n0.691518\n0.664188\n0.651867\n0.697254\n0.614804\n0.670923\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n206_IMG_3584.JPEG\n0.708753\n0.626577\n0.644176\n0.650449\n0.664188\n0.714146\n0.699209\n0.687429\n0.745159\n0.673599\n...\n0.763114\n0.734511\n0.755917\n0.751901\n0.939096\n1.000000\n0.813961\n0.878643\n0.767568\n0.918880\n\n\n206_IMG_3587.JPEG\n0.700074\n0.633139\n0.651721\n0.690462\n0.651867\n0.718811\n0.668693\n0.631837\n0.700078\n0.622394\n...\n0.746712\n0.684394\n0.755745\n0.752171\n0.788080\n0.813961\n1.000000\n0.836224\n0.913911\n0.806955\n\n\n206_IMG_3586.JPEG\n0.746665\n0.629304\n0.665901\n0.675733\n0.697254\n0.740875\n0.724477\n0.713933\n0.735753\n0.667181\n...\n0.769256\n0.732786\n0.786979\n0.786723\n0.869043\n0.878643\n0.836224\n1.000000\n0.782906\n0.882148\n\n\n206_IMG_3588.JPEG\n0.691813\n0.635964\n0.653605\n0.657201\n0.614804\n0.677047\n0.616284\n0.619100\n0.669488\n0.574665\n...\n0.688912\n0.645019\n0.697031\n0.689405\n0.713369\n0.767568\n0.913911\n0.782906\n1.000000\n0.765179\n\n\n206_IMG_3583.JPEG\n0.696542\n0.604534\n0.621452\n0.654708\n0.670923\n0.690024\n0.667251\n0.638447\n0.704495\n0.651841\n...\n0.730754\n0.678890\n0.742274\n0.740046\n0.882133\n0.918880\n0.806955\n0.882148\n0.765179\n1.000000\n\n\n\n\n1232 rows × 1232 columns\n\n\n\n\ndef plot_identity_similarities(identity, dino_features_df, dinov2_similarities, dataset_path):\n    \"\"\"Plot all images for a given identity with their similarity scores.\n    \n    Args:\n        identity: The identity ID to plot\n        dino_features_df: DataFrame containing image features and metadata\n        dinov2_similarities: Matrix of similarity scores between all images\n        dataset_path: Path to the dataset containing the images\n    \"\"\"\n    identity_df = dino_features_df[dino_features_df['identity'] == identity]\n\n    n_images = len(identity_df)\n    n_cols = n_images\n    n_rows = (n_images + n_cols - 1) // n_cols\n\n    plt.figure(figsize=(3*n_cols, 5*n_rows))\n\n    for idx, (_, row) in enumerate(identity_df.iterrows()):\n        # Get similarities for this image with other images of same identity\n        image_idx = dino_features_df[dino_features_df['file_name'] == row['file_name']].index[0]\n        similarities = dinov2_similarities[image_idx]\n        \n        # Get max similarity with other images of same identity (excluding self)\n        same_identity_mask = (dino_features_df['identity'] == identity) & (dino_features_df['file_name'] != row['file_name'])\n        if same_identity_mask.any():\n            max_similarity = np.max(similarities[same_identity_mask])\n        else:\n            max_similarity = 0.0\n\n        # Plot image\n        plt.subplot(n_rows, n_cols, idx + 1)\n        img = plt.imread(dataset_path/row['file_path'])\n        plt.imshow(img)\n        plt.xticks([])\n        plt.yticks([])\n        \n        # Get name of most similar image\n        if same_identity_mask.any():\n            most_similar_idx = np.argmax(similarities[same_identity_mask])\n            most_similar_name = dino_features_df.loc[same_identity_mask, 'file_name'].iloc[most_similar_idx]\n            plt.title(f'Max similarity: {max_similarity:.3f}\\nwith {most_similar_name}')\n        else:\n            plt.title(f'Max similarity: {max_similarity:.3f}\\nNo other images')\n        plt.xlabel(row['file_name'])\n\n    plt.suptitle(f'Images for identity {identity}', fontsize=16)\n    plt.tight_layout()\n\n\nidentity = dino_features_df['identity'].iloc[0]\nplot_identity_similarities(identity, dino_features_df, dinov2_similarities, dataset_path)\n\n\n\n\n\n\n\n\n\ndinov2_similarities_df.loc[dinov2_similarities_df.index.str.startswith('1_'), dinov2_similarities_df.columns.str.startswith('1_')]\n\n\n\n\n\n\n\nid_and_image_name\n1_IMG_2532.JPEG\n1_IMG_2530.JPEG\n1_IMG_2531.JPEG\n1_IMG_2533.JPEG\n1_IMG_2534.JPEG\n\n\nid_and_image_name\n\n\n\n\n\n\n\n\n\n1_IMG_2532.JPEG\n1.000000\n0.813332\n0.879888\n0.850998\n0.813479\n\n\n1_IMG_2530.JPEG\n0.813332\n1.000000\n0.833461\n0.800902\n0.729356\n\n\n1_IMG_2531.JPEG\n0.879888\n0.833461\n1.000000\n0.834979\n0.795149\n\n\n1_IMG_2533.JPEG\n0.850998\n0.800902\n0.834979\n1.000000\n0.780088\n\n\n1_IMG_2534.JPEG\n0.813479\n0.729356\n0.795149\n0.780088\n1.000000\n\n\n\n\n\n\n\n\nn_images = 4\n\nimage_counts = dino_features_df.groupby('identity').file_name.count()\nidentities_with_n_images = image_counts[image_counts == n_images].index.tolist()\nintra_identity_similarities_path = artifacts_path / 'intra_identity_similarities' / f'n_images_{n_images}'\nintra_identity_similarities_path.mkdir(parents=True, exist_ok=True)\n\nfor identity in identities_with_n_images:\n    plot_identity_similarities(identity, dino_features_df, dinov2_similarities, dataset_path)\n    plt.savefig(intra_identity_similarities_path / f'identity_{identity}_similarities.png')\n    plt.close()\n    df = dinov2_similarities_df.loc[dinov2_similarities_df.index.str.startswith(f'{identity}_'), dinov2_similarities_df.columns.str.startswith(f'{identity}_')]\n    df.to_csv(intra_identity_similarities_path / f'identity_{identity}_similarities.csv')\n    \n    # Preview the similarity matrix for this identity\n    display.display(df.style.background_gradient(cmap='RdYlBu', vmin=-1, vmax=1)\n              .format(\"{:.3f}\")\n              .set_caption(f\"Similarity matrix for identity {identity}\"))\n\n\n\n\n\n\nTable 1: Similarity matrix for identity 38\n\n\n\n\n\nid_and_image_name\n38_IMG_2505.JPEG\n38_IMG_2502.JPEG\n38_IMG_2503.JPEG\n38_IMG_2501.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n38_IMG_2505.JPEG\n1.000\n0.739\n0.897\n0.812\n\n\n38_IMG_2502.JPEG\n0.739\n1.000\n0.771\n0.721\n\n\n38_IMG_2503.JPEG\n0.897\n0.771\n1.000\n0.821\n\n\n38_IMG_2501.JPEG\n0.812\n0.721\n0.821\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2: Similarity matrix for identity 121\n\n\n\n\n\nid_and_image_name\n121_IMG_3236.JPEG\n121_IMG_3235.JPEG\n121_IMG_3237.JPEG\n121_IMG_3238.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n121_IMG_3236.JPEG\n1.000\n0.842\n0.749\n0.849\n\n\n121_IMG_3235.JPEG\n0.842\n1.000\n0.892\n0.854\n\n\n121_IMG_3237.JPEG\n0.749\n0.892\n1.000\n0.796\n\n\n121_IMG_3238.JPEG\n0.849\n0.854\n0.796\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 3: Similarity matrix for identity 172\n\n\n\n\n\nid_and_image_name\n172_IMG_3359.JPEG\n172_IMG_3358.JPEG\n172_IMG_3356.JPEG\n172_IMG_3357.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n172_IMG_3359.JPEG\n1.000\n0.872\n0.779\n0.818\n\n\n172_IMG_3358.JPEG\n0.872\n1.000\n0.822\n0.830\n\n\n172_IMG_3356.JPEG\n0.779\n0.822\n1.000\n0.890\n\n\n172_IMG_3357.JPEG\n0.818\n0.830\n0.890\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 4: Similarity matrix for identity 190\n\n\n\n\n\nid_and_image_name\n190_IMG_3647.JPEG\n190_IMG_3649.JPEG\n190_IMG_3646.JPEG\n190_IMG_3648.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n190_IMG_3647.JPEG\n1.000\n0.838\n0.845\n0.773\n\n\n190_IMG_3649.JPEG\n0.838\n1.000\n0.828\n0.816\n\n\n190_IMG_3646.JPEG\n0.845\n0.828\n1.000\n0.780\n\n\n190_IMG_3648.JPEG\n0.773\n0.816\n0.780\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 5: Similarity matrix for identity 191\n\n\n\n\n\nid_and_image_name\n191_IMG_3663.JPEG\n191_IMG_3664.JPEG\n191_IMG_3665.JPEG\n191_IMG_3662.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n191_IMG_3663.JPEG\n1.000\n0.792\n0.728\n0.749\n\n\n191_IMG_3664.JPEG\n0.792\n1.000\n0.865\n0.784\n\n\n191_IMG_3665.JPEG\n0.728\n0.865\n1.000\n0.790\n\n\n191_IMG_3662.JPEG\n0.749\n0.784\n0.790\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 6: Similarity matrix for identity 195\n\n\n\n\n\nid_and_image_name\n195_IMG_3658.JPEG\n195_IMG_3657.JPEG\n195_IMG_3659.JPEG\n195_IMG_3660.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n195_IMG_3658.JPEG\n1.000\n0.822\n0.801\n0.834\n\n\n195_IMG_3657.JPEG\n0.822\n1.000\n0.815\n0.821\n\n\n195_IMG_3659.JPEG\n0.801\n0.815\n1.000\n0.830\n\n\n195_IMG_3660.JPEG\n0.834\n0.821\n0.830\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 7: Similarity matrix for identity 198\n\n\n\n\n\nid_and_image_name\n198_IMG_3613.JPEG\n198_IMG_3611.JPEG\n198_IMG_3612.JPEG\n198_IMG_3610.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n198_IMG_3613.JPEG\n1.000\n0.820\n0.857\n0.880\n\n\n198_IMG_3611.JPEG\n0.820\n1.000\n0.873\n0.863\n\n\n198_IMG_3612.JPEG\n0.857\n0.873\n1.000\n0.818\n\n\n198_IMG_3610.JPEG\n0.880\n0.863\n0.818\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 8: Similarity matrix for identity 201\n\n\n\n\n\nid_and_image_name\n201_IMG_3623.JPEG\n201_IMG_3624.JPEG\n201_IMG_3622.JPEG\n201_IMG_3625.JPEG\n\n\nid_and_image_name\n \n \n \n \n\n\n\n\n201_IMG_3623.JPEG\n1.000\n0.962\n0.915\n0.885\n\n\n201_IMG_3624.JPEG\n0.962\n1.000\n0.940\n0.873\n\n\n201_IMG_3622.JPEG\n0.915\n0.940\n1.000\n0.850\n\n\n201_IMG_3625.JPEG\n0.885\n0.873\n0.850\n1.000\n\n\n\n\n\n\n\n\n\nn_images = 5\n\nimage_counts = dino_features_df.groupby('identity').file_name.count()\nidentities_with_n_images = image_counts[image_counts == n_images].index.tolist()\nintra_identity_similarities_path = artifacts_path / 'intra_identity_similarities' / f'n_images_{n_images}'\nintra_identity_similarities_path.mkdir(parents=True, exist_ok=True)\n\nfor identity in identities_with_n_images:\n    plot_identity_similarities(identity, dino_features_df, dinov2_similarities, dataset_path)\n    plt.savefig(intra_identity_similarities_path / f'identity_{identity}_similarities.png')\n    plt.close()\n    df = dinov2_similarities_df.loc[dinov2_similarities_df.index.str.startswith(f'{identity}_'), dinov2_similarities_df.columns.str.startswith(f'{identity}_')]\n    df.to_csv(intra_identity_similarities_path / f'identity_{identity}_similarities.csv')\n    \n    # Preview the similarity matrix for this identity\n    display.display(df.style.background_gradient(cmap='RdYlBu', vmin=-1, vmax=1)\n              .format(\"{:.3f}\")\n              .set_caption(f\"Similarity matrix for identity {identity}\"))\n\n\n\n\n\n\nTable 9: Similarity matrix for identity 1\n\n\n\n\n\nid_and_image_name\n1_IMG_2532.JPEG\n1_IMG_2530.JPEG\n1_IMG_2531.JPEG\n1_IMG_2533.JPEG\n1_IMG_2534.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n1_IMG_2532.JPEG\n1.000\n0.813\n0.880\n0.851\n0.813\n\n\n1_IMG_2530.JPEG\n0.813\n1.000\n0.833\n0.801\n0.729\n\n\n1_IMG_2531.JPEG\n0.880\n0.833\n1.000\n0.835\n0.795\n\n\n1_IMG_2533.JPEG\n0.851\n0.801\n0.835\n1.000\n0.780\n\n\n1_IMG_2534.JPEG\n0.813\n0.729\n0.795\n0.780\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 10: Similarity matrix for identity 2\n\n\n\n\n\nid_and_image_name\n2_IMG_2524.JPEG\n2_IMG_2527.JPEG\n2_IMG_2526.JPEG\n2_IMG_2525.JPEG\n2_IMG_2528.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n2_IMG_2524.JPEG\n1.000\n0.844\n0.788\n0.872\n0.783\n\n\n2_IMG_2527.JPEG\n0.844\n1.000\n0.848\n0.858\n0.824\n\n\n2_IMG_2526.JPEG\n0.788\n0.848\n1.000\n0.827\n0.773\n\n\n2_IMG_2525.JPEG\n0.872\n0.858\n0.827\n1.000\n0.788\n\n\n2_IMG_2528.JPEG\n0.783\n0.824\n0.773\n0.788\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 11: Similarity matrix for identity 3\n\n\n\n\n\nid_and_image_name\n3_IMG_2538.JPEG\n3_IMG_2539.JPEG\n3_IMG_2541.JPEG\n3_IMG_2540.JPEG\n3_IMG_2542.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n3_IMG_2538.JPEG\n1.000\n0.789\n0.829\n0.870\n0.879\n\n\n3_IMG_2539.JPEG\n0.789\n1.000\n0.769\n0.823\n0.760\n\n\n3_IMG_2541.JPEG\n0.829\n0.769\n1.000\n0.781\n0.825\n\n\n3_IMG_2540.JPEG\n0.870\n0.823\n0.781\n1.000\n0.833\n\n\n3_IMG_2542.JPEG\n0.879\n0.760\n0.825\n0.833\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 12: Similarity matrix for identity 4\n\n\n\n\n\nid_and_image_name\n4_IMG_2546.JPEG\n4_IMG_2544.JPEG\n4_IMG_2547.JPEG\n4_IMG_2548.JPEG\n4_IMG_2545.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n4_IMG_2546.JPEG\n1.000\n0.728\n0.705\n0.817\n0.739\n\n\n4_IMG_2544.JPEG\n0.728\n1.000\n0.765\n0.786\n0.738\n\n\n4_IMG_2547.JPEG\n0.705\n0.765\n1.000\n0.830\n0.788\n\n\n4_IMG_2548.JPEG\n0.817\n0.786\n0.830\n1.000\n0.807\n\n\n4_IMG_2545.JPEG\n0.739\n0.738\n0.788\n0.807\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 13: Similarity matrix for identity 5\n\n\n\n\n\nid_and_image_name\n5_IMG_2569.JPEG\n5_IMG_2572.JPEG\n5_IMG_2573.JPEG\n5_IMG_2571.JPEG\n5_IMG_2570.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n5_IMG_2569.JPEG\n1.000\n0.604\n0.794\n0.629\n0.854\n\n\n5_IMG_2572.JPEG\n0.604\n1.000\n0.697\n0.784\n0.733\n\n\n5_IMG_2573.JPEG\n0.794\n0.697\n1.000\n0.713\n0.865\n\n\n5_IMG_2571.JPEG\n0.629\n0.784\n0.713\n1.000\n0.763\n\n\n5_IMG_2570.JPEG\n0.854\n0.733\n0.865\n0.763\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 14: Similarity matrix for identity 6\n\n\n\n\n\nid_and_image_name\n6_IMG_2566.JPEG\n6_IMG_2567.JPEG\n6_IMG_2564.JPEG\n6_IMG_2565.JPEG\n6_IMG_2563.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n6_IMG_2566.JPEG\n1.000\n0.882\n0.867\n0.938\n0.906\n\n\n6_IMG_2567.JPEG\n0.882\n1.000\n0.895\n0.899\n0.899\n\n\n6_IMG_2564.JPEG\n0.867\n0.895\n1.000\n0.891\n0.926\n\n\n6_IMG_2565.JPEG\n0.938\n0.899\n0.891\n1.000\n0.912\n\n\n6_IMG_2563.JPEG\n0.906\n0.899\n0.926\n0.912\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 15: Similarity matrix for identity 7\n\n\n\n\n\nid_and_image_name\n7_IMG_2588.JPEG\n7_IMG_2590.JPEG\n7_IMG_2592.JPEG\n7_IMG_2591.JPEG\n7_IMG_2589.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n7_IMG_2588.JPEG\n1.000\n0.885\n0.859\n0.825\n0.874\n\n\n7_IMG_2590.JPEG\n0.885\n1.000\n0.889\n0.842\n0.871\n\n\n7_IMG_2592.JPEG\n0.859\n0.889\n1.000\n0.862\n0.867\n\n\n7_IMG_2591.JPEG\n0.825\n0.842\n0.862\n1.000\n0.860\n\n\n7_IMG_2589.JPEG\n0.874\n0.871\n0.867\n0.860\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 16: Similarity matrix for identity 8\n\n\n\n\n\nid_and_image_name\n8_IMG_2586.JPEG\n8_IMG_2585.JPEG\n8_IMG_2582.JPEG\n8_IMG_2584.JPEG\n8_IMG_2583.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n8_IMG_2586.JPEG\n1.000\n0.944\n0.764\n0.886\n0.795\n\n\n8_IMG_2585.JPEG\n0.944\n1.000\n0.755\n0.895\n0.762\n\n\n8_IMG_2582.JPEG\n0.764\n0.755\n1.000\n0.842\n0.878\n\n\n8_IMG_2584.JPEG\n0.886\n0.895\n0.842\n1.000\n0.841\n\n\n8_IMG_2583.JPEG\n0.795\n0.762\n0.878\n0.841\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 17: Similarity matrix for identity 9\n\n\n\n\n\nid_and_image_name\n9_IMG_2561.JPEG\n9_IMG_2557.JPEG\n9_IMG_2559.JPEG\n9_IMG_2560.JPEG\n9_IMG_2558.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n9_IMG_2561.JPEG\n1.000\n0.684\n0.697\n0.812\n0.779\n\n\n9_IMG_2557.JPEG\n0.684\n1.000\n0.809\n0.730\n0.877\n\n\n9_IMG_2559.JPEG\n0.697\n0.809\n1.000\n0.821\n0.818\n\n\n9_IMG_2560.JPEG\n0.812\n0.730\n0.821\n1.000\n0.821\n\n\n9_IMG_2558.JPEG\n0.779\n0.877\n0.818\n0.821\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 18: Similarity matrix for identity 13\n\n\n\n\n\nid_and_image_name\n13_IMG_2600.JPEG\n13_IMG_2602.JPEG\n13_IMG_2599.JPEG\n13_IMG_2601.JPEG\n13_IMG_2603.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n13_IMG_2600.JPEG\n1.000\n0.828\n0.869\n0.844\n0.838\n\n\n13_IMG_2602.JPEG\n0.828\n1.000\n0.813\n0.838\n0.905\n\n\n13_IMG_2599.JPEG\n0.869\n0.813\n1.000\n0.819\n0.805\n\n\n13_IMG_2601.JPEG\n0.844\n0.838\n0.819\n1.000\n0.856\n\n\n13_IMG_2603.JPEG\n0.838\n0.905\n0.805\n0.856\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 19: Similarity matrix for identity 14\n\n\n\n\n\nid_and_image_name\n14_IMG_2613.JPEG\n14_IMG_2612.JPEG\n14_IMG_2614.JPEG\n14_IMG_2615.JPEG\n14_IMG_2611.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n14_IMG_2613.JPEG\n1.000\n0.857\n0.924\n0.872\n0.920\n\n\n14_IMG_2612.JPEG\n0.857\n1.000\n0.843\n0.806\n0.861\n\n\n14_IMG_2614.JPEG\n0.924\n0.843\n1.000\n0.878\n0.899\n\n\n14_IMG_2615.JPEG\n0.872\n0.806\n0.878\n1.000\n0.871\n\n\n14_IMG_2611.JPEG\n0.920\n0.861\n0.899\n0.871\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 20: Similarity matrix for identity 15\n\n\n\n\n\nid_and_image_name\n15_IMG_2641.JPEG\n15_IMG_2639.JPEG\n15_IMG_2638.JPEG\n15_IMG_2637.JPEG\n15_IMG_2640.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n15_IMG_2641.JPEG\n1.000\n0.875\n0.843\n0.916\n0.873\n\n\n15_IMG_2639.JPEG\n0.875\n1.000\n0.918\n0.862\n0.869\n\n\n15_IMG_2638.JPEG\n0.843\n0.918\n1.000\n0.830\n0.833\n\n\n15_IMG_2637.JPEG\n0.916\n0.862\n0.830\n1.000\n0.833\n\n\n15_IMG_2640.JPEG\n0.873\n0.869\n0.833\n0.833\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 21: Similarity matrix for identity 16\n\n\n\n\n\nid_and_image_name\n16_IMG_2655.JPEG\n16_IMG_2660.JPEG\n16_IMG_2656.JPEG\n16_IMG_2658.JPEG\n16_IMG_2659.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n16_IMG_2655.JPEG\n1.000\n0.809\n0.872\n0.857\n0.881\n\n\n16_IMG_2660.JPEG\n0.809\n1.000\n0.804\n0.805\n0.822\n\n\n16_IMG_2656.JPEG\n0.872\n0.804\n1.000\n0.825\n0.883\n\n\n16_IMG_2658.JPEG\n0.857\n0.805\n0.825\n1.000\n0.863\n\n\n16_IMG_2659.JPEG\n0.881\n0.822\n0.883\n0.863\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 22: Similarity matrix for identity 18\n\n\n\n\n\nid_and_image_name\n18_IMG_2607.JPEG\n18_IMG_2609.JPEG\n18_IMG_2606.JPEG\n18_IMG_2605.JPEG\n18_IMG_2608.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n18_IMG_2607.JPEG\n1.000\n0.749\n0.805\n0.827\n0.805\n\n\n18_IMG_2609.JPEG\n0.749\n1.000\n0.824\n0.811\n0.886\n\n\n18_IMG_2606.JPEG\n0.805\n0.824\n1.000\n0.857\n0.885\n\n\n18_IMG_2605.JPEG\n0.827\n0.811\n0.857\n1.000\n0.881\n\n\n18_IMG_2608.JPEG\n0.805\n0.886\n0.885\n0.881\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 23: Similarity matrix for identity 19\n\n\n\n\n\nid_and_image_name\n19_IMG_2646.JPEG\n19_IMG_2645.JPEG\n19_IMG_2644.JPEG\n19_IMG_2643.JPEG\n19_IMG_2647.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n19_IMG_2646.JPEG\n1.000\n0.899\n0.748\n0.763\n0.767\n\n\n19_IMG_2645.JPEG\n0.899\n1.000\n0.769\n0.743\n0.756\n\n\n19_IMG_2644.JPEG\n0.748\n0.769\n1.000\n0.702\n0.688\n\n\n19_IMG_2643.JPEG\n0.763\n0.743\n0.702\n1.000\n0.923\n\n\n19_IMG_2647.JPEG\n0.767\n0.756\n0.688\n0.923\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 24: Similarity matrix for identity 20\n\n\n\n\n\nid_and_image_name\n20_IMG_2619.JPEG\n20_IMG_2621.JPEG\n20_IMG_2618.JPEG\n20_IMG_2620.JPEG\n20_IMG_2617.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n20_IMG_2619.JPEG\n1.000\n0.913\n0.804\n0.907\n0.833\n\n\n20_IMG_2621.JPEG\n0.913\n1.000\n0.840\n0.916\n0.876\n\n\n20_IMG_2618.JPEG\n0.804\n0.840\n1.000\n0.794\n0.917\n\n\n20_IMG_2620.JPEG\n0.907\n0.916\n0.794\n1.000\n0.831\n\n\n20_IMG_2617.JPEG\n0.833\n0.876\n0.917\n0.831\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 25: Similarity matrix for identity 21\n\n\n\n\n\nid_and_image_name\n21_IMG_2687.JPEG\n21_IMG_2688.JPEG\n21_IMG_2686.JPEG\n21_IMG_2690.JPEG\n21_IMG_2689.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n21_IMG_2687.JPEG\n1.000\n0.860\n0.958\n0.898\n0.898\n\n\n21_IMG_2688.JPEG\n0.860\n1.000\n0.886\n0.837\n0.824\n\n\n21_IMG_2686.JPEG\n0.958\n0.886\n1.000\n0.881\n0.883\n\n\n21_IMG_2690.JPEG\n0.898\n0.837\n0.881\n1.000\n0.938\n\n\n21_IMG_2689.JPEG\n0.898\n0.824\n0.883\n0.938\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 26: Similarity matrix for identity 23\n\n\n\n\n\nid_and_image_name\n23_IMG_2627.JPEG\n23_IMG_2624.JPEG\n23_IMG_2623.JPEG\n23_IMG_2626.JPEG\n23_IMG_2625.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n23_IMG_2627.JPEG\n1.000\n0.745\n0.847\n0.883\n0.878\n\n\n23_IMG_2624.JPEG\n0.745\n1.000\n0.818\n0.775\n0.786\n\n\n23_IMG_2623.JPEG\n0.847\n0.818\n1.000\n0.869\n0.816\n\n\n23_IMG_2626.JPEG\n0.883\n0.775\n0.869\n1.000\n0.807\n\n\n23_IMG_2625.JPEG\n0.878\n0.786\n0.816\n0.807\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 27: Similarity matrix for identity 24\n\n\n\n\n\nid_and_image_name\n24_IMG_2653.JPEG\n24_IMG_2652.JPEG\n24_IMG_2651.JPEG\n24_IMG_2649.JPEG\n24_IMG_2650.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n24_IMG_2653.JPEG\n1.000\n0.823\n0.772\n0.730\n0.815\n\n\n24_IMG_2652.JPEG\n0.823\n1.000\n0.792\n0.729\n0.832\n\n\n24_IMG_2651.JPEG\n0.772\n0.792\n1.000\n0.845\n0.851\n\n\n24_IMG_2649.JPEG\n0.730\n0.729\n0.845\n1.000\n0.871\n\n\n24_IMG_2650.JPEG\n0.815\n0.832\n0.851\n0.871\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 28: Similarity matrix for identity 26\n\n\n\n\n\nid_and_image_name\n26_IMG_2694.JPEG\n26_IMG_2696.JPEG\n26_IMG_2695.JPEG\n26_IMG_2692.JPEG\n26_IMG_2693.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n26_IMG_2694.JPEG\n1.000\n0.863\n0.823\n0.862\n0.897\n\n\n26_IMG_2696.JPEG\n0.863\n1.000\n0.839\n0.860\n0.889\n\n\n26_IMG_2695.JPEG\n0.823\n0.839\n1.000\n0.839\n0.864\n\n\n26_IMG_2692.JPEG\n0.862\n0.860\n0.839\n1.000\n0.891\n\n\n26_IMG_2693.JPEG\n0.897\n0.889\n0.864\n0.891\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 29: Similarity matrix for identity 27\n\n\n\n\n\nid_and_image_name\n27_IMG_2451.JPEG\n27_IMG_2452.JPEG\n27_IMG_2450.JPEG\n27_IMG_2453.JPEG\n27_IMG_2449.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n27_IMG_2451.JPEG\n1.000\n0.827\n0.821\n0.829\n0.864\n\n\n27_IMG_2452.JPEG\n0.827\n1.000\n0.817\n0.760\n0.830\n\n\n27_IMG_2450.JPEG\n0.821\n0.817\n1.000\n0.752\n0.884\n\n\n27_IMG_2453.JPEG\n0.829\n0.760\n0.752\n1.000\n0.789\n\n\n27_IMG_2449.JPEG\n0.864\n0.830\n0.884\n0.789\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 30: Similarity matrix for identity 29\n\n\n\n\n\nid_and_image_name\n29_IMG_2498.JPEG\n29_IMG_2496.JPEG\n29_IMG_2495.JPEG\n29_IMG_2499.JPEG\n29_IMG_2497.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n29_IMG_2498.JPEG\n1.000\n0.719\n0.702\n0.893\n0.821\n\n\n29_IMG_2496.JPEG\n0.719\n1.000\n0.856\n0.809\n0.797\n\n\n29_IMG_2495.JPEG\n0.702\n0.856\n1.000\n0.782\n0.795\n\n\n29_IMG_2499.JPEG\n0.893\n0.809\n0.782\n1.000\n0.876\n\n\n29_IMG_2497.JPEG\n0.821\n0.797\n0.795\n0.876\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 31: Similarity matrix for identity 30\n\n\n\n\n\nid_and_image_name\n30_IMG_2484.JPEG\n30_IMG_2481.JPEG\n30_IMG_2482.JPEG\n30_IMG_2480.JPEG\n30_IMG_2483.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n30_IMG_2484.JPEG\n1.000\n0.870\n0.861\n0.891\n0.810\n\n\n30_IMG_2481.JPEG\n0.870\n1.000\n0.897\n0.923\n0.851\n\n\n30_IMG_2482.JPEG\n0.861\n0.897\n1.000\n0.935\n0.898\n\n\n30_IMG_2480.JPEG\n0.891\n0.923\n0.935\n1.000\n0.863\n\n\n30_IMG_2483.JPEG\n0.810\n0.851\n0.898\n0.863\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 32: Similarity matrix for identity 32\n\n\n\n\n\nid_and_image_name\n32_IMG_2474.JPEG\n32_IMG_2475.JPEG\n32_IMG_2477.JPEG\n32_IMG_2478.JPEG\n32_IMG_2476.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n32_IMG_2474.JPEG\n1.000\n0.869\n0.851\n0.900\n0.879\n\n\n32_IMG_2475.JPEG\n0.869\n1.000\n0.873\n0.887\n0.889\n\n\n32_IMG_2477.JPEG\n0.851\n0.873\n1.000\n0.872\n0.916\n\n\n32_IMG_2478.JPEG\n0.900\n0.887\n0.872\n1.000\n0.898\n\n\n32_IMG_2476.JPEG\n0.879\n0.889\n0.916\n0.898\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 33: Similarity matrix for identity 36\n\n\n\n\n\nid_and_image_name\n36_IMG_2465.JPEG\n36_IMG_2463.JPEG\n36_IMG_2466.JPEG\n36_IMG_2462.JPEG\n36_IMG_2464.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n36_IMG_2465.JPEG\n1.000\n0.823\n0.813\n0.788\n0.899\n\n\n36_IMG_2463.JPEG\n0.823\n1.000\n0.731\n0.840\n0.863\n\n\n36_IMG_2466.JPEG\n0.813\n0.731\n1.000\n0.833\n0.839\n\n\n36_IMG_2462.JPEG\n0.788\n0.840\n0.833\n1.000\n0.837\n\n\n36_IMG_2464.JPEG\n0.899\n0.863\n0.839\n0.837\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 34: Similarity matrix for identity 37\n\n\n\n\n\nid_and_image_name\n37_IMG_2472.JPEG\n37_IMG_2470.JPEG\n37_IMG_2471.JPEG\n37_IMG_2468.JPEG\n37_IMG_2469.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n37_IMG_2472.JPEG\n1.000\n0.591\n0.711\n0.620\n0.541\n\n\n37_IMG_2470.JPEG\n0.591\n1.000\n0.817\n0.885\n0.880\n\n\n37_IMG_2471.JPEG\n0.711\n0.817\n1.000\n0.847\n0.795\n\n\n37_IMG_2468.JPEG\n0.620\n0.885\n0.847\n1.000\n0.866\n\n\n37_IMG_2469.JPEG\n0.541\n0.880\n0.795\n0.866\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 35: Similarity matrix for identity 40\n\n\n\n\n\nid_and_image_name\n40_IMG_2375.JPEG\n40_IMG_2377.JPEG\n40_IMG_2376.JPEG\n40_IMG_2373.JPEG\n40_IMG_2374.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n40_IMG_2375.JPEG\n1.000\n0.777\n0.877\n0.793\n0.882\n\n\n40_IMG_2377.JPEG\n0.777\n1.000\n0.777\n0.670\n0.809\n\n\n40_IMG_2376.JPEG\n0.877\n0.777\n1.000\n0.801\n0.935\n\n\n40_IMG_2373.JPEG\n0.793\n0.670\n0.801\n1.000\n0.787\n\n\n40_IMG_2374.JPEG\n0.882\n0.809\n0.935\n0.787\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 36: Similarity matrix for identity 43\n\n\n\n\n\nid_and_image_name\n43_IMG_2390.JPEG\n43_IMG_2387.JPEG\n43_IMG_2389.JPEG\n43_IMG_2388.JPEG\n43_IMG_2386.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n43_IMG_2390.JPEG\n1.000\n0.834\n0.867\n0.828\n0.859\n\n\n43_IMG_2387.JPEG\n0.834\n1.000\n0.795\n0.850\n0.847\n\n\n43_IMG_2389.JPEG\n0.867\n0.795\n1.000\n0.840\n0.877\n\n\n43_IMG_2388.JPEG\n0.828\n0.850\n0.840\n1.000\n0.844\n\n\n43_IMG_2386.JPEG\n0.859\n0.847\n0.877\n0.844\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 37: Similarity matrix for identity 44\n\n\n\n\n\nid_and_image_name\n44_IMG_2338.JPEG\n44_IMG_2336.JPEG\n44_IMG_2334.JPEG\n44_IMG_2335.JPEG\n44_IMG_2337.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n44_IMG_2338.JPEG\n1.000\n0.668\n0.663\n0.673\n0.612\n\n\n44_IMG_2336.JPEG\n0.668\n1.000\n0.835\n0.850\n0.867\n\n\n44_IMG_2334.JPEG\n0.663\n0.835\n1.000\n0.816\n0.830\n\n\n44_IMG_2335.JPEG\n0.673\n0.850\n0.816\n1.000\n0.811\n\n\n44_IMG_2337.JPEG\n0.612\n0.867\n0.830\n0.811\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 38: Similarity matrix for identity 47\n\n\n\n\n\nid_and_image_name\n47_IMG_2358.JPEG\n47_IMG_2355.JPEG\n47_IMG_2354.JPEG\n47_IMG_2356.JPEG\n47_IMG_2357.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n47_IMG_2358.JPEG\n1.000\n0.683\n0.696\n0.668\n0.788\n\n\n47_IMG_2355.JPEG\n0.683\n1.000\n0.824\n0.661\n0.762\n\n\n47_IMG_2354.JPEG\n0.696\n0.824\n1.000\n0.630\n0.826\n\n\n47_IMG_2356.JPEG\n0.668\n0.661\n0.630\n1.000\n0.720\n\n\n47_IMG_2357.JPEG\n0.788\n0.762\n0.826\n0.720\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 39: Similarity matrix for identity 48\n\n\n\n\n\nid_and_image_name\n48_IMG_2417.JPEG\n48_IMG_2415.JPEG\n48_IMG_2416.JPEG\n48_IMG_2413.JPEG\n48_IMG_2414.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n48_IMG_2417.JPEG\n1.000\n0.875\n0.894\n0.890\n0.824\n\n\n48_IMG_2415.JPEG\n0.875\n1.000\n0.834\n0.889\n0.855\n\n\n48_IMG_2416.JPEG\n0.894\n0.834\n1.000\n0.877\n0.736\n\n\n48_IMG_2413.JPEG\n0.890\n0.889\n0.877\n1.000\n0.851\n\n\n48_IMG_2414.JPEG\n0.824\n0.855\n0.736\n0.851\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 40: Similarity matrix for identity 52\n\n\n\n\n\nid_and_image_name\n52_IMG_2432.JPEG\n52_IMG_2434.JPEG\n52_IMG_2435.JPEG\n52_IMG_2433.JPEG\n52_IMG_2436.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n52_IMG_2432.JPEG\n1.000\n0.848\n0.827\n0.866\n0.842\n\n\n52_IMG_2434.JPEG\n0.848\n1.000\n0.822\n0.887\n0.850\n\n\n52_IMG_2435.JPEG\n0.827\n0.822\n1.000\n0.834\n0.813\n\n\n52_IMG_2433.JPEG\n0.866\n0.887\n0.834\n1.000\n0.842\n\n\n52_IMG_2436.JPEG\n0.842\n0.850\n0.813\n0.842\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 41: Similarity matrix for identity 53\n\n\n\n\n\nid_and_image_name\n53_IMG_2371.JPEG\n53_IMG_2368.JPEG\n53_IMG_2367.JPEG\n53_IMG_2370.JPEG\n53_IMG_2369.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n53_IMG_2371.JPEG\n1.000\n0.861\n0.852\n0.883\n0.844\n\n\n53_IMG_2368.JPEG\n0.861\n1.000\n0.830\n0.851\n0.893\n\n\n53_IMG_2367.JPEG\n0.852\n0.830\n1.000\n0.866\n0.804\n\n\n53_IMG_2370.JPEG\n0.883\n0.851\n0.866\n1.000\n0.840\n\n\n53_IMG_2369.JPEG\n0.844\n0.893\n0.804\n0.840\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 42: Similarity matrix for identity 55\n\n\n\n\n\nid_and_image_name\n55_IMG_2312.JPEG\n55_IMG_2313.JPEG\n55_IMG_2310.JPEG\n55_IMG_2311.JPEG\n55_IMG_2309.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n55_IMG_2312.JPEG\n1.000\n0.771\n0.884\n0.867\n0.848\n\n\n55_IMG_2313.JPEG\n0.771\n1.000\n0.798\n0.752\n0.754\n\n\n55_IMG_2310.JPEG\n0.884\n0.798\n1.000\n0.880\n0.878\n\n\n55_IMG_2311.JPEG\n0.867\n0.752\n0.880\n1.000\n0.870\n\n\n55_IMG_2309.JPEG\n0.848\n0.754\n0.878\n0.870\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 43: Similarity matrix for identity 56\n\n\n\n\n\nid_and_image_name\n56_IMG_2428.JPEG\n56_IMG_2426.JPEG\n56_IMG_2427.JPEG\n56_IMG_2429.JPEG\n56_IMG_2430.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n56_IMG_2428.JPEG\n1.000\n0.815\n0.859\n0.798\n0.788\n\n\n56_IMG_2426.JPEG\n0.815\n1.000\n0.853\n0.844\n0.825\n\n\n56_IMG_2427.JPEG\n0.859\n0.853\n1.000\n0.850\n0.827\n\n\n56_IMG_2429.JPEG\n0.798\n0.844\n0.850\n1.000\n0.767\n\n\n56_IMG_2430.JPEG\n0.788\n0.825\n0.827\n0.767\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 44: Similarity matrix for identity 57\n\n\n\n\n\nid_and_image_name\n57_IMG_2351.JPEG\n57_IMG_2352.JPEG\n57_IMG_2350.JPEG\n57_IMG_2349.JPEG\n57_IMG_2348.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n57_IMG_2351.JPEG\n1.000\n0.273\n0.846\n0.830\n0.860\n\n\n57_IMG_2352.JPEG\n0.273\n1.000\n0.365\n0.300\n0.303\n\n\n57_IMG_2350.JPEG\n0.846\n0.365\n1.000\n0.828\n0.872\n\n\n57_IMG_2349.JPEG\n0.830\n0.300\n0.828\n1.000\n0.831\n\n\n57_IMG_2348.JPEG\n0.860\n0.303\n0.872\n0.831\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 45: Similarity matrix for identity 59\n\n\n\n\n\nid_and_image_name\n59_IMG_2721.JPEG\n59_IMG_2720.JPEG\n59_IMG_2719.JPEG\n59_IMG_2722.JPEG\n59_IMG_2718.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n59_IMG_2721.JPEG\n1.000\n0.544\n0.801\n0.735\n0.805\n\n\n59_IMG_2720.JPEG\n0.544\n1.000\n0.648\n0.705\n0.585\n\n\n59_IMG_2719.JPEG\n0.801\n0.648\n1.000\n0.824\n0.811\n\n\n59_IMG_2722.JPEG\n0.735\n0.705\n0.824\n1.000\n0.800\n\n\n59_IMG_2718.JPEG\n0.805\n0.585\n0.811\n0.800\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 46: Similarity matrix for identity 61\n\n\n\n\n\nid_and_image_name\n61_IMG_2714.JPEG\n61_IMG_2713.JPEG\n61_IMG_2712.JPEG\n61_IMG_2715.JPEG\n61_IMG_2716.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n61_IMG_2714.JPEG\n1.000\n0.830\n0.863\n0.865\n0.867\n\n\n61_IMG_2713.JPEG\n0.830\n1.000\n0.945\n0.879\n0.860\n\n\n61_IMG_2712.JPEG\n0.863\n0.945\n1.000\n0.869\n0.895\n\n\n61_IMG_2715.JPEG\n0.865\n0.879\n0.869\n1.000\n0.867\n\n\n61_IMG_2716.JPEG\n0.867\n0.860\n0.895\n0.867\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 47: Similarity matrix for identity 63\n\n\n\n\n\nid_and_image_name\n63_IMG_2741.JPEG\n63_IMG_2743.JPEG\n63_IMG_2742.JPEG\n63_IMG_2745.JPEG\n63_IMG_2744.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n63_IMG_2741.JPEG\n1.000\n0.624\n0.843\n0.775\n0.684\n\n\n63_IMG_2743.JPEG\n0.624\n1.000\n0.668\n0.746\n0.793\n\n\n63_IMG_2742.JPEG\n0.843\n0.668\n1.000\n0.769\n0.753\n\n\n63_IMG_2745.JPEG\n0.775\n0.746\n0.769\n1.000\n0.785\n\n\n63_IMG_2744.JPEG\n0.684\n0.793\n0.753\n0.785\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 48: Similarity matrix for identity 65\n\n\n\n\n\nid_and_image_name\n65_IMG_2729.JPEG\n65_IMG_2727.JPEG\n65_IMG_2726.JPEG\n65_IMG_2725.JPEG\n65_IMG_2728.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n65_IMG_2729.JPEG\n1.000\n0.837\n0.859\n0.865\n0.858\n\n\n65_IMG_2727.JPEG\n0.837\n1.000\n0.877\n0.843\n0.876\n\n\n65_IMG_2726.JPEG\n0.859\n0.877\n1.000\n0.897\n0.827\n\n\n65_IMG_2725.JPEG\n0.865\n0.843\n0.897\n1.000\n0.841\n\n\n65_IMG_2728.JPEG\n0.858\n0.876\n0.827\n0.841\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 49: Similarity matrix for identity 81\n\n\n\n\n\nid_and_image_name\n81_IMG_2884.JPEG\n81_IMG_2880.JPEG\n81_IMG_2881.JPEG\n81_IMG_2883.JPEG\n81_IMG_2882.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n81_IMG_2884.JPEG\n1.000\n0.647\n0.883\n0.854\n0.849\n\n\n81_IMG_2880.JPEG\n0.647\n1.000\n0.746\n0.673\n0.679\n\n\n81_IMG_2881.JPEG\n0.883\n0.746\n1.000\n0.852\n0.896\n\n\n81_IMG_2883.JPEG\n0.854\n0.673\n0.852\n1.000\n0.830\n\n\n81_IMG_2882.JPEG\n0.849\n0.679\n0.896\n0.830\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 50: Similarity matrix for identity 82\n\n\n\n\n\nid_and_image_name\n82_IMG_2869.JPEG\n82_IMG_2871.JPEG\n82_IMG_2868.JPEG\n82_IMG_2870.JPEG\n82_IMG_2872.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n82_IMG_2869.JPEG\n1.000\n0.762\n0.813\n0.753\n0.776\n\n\n82_IMG_2871.JPEG\n0.762\n1.000\n0.804\n0.854\n0.832\n\n\n82_IMG_2868.JPEG\n0.813\n0.804\n1.000\n0.788\n0.855\n\n\n82_IMG_2870.JPEG\n0.753\n0.854\n0.788\n1.000\n0.805\n\n\n82_IMG_2872.JPEG\n0.776\n0.832\n0.855\n0.805\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 51: Similarity matrix for identity 85\n\n\n\n\n\nid_and_image_name\n85_IMG_2874.JPEG\n85_IMG_2878.JPEG\n85_IMG_2876.JPEG\n85_IMG_2877.JPEG\n85_IMG_2875.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n85_IMG_2874.JPEG\n1.000\n0.701\n0.719\n0.684\n0.767\n\n\n85_IMG_2878.JPEG\n0.701\n1.000\n0.717\n0.808\n0.670\n\n\n85_IMG_2876.JPEG\n0.719\n0.717\n1.000\n0.741\n0.696\n\n\n85_IMG_2877.JPEG\n0.684\n0.808\n0.741\n1.000\n0.610\n\n\n85_IMG_2875.JPEG\n0.767\n0.670\n0.696\n0.610\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 52: Similarity matrix for identity 87\n\n\n\n\n\nid_and_image_name\n87_IMG_2827.JPEG\n87_IMG_2824.JPEG\n87_IMG_2826.JPEG\n87_IMG_2828.JPEG\n87_IMG_2825.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n87_IMG_2827.JPEG\n1.000\n0.596\n0.595\n0.627\n0.661\n\n\n87_IMG_2824.JPEG\n0.596\n1.000\n0.728\n0.759\n0.659\n\n\n87_IMG_2826.JPEG\n0.595\n0.728\n1.000\n0.819\n0.833\n\n\n87_IMG_2828.JPEG\n0.627\n0.759\n0.819\n1.000\n0.728\n\n\n87_IMG_2825.JPEG\n0.661\n0.659\n0.833\n0.728\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 53: Similarity matrix for identity 88\n\n\n\n\n\nid_and_image_name\n88_IMG_2834.JPEG\n88_IMG_2832.JPEG\n88_IMG_2833.JPEG\n88_IMG_2831.JPEG\n88_IMG_2830.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n88_IMG_2834.JPEG\n1.000\n0.815\n0.829\n0.851\n0.791\n\n\n88_IMG_2832.JPEG\n0.815\n1.000\n0.889\n0.810\n0.830\n\n\n88_IMG_2833.JPEG\n0.829\n0.889\n1.000\n0.778\n0.807\n\n\n88_IMG_2831.JPEG\n0.851\n0.810\n0.778\n1.000\n0.733\n\n\n88_IMG_2830.JPEG\n0.791\n0.830\n0.807\n0.733\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 54: Similarity matrix for identity 101\n\n\n\n\n\nid_and_image_name\n101_IMG_3572.JPEG\n101_IMG_3571.JPEG\n101_IMG_3570.JPEG\n101_IMG_3569.JPEG\n101_IMG_3568.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n101_IMG_3572.JPEG\n1.000\n0.947\n0.911\n0.628\n0.637\n\n\n101_IMG_3571.JPEG\n0.947\n1.000\n0.899\n0.625\n0.638\n\n\n101_IMG_3570.JPEG\n0.911\n0.899\n1.000\n0.684\n0.693\n\n\n101_IMG_3569.JPEG\n0.628\n0.625\n0.684\n1.000\n0.786\n\n\n101_IMG_3568.JPEG\n0.637\n0.638\n0.693\n0.786\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 55: Similarity matrix for identity 103\n\n\n\n\n\nid_and_image_name\n103_IMG_3076.JPEG\n103_IMG_3077.JPEG\n103_IMG_3075.JPEG\n103_IMG_3078.JPEG\n103_IMG_3079.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n103_IMG_3076.JPEG\n1.000\n0.766\n0.840\n0.671\n0.633\n\n\n103_IMG_3077.JPEG\n0.766\n1.000\n0.829\n0.749\n0.680\n\n\n103_IMG_3075.JPEG\n0.840\n0.829\n1.000\n0.709\n0.673\n\n\n103_IMG_3078.JPEG\n0.671\n0.749\n0.709\n1.000\n0.852\n\n\n103_IMG_3079.JPEG\n0.633\n0.680\n0.673\n0.852\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 56: Similarity matrix for identity 104\n\n\n\n\n\nid_and_image_name\n104_IMG_3138.JPEG\n104_IMG_3139.JPEG\n104_IMG_3140.JPEG\n104_IMG_3141.JPEG\n104_IMG_3137.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n104_IMG_3138.JPEG\n1.000\n0.848\n0.745\n0.728\n0.783\n\n\n104_IMG_3139.JPEG\n0.848\n1.000\n0.800\n0.754\n0.828\n\n\n104_IMG_3140.JPEG\n0.745\n0.800\n1.000\n0.796\n0.776\n\n\n104_IMG_3141.JPEG\n0.728\n0.754\n0.796\n1.000\n0.659\n\n\n104_IMG_3137.JPEG\n0.783\n0.828\n0.776\n0.659\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 57: Similarity matrix for identity 105\n\n\n\n\n\nid_and_image_name\n105_IMG_3081.JPEG\n105_IMG_3082.JPEG\n105_IMG_3084.JPEG\n105_IMG_3085.JPEG\n105_IMG_3083.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n105_IMG_3081.JPEG\n1.000\n0.881\n0.867\n0.843\n0.898\n\n\n105_IMG_3082.JPEG\n0.881\n1.000\n0.844\n0.848\n0.925\n\n\n105_IMG_3084.JPEG\n0.867\n0.844\n1.000\n0.874\n0.894\n\n\n105_IMG_3085.JPEG\n0.843\n0.848\n0.874\n1.000\n0.882\n\n\n105_IMG_3083.JPEG\n0.898\n0.925\n0.894\n0.882\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 58: Similarity matrix for identity 106\n\n\n\n\n\nid_and_image_name\n106_IMG_3114.JPEG\n106_IMG_3111.JPEG\n106_IMG_3115.JPEG\n106_IMG_3112.JPEG\n106_IMG_3113.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n106_IMG_3114.JPEG\n1.000\n0.828\n0.856\n0.847\n0.843\n\n\n106_IMG_3111.JPEG\n0.828\n1.000\n0.774\n0.799\n0.758\n\n\n106_IMG_3115.JPEG\n0.856\n0.774\n1.000\n0.869\n0.887\n\n\n106_IMG_3112.JPEG\n0.847\n0.799\n0.869\n1.000\n0.819\n\n\n106_IMG_3113.JPEG\n0.843\n0.758\n0.887\n0.819\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 59: Similarity matrix for identity 107\n\n\n\n\n\nid_and_image_name\n107_IMG_3091.JPEG\n107_IMG_3090.JPEG\n107_IMG_3089.JPEG\n107_IMG_3087.JPEG\n107_IMG_3088.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n107_IMG_3091.JPEG\n1.000\n0.806\n0.854\n0.764\n0.822\n\n\n107_IMG_3090.JPEG\n0.806\n1.000\n0.900\n0.742\n0.835\n\n\n107_IMG_3089.JPEG\n0.854\n0.900\n1.000\n0.811\n0.882\n\n\n107_IMG_3087.JPEG\n0.764\n0.742\n0.811\n1.000\n0.848\n\n\n107_IMG_3088.JPEG\n0.822\n0.835\n0.882\n0.848\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 60: Similarity matrix for identity 108\n\n\n\n\n\nid_and_image_name\n108_IMG_3159.JPEG\n108_IMG_3155.JPEG\n108_IMG_3158.JPEG\n108_IMG_3157.JPEG\n108_IMG_3156.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n108_IMG_3159.JPEG\n1.000\n0.776\n0.835\n0.841\n0.873\n\n\n108_IMG_3155.JPEG\n0.776\n1.000\n0.836\n0.758\n0.821\n\n\n108_IMG_3158.JPEG\n0.835\n0.836\n1.000\n0.837\n0.854\n\n\n108_IMG_3157.JPEG\n0.841\n0.758\n0.837\n1.000\n0.859\n\n\n108_IMG_3156.JPEG\n0.873\n0.821\n0.854\n0.859\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 61: Similarity matrix for identity 110\n\n\n\n\n\nid_and_image_name\n110_IMG_3134.JPEG\n110_IMG_3132.JPEG\n110_IMG_3131.JPEG\n110_IMG_3135.JPEG\n110_IMG_3133.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n110_IMG_3134.JPEG\n1.000\n0.877\n0.869\n0.915\n0.906\n\n\n110_IMG_3132.JPEG\n0.877\n1.000\n0.850\n0.907\n0.949\n\n\n110_IMG_3131.JPEG\n0.869\n0.850\n1.000\n0.860\n0.840\n\n\n110_IMG_3135.JPEG\n0.915\n0.907\n0.860\n1.000\n0.929\n\n\n110_IMG_3133.JPEG\n0.906\n0.949\n0.840\n0.929\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 62: Similarity matrix for identity 111\n\n\n\n\n\nid_and_image_name\n111_IMG_3067.JPEG\n111_IMG_3063.JPEG\n111_IMG_3064.JPEG\n111_IMG_3066.JPEG\n111_IMG_3065.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n111_IMG_3067.JPEG\n1.000\n0.794\n0.818\n0.831\n0.807\n\n\n111_IMG_3063.JPEG\n0.794\n1.000\n0.859\n0.826\n0.790\n\n\n111_IMG_3064.JPEG\n0.818\n0.859\n1.000\n0.814\n0.832\n\n\n111_IMG_3066.JPEG\n0.831\n0.826\n0.814\n1.000\n0.785\n\n\n111_IMG_3065.JPEG\n0.807\n0.790\n0.832\n0.785\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 63: Similarity matrix for identity 113\n\n\n\n\n\nid_and_image_name\n113_IMG_3071.JPEG\n113_IMG_3072.JPEG\n113_IMG_3070.JPEG\n113_IMG_3069.JPEG\n113_IMG_3073.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n113_IMG_3071.JPEG\n1.000\n0.831\n0.860\n0.879\n0.837\n\n\n113_IMG_3072.JPEG\n0.831\n1.000\n0.804\n0.811\n0.851\n\n\n113_IMG_3070.JPEG\n0.860\n0.804\n1.000\n0.876\n0.829\n\n\n113_IMG_3069.JPEG\n0.879\n0.811\n0.876\n1.000\n0.827\n\n\n113_IMG_3073.JPEG\n0.837\n0.851\n0.829\n0.827\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 64: Similarity matrix for identity 114\n\n\n\n\n\nid_and_image_name\n114_IMG_3097.JPEG\n114_IMG_3093.JPEG\n114_IMG_3095.JPEG\n114_IMG_3094.JPEG\n114_IMG_3096.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n114_IMG_3097.JPEG\n1.000\n0.819\n0.863\n0.832\n0.855\n\n\n114_IMG_3093.JPEG\n0.819\n1.000\n0.806\n0.799\n0.801\n\n\n114_IMG_3095.JPEG\n0.863\n0.806\n1.000\n0.841\n0.816\n\n\n114_IMG_3094.JPEG\n0.832\n0.799\n0.841\n1.000\n0.773\n\n\n114_IMG_3096.JPEG\n0.855\n0.801\n0.816\n0.773\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 65: Similarity matrix for identity 115\n\n\n\n\n\nid_and_image_name\n115_IMG_3149.JPEG\n115_IMG_3150.JPEG\n115_IMG_3153.JPEG\n115_IMG_3152.JPEG\n115_IMG_3151.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n115_IMG_3149.JPEG\n1.000\n0.877\n0.868\n0.863\n0.866\n\n\n115_IMG_3150.JPEG\n0.877\n1.000\n0.888\n0.863\n0.873\n\n\n115_IMG_3153.JPEG\n0.868\n0.888\n1.000\n0.927\n0.955\n\n\n115_IMG_3152.JPEG\n0.863\n0.863\n0.927\n1.000\n0.925\n\n\n115_IMG_3151.JPEG\n0.866\n0.873\n0.955\n0.925\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 66: Similarity matrix for identity 116\n\n\n\n\n\nid_and_image_name\n116_IMG_3105.JPEG\n116_IMG_3108.JPEG\n116_IMG_3107.JPEG\n116_IMG_3106.JPEG\n116_IMG_3109.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n116_IMG_3105.JPEG\n1.000\n0.787\n0.716\n0.758\n0.716\n\n\n116_IMG_3108.JPEG\n0.787\n1.000\n0.867\n0.793\n0.702\n\n\n116_IMG_3107.JPEG\n0.716\n0.867\n1.000\n0.781\n0.669\n\n\n116_IMG_3106.JPEG\n0.758\n0.793\n0.781\n1.000\n0.731\n\n\n116_IMG_3109.JPEG\n0.716\n0.702\n0.669\n0.731\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 67: Similarity matrix for identity 117\n\n\n\n\n\nid_and_image_name\n117_IMG_3100.JPEG\n117_IMG_3103.JPEG\n117_IMG_3102.JPEG\n117_IMG_3099.JPEG\n117_IMG_3101.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n117_IMG_3100.JPEG\n1.000\n0.840\n0.805\n0.834\n0.850\n\n\n117_IMG_3103.JPEG\n0.840\n1.000\n0.859\n0.751\n0.850\n\n\n117_IMG_3102.JPEG\n0.805\n0.859\n1.000\n0.700\n0.922\n\n\n117_IMG_3099.JPEG\n0.834\n0.751\n0.700\n1.000\n0.744\n\n\n117_IMG_3101.JPEG\n0.850\n0.850\n0.922\n0.744\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 68: Similarity matrix for identity 118\n\n\n\n\n\nid_and_image_name\n118_IMG_3144.JPEG\n118_IMG_3143.JPEG\n118_IMG_3146.JPEG\n118_IMG_3147.JPEG\n118_IMG_3145.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n118_IMG_3144.JPEG\n1.000\n0.849\n0.865\n0.884\n0.857\n\n\n118_IMG_3143.JPEG\n0.849\n1.000\n0.787\n0.822\n0.775\n\n\n118_IMG_3146.JPEG\n0.865\n0.787\n1.000\n0.879\n0.901\n\n\n118_IMG_3147.JPEG\n0.884\n0.822\n0.879\n1.000\n0.871\n\n\n118_IMG_3145.JPEG\n0.857\n0.775\n0.901\n0.871\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 69: Similarity matrix for identity 119\n\n\n\n\n\nid_and_image_name\n119_IMG_3168.JPEG\n119_IMG_3169.JPEG\n119_IMG_3170.JPEG\n119_IMG_3171.JPEG\n119_IMG_3172.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n119_IMG_3168.JPEG\n1.000\n0.776\n0.712\n0.798\n0.635\n\n\n119_IMG_3169.JPEG\n0.776\n1.000\n0.834\n0.887\n0.612\n\n\n119_IMG_3170.JPEG\n0.712\n0.834\n1.000\n0.841\n0.685\n\n\n119_IMG_3171.JPEG\n0.798\n0.887\n0.841\n1.000\n0.659\n\n\n119_IMG_3172.JPEG\n0.635\n0.612\n0.685\n0.659\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 70: Similarity matrix for identity 120\n\n\n\n\n\nid_and_image_name\n120_IMG_3164.JPEG\n120_IMG_3166.JPEG\n120_IMG_3162.JPEG\n120_IMG_3165.JPEG\n120_IMG_3163.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n120_IMG_3164.JPEG\n1.000\n0.860\n0.868\n0.925\n0.901\n\n\n120_IMG_3166.JPEG\n0.860\n1.000\n0.804\n0.818\n0.833\n\n\n120_IMG_3162.JPEG\n0.868\n0.804\n1.000\n0.852\n0.881\n\n\n120_IMG_3165.JPEG\n0.925\n0.818\n0.852\n1.000\n0.893\n\n\n120_IMG_3163.JPEG\n0.901\n0.833\n0.881\n0.893\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 71: Similarity matrix for identity 122\n\n\n\n\n\nid_and_image_name\n122_IMG_3190.JPEG\n122_IMG_3187.JPEG\n122_IMG_3188.JPEG\n122_IMG_3186.JPEG\n122_IMG_3189.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n122_IMG_3190.JPEG\n1.000\n0.874\n0.830\n0.845\n0.889\n\n\n122_IMG_3187.JPEG\n0.874\n1.000\n0.799\n0.853\n0.878\n\n\n122_IMG_3188.JPEG\n0.830\n0.799\n1.000\n0.888\n0.828\n\n\n122_IMG_3186.JPEG\n0.845\n0.853\n0.888\n1.000\n0.856\n\n\n122_IMG_3189.JPEG\n0.889\n0.878\n0.828\n0.856\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 72: Similarity matrix for identity 124\n\n\n\n\n\nid_and_image_name\n124_IMG_3196.JPEG\n124_IMG_3193.JPEG\n124_IMG_3195.JPEG\n124_IMG_3192.JPEG\n124_IMG_3194.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n124_IMG_3196.JPEG\n1.000\n0.900\n0.897\n0.918\n0.879\n\n\n124_IMG_3193.JPEG\n0.900\n1.000\n0.891\n0.916\n0.936\n\n\n124_IMG_3195.JPEG\n0.897\n0.891\n1.000\n0.884\n0.882\n\n\n124_IMG_3192.JPEG\n0.918\n0.916\n0.884\n1.000\n0.914\n\n\n124_IMG_3194.JPEG\n0.879\n0.936\n0.882\n0.914\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 73: Similarity matrix for identity 128\n\n\n\n\n\nid_and_image_name\n128_IMG_3174.JPEG\n128_IMG_3175.JPEG\n128_IMG_3178.JPEG\n128_IMG_3176.JPEG\n128_IMG_3177.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n128_IMG_3174.JPEG\n1.000\n0.820\n0.671\n0.840\n0.716\n\n\n128_IMG_3175.JPEG\n0.820\n1.000\n0.561\n0.827\n0.809\n\n\n128_IMG_3178.JPEG\n0.671\n0.561\n1.000\n0.717\n0.630\n\n\n128_IMG_3176.JPEG\n0.840\n0.827\n0.717\n1.000\n0.849\n\n\n128_IMG_3177.JPEG\n0.716\n0.809\n0.630\n0.849\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 74: Similarity matrix for identity 130\n\n\n\n\n\nid_and_image_name\n130_IMG_3184.JPEG\n130_IMG_3183.JPEG\n130_IMG_3181.JPEG\n130_IMG_3180.JPEG\n130_IMG_3182.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n130_IMG_3184.JPEG\n1.000\n0.843\n0.736\n0.833\n0.820\n\n\n130_IMG_3183.JPEG\n0.843\n1.000\n0.796\n0.833\n0.882\n\n\n130_IMG_3181.JPEG\n0.736\n0.796\n1.000\n0.818\n0.850\n\n\n130_IMG_3180.JPEG\n0.833\n0.833\n0.818\n1.000\n0.845\n\n\n130_IMG_3182.JPEG\n0.820\n0.882\n0.850\n0.845\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 75: Similarity matrix for identity 131\n\n\n\n\n\nid_and_image_name\n131_IMG_3202.JPEG\n131_IMG_3199.JPEG\n131_IMG_3200.JPEG\n131_IMG_3201.JPEG\n131_IMG_3198.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n131_IMG_3202.JPEG\n1.000\n0.847\n0.869\n0.901\n0.836\n\n\n131_IMG_3199.JPEG\n0.847\n1.000\n0.916\n0.879\n0.922\n\n\n131_IMG_3200.JPEG\n0.869\n0.916\n1.000\n0.928\n0.913\n\n\n131_IMG_3201.JPEG\n0.901\n0.879\n0.928\n1.000\n0.884\n\n\n131_IMG_3198.JPEG\n0.836\n0.922\n0.913\n0.884\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 76: Similarity matrix for identity 132\n\n\n\n\n\nid_and_image_name\n132_IMG_3242.JPEG\n132_IMG_3245.JPEG\n132_IMG_3241.JPEG\n132_IMG_3244.JPEG\n132_IMG_3243.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n132_IMG_3242.JPEG\n1.000\n0.804\n0.826\n0.830\n0.810\n\n\n132_IMG_3245.JPEG\n0.804\n1.000\n0.849\n0.824\n0.745\n\n\n132_IMG_3241.JPEG\n0.826\n0.849\n1.000\n0.844\n0.772\n\n\n132_IMG_3244.JPEG\n0.830\n0.824\n0.844\n1.000\n0.749\n\n\n132_IMG_3243.JPEG\n0.810\n0.745\n0.772\n0.749\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 77: Similarity matrix for identity 133\n\n\n\n\n\nid_and_image_name\n133_IMG_2970.JPEG\n133_IMG_2972.JPEG\n133_IMG_2971.JPEG\n133_IMG_2968.JPEG\n133_IMG_2969.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n133_IMG_2970.JPEG\n1.000\n0.828\n0.829\n0.748\n0.815\n\n\n133_IMG_2972.JPEG\n0.828\n1.000\n0.938\n0.789\n0.872\n\n\n133_IMG_2971.JPEG\n0.829\n0.938\n1.000\n0.820\n0.873\n\n\n133_IMG_2968.JPEG\n0.748\n0.789\n0.820\n1.000\n0.894\n\n\n133_IMG_2969.JPEG\n0.815\n0.872\n0.873\n0.894\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 78: Similarity matrix for identity 136\n\n\n\n\n\nid_and_image_name\n136_IMG_3050.JPEG\n136_IMG_3051.JPEG\n136_IMG_3054.JPEG\n136_IMG_3053.JPEG\n136_IMG_3052.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n136_IMG_3050.JPEG\n1.000\n0.902\n0.863\n0.873\n0.900\n\n\n136_IMG_3051.JPEG\n0.902\n1.000\n0.893\n0.880\n0.909\n\n\n136_IMG_3054.JPEG\n0.863\n0.893\n1.000\n0.911\n0.935\n\n\n136_IMG_3053.JPEG\n0.873\n0.880\n0.911\n1.000\n0.918\n\n\n136_IMG_3052.JPEG\n0.900\n0.909\n0.935\n0.918\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 79: Similarity matrix for identity 137\n\n\n\n\n\nid_and_image_name\n137_IMG_3019.JPEG\n137_IMG_3018.JPEG\n137_IMG_3020.JPEG\n137_IMG_3021.JPEG\n137_IMG_3017.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n137_IMG_3019.JPEG\n1.000\n0.859\n0.887\n0.811\n0.727\n\n\n137_IMG_3018.JPEG\n0.859\n1.000\n0.859\n0.758\n0.793\n\n\n137_IMG_3020.JPEG\n0.887\n0.859\n1.000\n0.807\n0.778\n\n\n137_IMG_3021.JPEG\n0.811\n0.758\n0.807\n1.000\n0.787\n\n\n137_IMG_3017.JPEG\n0.727\n0.793\n0.778\n0.787\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 80: Similarity matrix for identity 138\n\n\n\n\n\nid_and_image_name\n138_IMG_3032.JPEG\n138_IMG_3033.JPEG\n138_IMG_3034.JPEG\n138_IMG_3030.JPEG\n138_IMG_3031.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n138_IMG_3032.JPEG\n1.000\n0.826\n0.770\n0.773\n0.816\n\n\n138_IMG_3033.JPEG\n0.826\n1.000\n0.869\n0.791\n0.882\n\n\n138_IMG_3034.JPEG\n0.770\n0.869\n1.000\n0.777\n0.859\n\n\n138_IMG_3030.JPEG\n0.773\n0.791\n0.777\n1.000\n0.802\n\n\n138_IMG_3031.JPEG\n0.816\n0.882\n0.859\n0.802\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 81: Similarity matrix for identity 140\n\n\n\n\n\nid_and_image_name\n140_IMG_3004.JPEG\n140_IMG_3003.JPEG\n140_IMG_3006.JPEG\n140_IMG_3005.JPEG\n140_IMG_3002.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n140_IMG_3004.JPEG\n1.000\n0.973\n0.934\n0.937\n0.917\n\n\n140_IMG_3003.JPEG\n0.973\n1.000\n0.936\n0.933\n0.919\n\n\n140_IMG_3006.JPEG\n0.934\n0.936\n1.000\n0.912\n0.906\n\n\n140_IMG_3005.JPEG\n0.937\n0.933\n0.912\n1.000\n0.918\n\n\n140_IMG_3002.JPEG\n0.917\n0.919\n0.906\n0.918\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 82: Similarity matrix for identity 144\n\n\n\n\n\nid_and_image_name\n144_IMG_2900.JPEG\n144_IMG_2898.JPEG\n144_IMG_2899.JPEG\n144_IMG_2897.JPEG\n144_IMG_2896.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n144_IMG_2900.JPEG\n1.000\n0.869\n0.876\n0.849\n0.728\n\n\n144_IMG_2898.JPEG\n0.869\n1.000\n0.797\n0.860\n0.713\n\n\n144_IMG_2899.JPEG\n0.876\n0.797\n1.000\n0.845\n0.696\n\n\n144_IMG_2897.JPEG\n0.849\n0.860\n0.845\n1.000\n0.806\n\n\n144_IMG_2896.JPEG\n0.728\n0.713\n0.696\n0.806\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 83: Similarity matrix for identity 145\n\n\n\n\n\nid_and_image_name\n145_IMG_3056.JPEG\n145_IMG_3059.JPEG\n145_IMG_3057.JPEG\n145_IMG_3060.JPEG\n145_IMG_3058.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n145_IMG_3056.JPEG\n1.000\n0.834\n0.881\n0.825\n0.819\n\n\n145_IMG_3059.JPEG\n0.834\n1.000\n0.858\n0.895\n0.817\n\n\n145_IMG_3057.JPEG\n0.881\n0.858\n1.000\n0.868\n0.874\n\n\n145_IMG_3060.JPEG\n0.825\n0.895\n0.868\n1.000\n0.876\n\n\n145_IMG_3058.JPEG\n0.819\n0.817\n0.874\n0.876\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 84: Similarity matrix for identity 146\n\n\n\n\n\nid_and_image_name\n146_IMG_3048.JPEG\n146_IMG_3044.JPEG\n146_IMG_3043.JPEG\n146_IMG_3047.JPEG\n146_IMG_3046.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n146_IMG_3048.JPEG\n1.000\n0.718\n0.669\n0.833\n0.745\n\n\n146_IMG_3044.JPEG\n0.718\n1.000\n0.848\n0.759\n0.761\n\n\n146_IMG_3043.JPEG\n0.669\n0.848\n1.000\n0.710\n0.723\n\n\n146_IMG_3047.JPEG\n0.833\n0.759\n0.710\n1.000\n0.782\n\n\n146_IMG_3046.JPEG\n0.745\n0.761\n0.723\n0.782\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 85: Similarity matrix for identity 147\n\n\n\n\n\nid_and_image_name\n147_IMG_2933.JPEG\n147_IMG_2934.JPEG\n147_IMG_2931.JPEG\n147_IMG_2935.JPEG\n147_IMG_2932.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n147_IMG_2933.JPEG\n1.000\n0.904\n0.760\n0.848\n0.905\n\n\n147_IMG_2934.JPEG\n0.904\n1.000\n0.864\n0.938\n0.928\n\n\n147_IMG_2931.JPEG\n0.760\n0.864\n1.000\n0.838\n0.847\n\n\n147_IMG_2935.JPEG\n0.848\n0.938\n0.838\n1.000\n0.904\n\n\n147_IMG_2932.JPEG\n0.905\n0.928\n0.847\n0.904\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 86: Similarity matrix for identity 148\n\n\n\n\n\nid_and_image_name\n148_IMG_2940.JPEG\n148_IMG_2938.JPEG\n148_IMG_2939.JPEG\n148_IMG_2937.JPEG\n148_IMG_2941.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n148_IMG_2940.JPEG\n1.000\n0.721\n0.869\n0.783\n0.936\n\n\n148_IMG_2938.JPEG\n0.721\n1.000\n0.790\n0.813\n0.741\n\n\n148_IMG_2939.JPEG\n0.869\n0.790\n1.000\n0.833\n0.872\n\n\n148_IMG_2937.JPEG\n0.783\n0.813\n0.833\n1.000\n0.817\n\n\n148_IMG_2941.JPEG\n0.936\n0.741\n0.872\n0.817\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 87: Similarity matrix for identity 149\n\n\n\n\n\nid_and_image_name\n149_IMG_2943.JPEG\n149_IMG_2946.JPEG\n149_IMG_2947.JPEG\n149_IMG_2945.JPEG\n149_IMG_2944.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n149_IMG_2943.JPEG\n1.000\n0.900\n0.873\n0.905\n0.830\n\n\n149_IMG_2946.JPEG\n0.900\n1.000\n0.916\n0.909\n0.853\n\n\n149_IMG_2947.JPEG\n0.873\n0.916\n1.000\n0.873\n0.827\n\n\n149_IMG_2945.JPEG\n0.905\n0.909\n0.873\n1.000\n0.795\n\n\n149_IMG_2944.JPEG\n0.830\n0.853\n0.827\n0.795\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 88: Similarity matrix for identity 151\n\n\n\n\n\nid_and_image_name\n151_IMG_2922.JPEG\n151_IMG_2919.JPEG\n151_IMG_2921.JPEG\n151_IMG_2923.JPEG\n151_IMG_2920.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n151_IMG_2922.JPEG\n1.000\n0.836\n0.828\n0.807\n0.816\n\n\n151_IMG_2919.JPEG\n0.836\n1.000\n0.825\n0.840\n0.897\n\n\n151_IMG_2921.JPEG\n0.828\n0.825\n1.000\n0.819\n0.821\n\n\n151_IMG_2923.JPEG\n0.807\n0.840\n0.819\n1.000\n0.879\n\n\n151_IMG_2920.JPEG\n0.816\n0.897\n0.821\n0.879\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 89: Similarity matrix for identity 152\n\n\n\n\n\nid_and_image_name\n152_IMG_2952.JPEG\n152_IMG_2949.JPEG\n152_IMG_2950.JPEG\n152_IMG_2953.JPEG\n152_IMG_2951.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n152_IMG_2952.JPEG\n1.000\n0.775\n0.908\n0.877\n0.858\n\n\n152_IMG_2949.JPEG\n0.775\n1.000\n0.839\n0.836\n0.869\n\n\n152_IMG_2950.JPEG\n0.908\n0.839\n1.000\n0.929\n0.915\n\n\n152_IMG_2953.JPEG\n0.877\n0.836\n0.929\n1.000\n0.892\n\n\n152_IMG_2951.JPEG\n0.858\n0.869\n0.915\n0.892\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 90: Similarity matrix for identity 153\n\n\n\n\n\nid_and_image_name\n153_IMG_2978.JPEG\n153_IMG_2975.JPEG\n153_IMG_2977.JPEG\n153_IMG_2976.JPEG\n153_IMG_2974.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n153_IMG_2978.JPEG\n1.000\n0.874\n0.886\n0.884\n0.882\n\n\n153_IMG_2975.JPEG\n0.874\n1.000\n0.883\n0.913\n0.914\n\n\n153_IMG_2977.JPEG\n0.886\n0.883\n1.000\n0.893\n0.857\n\n\n153_IMG_2976.JPEG\n0.884\n0.913\n0.893\n1.000\n0.907\n\n\n153_IMG_2974.JPEG\n0.882\n0.914\n0.857\n0.907\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 91: Similarity matrix for identity 154\n\n\n\n\n\nid_and_image_name\n154_IMG_2983.JPEG\n154_IMG_2984.JPEG\n154_IMG_2981.JPEG\n154_IMG_2982.JPEG\n154_IMG_2980.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n154_IMG_2983.JPEG\n1.000\n0.899\n0.819\n0.876\n0.859\n\n\n154_IMG_2984.JPEG\n0.899\n1.000\n0.881\n0.919\n0.917\n\n\n154_IMG_2981.JPEG\n0.819\n0.881\n1.000\n0.898\n0.906\n\n\n154_IMG_2982.JPEG\n0.876\n0.919\n0.898\n1.000\n0.921\n\n\n154_IMG_2980.JPEG\n0.859\n0.917\n0.906\n0.921\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 92: Similarity matrix for identity 155\n\n\n\n\n\nid_and_image_name\n155_IMG_2928.JPEG\n155_IMG_2926.JPEG\n155_IMG_2929.JPEG\n155_IMG_2925.JPEG\n155_IMG_2927.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n155_IMG_2928.JPEG\n1.000\n0.844\n0.853\n0.842\n0.871\n\n\n155_IMG_2926.JPEG\n0.844\n1.000\n0.866\n0.809\n0.823\n\n\n155_IMG_2929.JPEG\n0.853\n0.866\n1.000\n0.802\n0.785\n\n\n155_IMG_2925.JPEG\n0.842\n0.809\n0.802\n1.000\n0.782\n\n\n155_IMG_2927.JPEG\n0.871\n0.823\n0.785\n0.782\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 93: Similarity matrix for identity 157\n\n\n\n\n\nid_and_image_name\n157_IMG_2963.JPEG\n157_IMG_2962.JPEG\n157_IMG_2965.JPEG\n157_IMG_2966.JPEG\n157_IMG_2964.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n157_IMG_2963.JPEG\n1.000\n0.891\n0.909\n0.886\n0.884\n\n\n157_IMG_2962.JPEG\n0.891\n1.000\n0.887\n0.895\n0.791\n\n\n157_IMG_2965.JPEG\n0.909\n0.887\n1.000\n0.958\n0.828\n\n\n157_IMG_2966.JPEG\n0.886\n0.895\n0.958\n1.000\n0.798\n\n\n157_IMG_2964.JPEG\n0.884\n0.791\n0.828\n0.798\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 94: Similarity matrix for identity 158\n\n\n\n\n\nid_and_image_name\n158_IMG_3353.JPEG\n158_IMG_3352.JPEG\n158_IMG_3351.JPEG\n158_IMG_3354.JPEG\n158_IMG_3350.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n158_IMG_3353.JPEG\n1.000\n0.877\n0.870\n0.870\n0.638\n\n\n158_IMG_3352.JPEG\n0.877\n1.000\n0.913\n0.833\n0.697\n\n\n158_IMG_3351.JPEG\n0.870\n0.913\n1.000\n0.835\n0.667\n\n\n158_IMG_3354.JPEG\n0.870\n0.833\n0.835\n1.000\n0.692\n\n\n158_IMG_3350.JPEG\n0.638\n0.697\n0.667\n0.692\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 95: Similarity matrix for identity 159\n\n\n\n\n\nid_and_image_name\n159_IMG_3321.JPEG\n159_IMG_3322.JPEG\n159_IMG_3323.JPEG\n159_IMG_3320.JPEG\n159_IMG_3319.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n159_IMG_3321.JPEG\n1.000\n0.812\n0.765\n0.766\n0.760\n\n\n159_IMG_3322.JPEG\n0.812\n1.000\n0.847\n0.741\n0.681\n\n\n159_IMG_3323.JPEG\n0.765\n0.847\n1.000\n0.777\n0.661\n\n\n159_IMG_3320.JPEG\n0.766\n0.741\n0.777\n1.000\n0.825\n\n\n159_IMG_3319.JPEG\n0.760\n0.681\n0.661\n0.825\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 96: Similarity matrix for identity 160\n\n\n\n\n\nid_and_image_name\n160_IMG_3270.JPEG\n160_IMG_3269.JPEG\n160_IMG_3273.JPEG\n160_IMG_3271.JPEG\n160_IMG_3272.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n160_IMG_3270.JPEG\n1.000\n0.873\n0.857\n0.857\n0.825\n\n\n160_IMG_3269.JPEG\n0.873\n1.000\n0.854\n0.892\n0.844\n\n\n160_IMG_3273.JPEG\n0.857\n0.854\n1.000\n0.882\n0.894\n\n\n160_IMG_3271.JPEG\n0.857\n0.892\n0.882\n1.000\n0.877\n\n\n160_IMG_3272.JPEG\n0.825\n0.844\n0.894\n0.877\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 97: Similarity matrix for identity 162\n\n\n\n\n\nid_and_image_name\n162_IMG_3301.JPEG\n162_IMG_3303.JPEG\n162_IMG_3300.JPEG\n162_IMG_3302.JPEG\n162_IMG_3304.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n162_IMG_3301.JPEG\n1.000\n0.870\n0.904\n0.852\n0.894\n\n\n162_IMG_3303.JPEG\n0.870\n1.000\n0.823\n0.797\n0.889\n\n\n162_IMG_3300.JPEG\n0.904\n0.823\n1.000\n0.839\n0.844\n\n\n162_IMG_3302.JPEG\n0.852\n0.797\n0.839\n1.000\n0.860\n\n\n162_IMG_3304.JPEG\n0.894\n0.889\n0.844\n0.860\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 98: Similarity matrix for identity 164\n\n\n\n\n\nid_and_image_name\n164_IMG_3328.JPEG\n164_IMG_3327.JPEG\n164_IMG_3325.JPEG\n164_IMG_3329.JPEG\n164_IMG_3326.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n164_IMG_3328.JPEG\n1.000\n0.837\n0.702\n0.807\n0.807\n\n\n164_IMG_3327.JPEG\n0.837\n1.000\n0.751\n0.769\n0.796\n\n\n164_IMG_3325.JPEG\n0.702\n0.751\n1.000\n0.682\n0.800\n\n\n164_IMG_3329.JPEG\n0.807\n0.769\n0.682\n1.000\n0.808\n\n\n164_IMG_3326.JPEG\n0.807\n0.796\n0.800\n0.808\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 99: Similarity matrix for identity 165\n\n\n\n\n\nid_and_image_name\n165_IMG_3282.JPEG\n165_IMG_3285.JPEG\n165_IMG_3281.JPEG\n165_IMG_3284.JPEG\n165_IMG_3283.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n165_IMG_3282.JPEG\n1.000\n0.773\n0.769\n0.823\n0.864\n\n\n165_IMG_3285.JPEG\n0.773\n1.000\n0.676\n0.804\n0.781\n\n\n165_IMG_3281.JPEG\n0.769\n0.676\n1.000\n0.755\n0.787\n\n\n165_IMG_3284.JPEG\n0.823\n0.804\n0.755\n1.000\n0.868\n\n\n165_IMG_3283.JPEG\n0.864\n0.781\n0.787\n0.868\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 100: Similarity matrix for identity 166\n\n\n\n\n\nid_and_image_name\n166_IMG_3275.JPEG\n166_IMG_3278.JPEG\n166_IMG_3279.JPEG\n166_IMG_3276.JPEG\n166_IMG_3277.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n166_IMG_3275.JPEG\n1.000\n0.750\n0.879\n0.877\n0.813\n\n\n166_IMG_3278.JPEG\n0.750\n1.000\n0.796\n0.837\n0.801\n\n\n166_IMG_3279.JPEG\n0.879\n0.796\n1.000\n0.881\n0.817\n\n\n166_IMG_3276.JPEG\n0.877\n0.837\n0.881\n1.000\n0.865\n\n\n166_IMG_3277.JPEG\n0.813\n0.801\n0.817\n0.865\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 101: Similarity matrix for identity 169\n\n\n\n\n\nid_and_image_name\n169_IMG_3316.JPEG\n169_IMG_3313.JPEG\n169_IMG_3315.JPEG\n169_IMG_3317.JPEG\n169_IMG_3314.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n169_IMG_3316.JPEG\n1.000\n0.766\n0.811\n0.860\n0.857\n\n\n169_IMG_3313.JPEG\n0.766\n1.000\n0.735\n0.814\n0.774\n\n\n169_IMG_3315.JPEG\n0.811\n0.735\n1.000\n0.755\n0.825\n\n\n169_IMG_3317.JPEG\n0.860\n0.814\n0.755\n1.000\n0.816\n\n\n169_IMG_3314.JPEG\n0.857\n0.774\n0.825\n0.816\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 102: Similarity matrix for identity 171\n\n\n\n\n\nid_and_image_name\n171_IMG_3262.JPEG\n171_IMG_3264.JPEG\n171_IMG_3266.JPEG\n171_IMG_3265.JPEG\n171_IMG_3263.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n171_IMG_3262.JPEG\n1.000\n0.881\n0.877\n0.870\n0.827\n\n\n171_IMG_3264.JPEG\n0.881\n1.000\n0.896\n0.873\n0.829\n\n\n171_IMG_3266.JPEG\n0.877\n0.896\n1.000\n0.886\n0.861\n\n\n171_IMG_3265.JPEG\n0.870\n0.873\n0.886\n1.000\n0.859\n\n\n171_IMG_3263.JPEG\n0.827\n0.829\n0.861\n0.859\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 103: Similarity matrix for identity 174\n\n\n\n\n\nid_and_image_name\n174_IMG_3290.JPEG\n174_IMG_3288.JPEG\n174_IMG_3291.JPEG\n174_IMG_3287.JPEG\n174_IMG_3289.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n174_IMG_3290.JPEG\n1.000\n0.781\n0.788\n0.690\n0.821\n\n\n174_IMG_3288.JPEG\n0.781\n1.000\n0.818\n0.784\n0.821\n\n\n174_IMG_3291.JPEG\n0.788\n0.818\n1.000\n0.792\n0.831\n\n\n174_IMG_3287.JPEG\n0.690\n0.784\n0.792\n1.000\n0.796\n\n\n174_IMG_3289.JPEG\n0.821\n0.821\n0.831\n0.796\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 104: Similarity matrix for identity 175\n\n\n\n\n\nid_and_image_name\n175_IMG_3363.JPEG\n175_IMG_3366.JPEG\n175_IMG_3365.JPEG\n175_IMG_3364.JPEG\n175_IMG_3362.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n175_IMG_3363.JPEG\n1.000\n0.914\n0.908\n0.918\n0.925\n\n\n175_IMG_3366.JPEG\n0.914\n1.000\n0.909\n0.945\n0.924\n\n\n175_IMG_3365.JPEG\n0.908\n0.909\n1.000\n0.906\n0.932\n\n\n175_IMG_3364.JPEG\n0.918\n0.945\n0.906\n1.000\n0.939\n\n\n175_IMG_3362.JPEG\n0.925\n0.924\n0.932\n0.939\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 105: Similarity matrix for identity 176\n\n\n\n\n\nid_and_image_name\n176_IMG_3372.JPEG\n176_IMG_3371.JPEG\n176_IMG_3369.JPEG\n176_IMG_3368.JPEG\n176_IMG_3370.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n176_IMG_3372.JPEG\n1.000\n0.927\n0.886\n0.868\n0.884\n\n\n176_IMG_3371.JPEG\n0.927\n1.000\n0.922\n0.900\n0.901\n\n\n176_IMG_3369.JPEG\n0.886\n0.922\n1.000\n0.912\n0.894\n\n\n176_IMG_3368.JPEG\n0.868\n0.900\n0.912\n1.000\n0.912\n\n\n176_IMG_3370.JPEG\n0.884\n0.901\n0.894\n0.912\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 106: Similarity matrix for identity 178\n\n\n\n\n\nid_and_image_name\n178_IMG_3383.JPEG\n178_IMG_3385.JPEG\n178_IMG_3386.JPEG\n178_IMG_3384.JPEG\n178_IMG_3387.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n178_IMG_3383.JPEG\n1.000\n0.875\n0.881\n0.761\n0.832\n\n\n178_IMG_3385.JPEG\n0.875\n1.000\n0.842\n0.742\n0.840\n\n\n178_IMG_3386.JPEG\n0.881\n0.842\n1.000\n0.719\n0.809\n\n\n178_IMG_3384.JPEG\n0.761\n0.742\n0.719\n1.000\n0.719\n\n\n178_IMG_3387.JPEG\n0.832\n0.840\n0.809\n0.719\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 107: Similarity matrix for identity 184\n\n\n\n\n\nid_and_image_name\n184_IMG_2282.JPEG\n184_IMG_2284.JPEG\n184_IMG_2285.JPEG\n184_IMG_2283.JPEG\n184_IMG_2281.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n184_IMG_2282.JPEG\n1.000\n0.805\n0.852\n0.822\n0.840\n\n\n184_IMG_2284.JPEG\n0.805\n1.000\n0.841\n0.834\n0.791\n\n\n184_IMG_2285.JPEG\n0.852\n0.841\n1.000\n0.829\n0.833\n\n\n184_IMG_2283.JPEG\n0.822\n0.834\n0.829\n1.000\n0.780\n\n\n184_IMG_2281.JPEG\n0.840\n0.791\n0.833\n0.780\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 108: Similarity matrix for identity 185\n\n\n\n\n\nid_and_image_name\n185_IMG_3630.JPEG\n185_IMG_3629.JPEG\n185_IMG_3628.JPEG\n185_IMG_3632.JPEG\n185_IMG_3631.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n185_IMG_3630.JPEG\n1.000\n0.834\n0.810\n0.857\n0.888\n\n\n185_IMG_3629.JPEG\n0.834\n1.000\n0.867\n0.834\n0.828\n\n\n185_IMG_3628.JPEG\n0.810\n0.867\n1.000\n0.769\n0.756\n\n\n185_IMG_3632.JPEG\n0.857\n0.834\n0.769\n1.000\n0.870\n\n\n185_IMG_3631.JPEG\n0.888\n0.828\n0.756\n0.870\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 109: Similarity matrix for identity 186\n\n\n\n\n\nid_and_image_name\n186_IMG_3644.JPEG\n186_IMG_3640.JPEG\n186_IMG_3642.JPEG\n186_IMG_3643.JPEG\n186_IMG_3641.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n186_IMG_3644.JPEG\n1.000\n0.741\n0.881\n0.882\n0.887\n\n\n186_IMG_3640.JPEG\n0.741\n1.000\n0.762\n0.741\n0.816\n\n\n186_IMG_3642.JPEG\n0.881\n0.762\n1.000\n0.929\n0.901\n\n\n186_IMG_3643.JPEG\n0.882\n0.741\n0.929\n1.000\n0.902\n\n\n186_IMG_3641.JPEG\n0.887\n0.816\n0.901\n0.902\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 110: Similarity matrix for identity 187\n\n\n\n\n\nid_and_image_name\n187_IMG_3636.JPEG\n187_IMG_3637.JPEG\n187_IMG_3638.JPEG\n187_IMG_3634.JPEG\n187_IMG_3635.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n187_IMG_3636.JPEG\n1.000\n0.856\n0.858\n0.756\n0.834\n\n\n187_IMG_3637.JPEG\n0.856\n1.000\n0.915\n0.778\n0.904\n\n\n187_IMG_3638.JPEG\n0.858\n0.915\n1.000\n0.816\n0.884\n\n\n187_IMG_3634.JPEG\n0.756\n0.778\n0.816\n1.000\n0.789\n\n\n187_IMG_3635.JPEG\n0.834\n0.904\n0.884\n0.789\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 111: Similarity matrix for identity 188\n\n\n\n\n\nid_and_image_name\n188_IMG_3686.JPEG\n188_IMG_3688.JPEG\n188_IMG_3687.JPEG\n188_IMG_3685.JPEG\n188_IMG_3689.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n188_IMG_3686.JPEG\n1.000\n0.805\n0.811\n0.854\n0.824\n\n\n188_IMG_3688.JPEG\n0.805\n1.000\n0.891\n0.882\n0.901\n\n\n188_IMG_3687.JPEG\n0.811\n0.891\n1.000\n0.893\n0.840\n\n\n188_IMG_3685.JPEG\n0.854\n0.882\n0.893\n1.000\n0.852\n\n\n188_IMG_3689.JPEG\n0.824\n0.901\n0.840\n0.852\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 112: Similarity matrix for identity 189\n\n\n\n\n\nid_and_image_name\n189_IMG_3677.JPEG\n189_IMG_3675.JPEG\n189_IMG_3674.JPEG\n189_IMG_3676.JPEG\n189_IMG_3673.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n189_IMG_3677.JPEG\n1.000\n0.936\n0.909\n0.950\n0.893\n\n\n189_IMG_3675.JPEG\n0.936\n1.000\n0.925\n0.956\n0.882\n\n\n189_IMG_3674.JPEG\n0.909\n0.925\n1.000\n0.926\n0.926\n\n\n189_IMG_3676.JPEG\n0.950\n0.956\n0.926\n1.000\n0.897\n\n\n189_IMG_3673.JPEG\n0.893\n0.882\n0.926\n0.897\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 113: Similarity matrix for identity 192\n\n\n\n\n\nid_and_image_name\n192_IMG_3667.JPEG\n192_IMG_3671.JPEG\n192_IMG_3669.JPEG\n192_IMG_3668.JPEG\n192_IMG_3670.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n192_IMG_3667.JPEG\n1.000\n0.729\n0.794\n0.811\n0.693\n\n\n192_IMG_3671.JPEG\n0.729\n1.000\n0.875\n0.900\n0.883\n\n\n192_IMG_3669.JPEG\n0.794\n0.875\n1.000\n0.881\n0.854\n\n\n192_IMG_3668.JPEG\n0.811\n0.900\n0.881\n1.000\n0.848\n\n\n192_IMG_3670.JPEG\n0.693\n0.883\n0.854\n0.848\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 114: Similarity matrix for identity 193\n\n\n\n\n\nid_and_image_name\n193_IMG_3682.JPEG\n193_IMG_3679.JPEG\n193_IMG_3680.JPEG\n193_IMG_3681.JPEG\n193_IMG_3683.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n193_IMG_3682.JPEG\n1.000\n0.832\n0.902\n0.898\n0.912\n\n\n193_IMG_3679.JPEG\n0.832\n1.000\n0.848\n0.829\n0.869\n\n\n193_IMG_3680.JPEG\n0.902\n0.848\n1.000\n0.880\n0.915\n\n\n193_IMG_3681.JPEG\n0.898\n0.829\n0.880\n1.000\n0.901\n\n\n193_IMG_3683.JPEG\n0.912\n0.869\n0.915\n0.901\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 115: Similarity matrix for identity 194\n\n\n\n\n\nid_and_image_name\n194_IMG_3692.JPEG\n194_IMG_3691.JPEG\n194_IMG_3694.JPEG\n194_IMG_3695.JPEG\n194_IMG_3693.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n194_IMG_3692.JPEG\n1.000\n0.897\n0.850\n0.883\n0.835\n\n\n194_IMG_3691.JPEG\n0.897\n1.000\n0.853\n0.866\n0.845\n\n\n194_IMG_3694.JPEG\n0.850\n0.853\n1.000\n0.879\n0.919\n\n\n194_IMG_3695.JPEG\n0.883\n0.866\n0.879\n1.000\n0.864\n\n\n194_IMG_3693.JPEG\n0.835\n0.845\n0.919\n0.864\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 116: Similarity matrix for identity 196\n\n\n\n\n\nid_and_image_name\n196_IMG_3653.JPEG\n196_IMG_3651.JPEG\n196_IMG_3652.JPEG\n196_IMG_3655.JPEG\n196_IMG_3654.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n196_IMG_3653.JPEG\n1.000\n0.837\n0.876\n0.695\n0.755\n\n\n196_IMG_3651.JPEG\n0.837\n1.000\n0.858\n0.831\n0.811\n\n\n196_IMG_3652.JPEG\n0.876\n0.858\n1.000\n0.746\n0.794\n\n\n196_IMG_3655.JPEG\n0.695\n0.831\n0.746\n1.000\n0.683\n\n\n196_IMG_3654.JPEG\n0.755\n0.811\n0.794\n0.683\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 117: Similarity matrix for identity 197\n\n\n\n\n\nid_and_image_name\n197_IMG_3605.JPEG\n197_IMG_3604.JPEG\n197_IMG_3606.JPEG\n197_IMG_3607.JPEG\n197_IMG_3608.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n197_IMG_3605.JPEG\n1.000\n0.804\n0.899\n0.863\n0.289\n\n\n197_IMG_3604.JPEG\n0.804\n1.000\n0.807\n0.852\n0.254\n\n\n197_IMG_3606.JPEG\n0.899\n0.807\n1.000\n0.871\n0.238\n\n\n197_IMG_3607.JPEG\n0.863\n0.852\n0.871\n1.000\n0.223\n\n\n197_IMG_3608.JPEG\n0.289\n0.254\n0.238\n0.223\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 118: Similarity matrix for identity 199\n\n\n\n\n\nid_and_image_name\n199_IMG_3595.JPEG\n199_IMG_3592.JPEG\n199_IMG_3591.JPEG\n199_IMG_3594.JPEG\n199_IMG_3593.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n199_IMG_3595.JPEG\n1.000\n0.738\n0.690\n0.742\n0.706\n\n\n199_IMG_3592.JPEG\n0.738\n1.000\n0.885\n0.874\n0.953\n\n\n199_IMG_3591.JPEG\n0.690\n0.885\n1.000\n0.829\n0.875\n\n\n199_IMG_3594.JPEG\n0.742\n0.874\n0.829\n1.000\n0.866\n\n\n199_IMG_3593.JPEG\n0.706\n0.953\n0.875\n0.866\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 119: Similarity matrix for identity 202\n\n\n\n\n\nid_and_image_name\n202_IMG_3618.JPEG\n202_IMG_3617.JPEG\n202_IMG_3616.JPEG\n202_IMG_3615.JPEG\n202_IMG_3619.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n202_IMG_3618.JPEG\n1.000\n0.796\n0.573\n0.266\n0.663\n\n\n202_IMG_3617.JPEG\n0.796\n1.000\n0.664\n0.251\n0.589\n\n\n202_IMG_3616.JPEG\n0.573\n0.664\n1.000\n0.471\n0.465\n\n\n202_IMG_3615.JPEG\n0.266\n0.251\n0.471\n1.000\n0.277\n\n\n202_IMG_3619.JPEG\n0.663\n0.589\n0.465\n0.277\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 120: Similarity matrix for identity 203\n\n\n\n\n\nid_and_image_name\n203_IMG_3701.JPEG\n203_IMG_3703.JPEG\n203_IMG_3700.JPEG\n203_IMG_3702.JPEG\n203_IMG_3704.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n203_IMG_3701.JPEG\n1.000\n0.800\n0.871\n0.884\n0.785\n\n\n203_IMG_3703.JPEG\n0.800\n1.000\n0.767\n0.795\n0.847\n\n\n203_IMG_3700.JPEG\n0.871\n0.767\n1.000\n0.867\n0.749\n\n\n203_IMG_3702.JPEG\n0.884\n0.795\n0.867\n1.000\n0.816\n\n\n203_IMG_3704.JPEG\n0.785\n0.847\n0.749\n0.816\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 121: Similarity matrix for identity 204\n\n\n\n\n\nid_and_image_name\n204_IMG_3711.JPEG\n204_IMG_3712.JPEG\n204_IMG_3710.JPEG\n204_IMG_3709.JPEG\n204_IMG_3713.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n204_IMG_3711.JPEG\n1.000\n0.827\n0.913\n0.921\n0.838\n\n\n204_IMG_3712.JPEG\n0.827\n1.000\n0.826\n0.831\n0.831\n\n\n204_IMG_3710.JPEG\n0.913\n0.826\n1.000\n0.908\n0.820\n\n\n204_IMG_3709.JPEG\n0.921\n0.831\n0.908\n1.000\n0.818\n\n\n204_IMG_3713.JPEG\n0.838\n0.831\n0.820\n0.818\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 122: Similarity matrix for identity 205\n\n\n\n\n\nid_and_image_name\n205_IMG_3579.JPEG\n205_IMG_3581.JPEG\n205_IMG_3577.JPEG\n205_IMG_3580.JPEG\n205_IMG_3578.JPEG\n\n\nid_and_image_name\n \n \n \n \n \n\n\n\n\n205_IMG_3579.JPEG\n1.000\n0.856\n0.761\n0.858\n0.873\n\n\n205_IMG_3581.JPEG\n0.856\n1.000\n0.770\n0.886\n0.841\n\n\n205_IMG_3577.JPEG\n0.761\n0.770\n1.000\n0.759\n0.838\n\n\n205_IMG_3580.JPEG\n0.858\n0.886\n0.759\n1.000\n0.871\n\n\n205_IMG_3578.JPEG\n0.873\n0.841\n0.838\n0.871\n1.000",
    "crumbs": [
      "Artefacts"
    ]
  },
  {
    "objectID": "newt_current.html",
    "href": "newt_current.html",
    "title": "Newt Current",
    "section": "",
    "text": "import os\nimport sys\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom wildlife_datasets import analysis, datasets, splits\nimport pycocotools.mask as mask_util\nfrom wildlife_tools.data import ImageDataset\nfrom sklearn.metrics import average_precision_score\nimport numpy as np\nimport timm\nfrom transformers import AutoModel\nimport torch\nimport numpy as np\nfrom wildlife_tools.inference import TopkClassifier, KnnClassifier\nfrom wildlife_tools.features import DeepFeatures\nimport torchvision.transforms as T\nfrom PIL import Image\nimport kaggle\nimport pandas as pd\nfrom wildlife_tools.data import ImageDataset\nfrom gcn_reid.segmentation import decode_rle_mask\n\n\nCreate Dataset Class\n\nsource\n\nget_newt_dataset\n\n get_newt_dataset ()\n\n\nsource\n\n\nget_cropped_newt\n\n get_cropped_newt (path, rle)\n\n\nsource\n\n\nget_cropping_image_dataset\n\n get_cropping_image_dataset ()\n\n\nCroppingImageDataset = get_cropping_image_dataset()\n\nDataset already exists at data/newt_dataset\n\n\n\n\n\n\n\n\n\npath\nimage_name\nidentity\nsegmentation_mask_rle\n\n\n\n\n0\noriginal_images/GCN63-P6-S2/IMG_2725.JPEG\nIMG_2725.JPEG\nGCN63-P6-S2\n2048x1536:bjlS15go17J6oIGT\\N&lt;`c1O^\\N7]c1Ib\\N&gt;X...\n\n\n1\noriginal_images/GCN63-P6-S2/IMG_2727.JPEG\nIMG_2727.JPEG\nGCN63-P6-S2\n2048x1536:XljT17do17N2M2THEQ`N&lt;k_1KP`N=h_1FU`N...\n\n\n2\noriginal_images/GCN63-P6-S2/IMG_2728.JPEG\nIMG_2728.JPEG\nGCN63-P6-S2\n2048x1536:chln02mo12N2M3E&lt;M3N1OO4CQS2LXmM6L5K5...\n\n\n3\noriginal_images/GCN63-P6-S2/IMG_2726.JPEG\nIMG_2726.JPEG\nGCN63-P6-S2\n2048x1536:l]\\P1U1=]O4KVl1R1ZSN^O:IVl1m2K6[TNYL...\n\n\n4\noriginal_images/GCN63-P6-S2/IMG_2729.JPEG\nIMG_2729.JPEG\nGCN63-P6-S2\n2048x1536:S]`92no11OO10ho31VPL3_PNKVo1=VOGQRN7...\n\n\n\n\n\n\n\n\ndataset_path = \"data/newt_dataset\"\nNewtDataset = get_newt_dataset()\nNewtDataset._download(dataset_name=\"mshahoyi/barhill-newts-segmented\", download_path=dataset_path)\ndataset = NewtDataset(dataset_path)\ndataset.df.head()\n\n\ndataset.plot_grid()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis.display_statistics(dataset.df)\n\nNumber of identitites            207\nNumber of all animals            1253\nNumber of animals with one image 0\nNumber of unidentified animals   0\n\n\n\n\n\n\n\n\n\n\n\n\nCreate Query and Database Sets\n\nsplitter = splits.ClosedSetSplit(0.9)\nfor idx_database, idx_query in splitter.split(dataset.df):\n    df_database, df_query = dataset.df.loc[idx_database], dataset.df.loc[idx_query]\n    splits.analyze_split(dataset.df, idx_database, idx_query)\n\nSplit: time-unaware closed-set\nSamples: train/test/unassigned/total = 1043/210/0/1253\nClasses: train/test/unassigned/total = 207/207/0/207\nSamples: train only/test only        = 0/0\nClasses: train only/test only/joint  = 0/0/207\n\nFraction of train set     = 83.24%\nFraction of test set only = 0.00%\n\n\n\n\nTest MegaDescriptor\n\ntransform = T.Compose([T.Resize([384, 384]), T.ToTensor(), T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\ndataset_database = datasets.WildlifeDataset(df=df_database, root=dataset.root, transform=transform)\ndataset_query = datasets.WildlifeDataset(df=df_query, root=dataset.root, transform=transform)\n\n\nname = 'hf-hub:BVRA/MegaDescriptor-L-384'\ndevice = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\nextractor = DeepFeatures(timm.create_model(name, num_classes=0, pretrained=True), \n                         device=device,\n                         batch_size=32,\n                         num_workers=4,\n                         )\nprint(\"model loaded to device:\", device)\n\n2025-05-27 17:23:22.237805: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748366602.260419   47612 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748366602.267161   47612 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\n\nmodel loaded to device: cuda:1\n\n\n\nquery = extractor(CroppingImageDataset(dataset_query.df, root=dataset_query.root, transform=dataset_query.transform, crop_out=False))\ndatabase = extractor(CroppingImageDataset(dataset_database.df, root=dataset_database.root, transform=dataset_database.transform, crop_out=False))\n\n100%|█████████████████████████████████████████████████████████████████| 7/7 [00:18&lt;00:00,  2.63s/it]\n100%|███████████████████████████████████████████████████████████████| 33/33 [01:30&lt;00:00,  2.75s/it]\n\n\n\nsimilarity_function = CosineSimilarity()\nsimilarity = similarity_function(query, database)\n\n\ntop_5_classifier = TopkClassifier(k=5, database_labels=dataset_database.labels_string, return_all=True)\npredictions_top_5, scores_top_5, _ = top_5_classifier(similarity)\n\n\naccuracy_top_1 = np.mean(dataset_query.labels_string == predictions_top_5[:, 0])\naccuracy_top_5 = np.mean(np.any(predictions_top_5 == dataset_query.labels_string[:, np.newaxis], axis=1))\n\naccuracy_top_1, accuracy_top_5\n\n(0.8523809523809524, 0.8523809523809524, 0.9714285714285714)\n\n\n\ndef calculate_map(query_labels, database_labels, similarity_matrix):\n    \"\"\"\n    Calculate mean Average Precision (mAP) for retrieval task.\n    \n    Args:\n        query_labels: Array of query labels\n        database_labels: Array of database labels  \n        similarity_matrix: Similarity scores between queries and database\n    \n    Returns:\n        mAP: Mean Average Precision\n    \"\"\"\n    aps = []\n    \n    for i, query_label in enumerate(query_labels):\n        # Get similarity scores for this query\n        scores = similarity_matrix[i]\n        \n        # Create binary relevance labels (1 if same identity, 0 otherwise)\n        relevance = (database_labels == query_label).astype(int)\n        \n        # Calculate Average Precision for this query\n        if np.sum(relevance) &gt; 0:  # Only if there are relevant items\n            ap = average_precision_score(relevance, scores)\n            aps.append(ap)\n    \n    return np.mean(aps)\n\n# Calculate mAP\nmap_score = calculate_map(dataset_query.labels_string, dataset_database.labels_string, similarity)\nprint(f\"Mean Average Precision (mAP): {map_score:.4f}\")\n\nMean Average Precision (mAP): 0.6209\n\n\n\nsource\n\nplot_retrieval_results\n\n plot_retrieval_results (dataset_query, dataset_database,\n                         similarity_matrix, crop_out=False,\n                         mode='mistakes', num_results=4, num_queries=5,\n                         figsize=(15, 20))\n\n*Plot retrieval results showing query images and their most similar matches.\nArgs: dataset_query: Query dataset with images and labels dataset_database: Database dataset with images and labels similarity_matrix: Similarity scores between queries and database num_results: Number of top similar images to show per query num_queries: Number of query images to display figsize: Figure size for the plot*\n\n# Plot retrieval results\nplot_retrieval_results(dataset_query, dataset_database, similarity, num_results=4, num_queries=5)\n\n\n\n\n\n\n\n\n\n\n\nTest MiewID\n\nmiew_id_model = AutoModel.from_pretrained(\"conservationxlabs/miewid-msv2\", trust_remote_code=True)\n\nmiew_id_extractor = DeepFeatures(miew_id_model, \n                         device=device,\n                         batch_size=32,\n                         num_workers=4,\n                         )\n\nBuilding Model Backbone for efficientnetv2_rw_m model\nconfig.model_name efficientnetv2_rw_m\nmodel_name efficientnetv2_rw_m\n\n\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for conv_stem.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.0.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.0.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.1.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.1.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.2.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.2.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.0.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.0.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.0.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.1.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.1.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.2.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.2.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.3.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.3.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.4.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.4.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.1.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.0.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.0.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.1.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.1.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.2.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.2.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.3.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.3.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.4.conv_exp.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.4.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.2.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.6.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.3.7.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.6.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.7.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.8.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.9.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.10.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.11.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.12.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.13.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.4.14.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.6.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.7.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.8.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.9.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.10.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.11.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.12.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.13.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.14.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.15.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.16.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.17.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.18.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.19.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.20.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.21.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.22.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.conv_pw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.conv_dw.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.se.conv_reduce.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.se.conv_reduce.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.se.conv_expand.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.se.conv_expand.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.conv_pwl.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for blocks.5.23.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for conv_head.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n  warnings.warn(\n\n\nfinal_in_features 2152\n\n\n\nmiew_id_query = miew_id_extractor(ImageDataset(dataset_query.df, root=dataset_query.root, transform=dataset_query.transform))\nmiew_id_database = miew_id_extractor(ImageDataset(dataset_database.df, root=dataset_database.root, transform=dataset_database.transform))\n\n100%|█████████████████████████████████████████████████████████████████| 7/7 [00:08&lt;00:00,  1.15s/it]\n100%|███████████████████████████████████████████████████████████████| 33/33 [00:27&lt;00:00,  1.22it/s]\n\n\n\nmiew_id_similarity = similarity_function(miew_id_query, miew_id_database)\nmiew_id_predictions_top_5, miew_id_scores_top_5, _ = top_5_classifier(miew_id_similarity)\n\n\nmiew_id_accuracy_top_1 = np.mean(dataset_query.labels_string == miew_id_predictions_top_5[:, 0])\nmiew_id_accuracy_top_5 = np.mean(np.any(miew_id_predictions_top_5 == dataset_query.labels_string[:, np.newaxis], axis=1))\n\nmiew_id_accuracy_top_1, miew_id_accuracy_top_5\n\n(0.9333333333333333, 0.9333333333333333, 0.9761904761904762)\n\n\n\nmiew_id_map_score = calculate_map(dataset_query.labels_string, dataset_database.labels_string, miew_id_similarity)\nmiew_id_map_score\n\n0.7022891902605303\n\n\n\nplot_retrieval_results(dataset_query, dataset_database, miew_id_similarity, mode=\"mistakes\", num_results=4, num_queries=5)\n\n\n\n\n\n\n\n\n\n\nTest on Cropped Newts\n\ncropped_mega_query = extractor(CroppingImageDataset(dataset_query.df, root=dataset_query.root, transform=dataset_query.transform))\ncropped_mega_database = extractor(CroppingImageDataset(dataset_database.df, root=dataset_database.root, transform=dataset_database.transform))\n\n100%|█████████████████████████████████████████████████████████████████| 7/7 [00:25&lt;00:00,  3.64s/it]\n100%|███████████████████████████████████████████████████████████████| 33/33 [01:36&lt;00:00,  2.93s/it]\n\n\n\ncropped_mega_similarity = similarity_function(cropped_mega_query, cropped_mega_database)\ncropped_mega_predictions_top_5, cropped_mega_scores_top_5, _ = top_5_classifier(cropped_mega_similarity)\n\n\ncropped_mega_accuracy_top_1 = np.mean(dataset_query.labels_string == cropped_mega_predictions_top_5[:, 0])\ncropped_mega_accuracy_top_5 = np.mean(np.any(cropped_mega_predictions_top_5 == dataset_query.labels_string[:, np.newaxis], axis=1))\n\ncropped_mega_accuracy_top_1, cropped_mega_accuracy_top_5\n\n(0.6285714285714286, 0.6285714285714286, 0.7761904761904762)\n\n\n\ncropped_mega_map_score = calculate_map(dataset_query.labels_string, dataset_database.labels_string, cropped_mega_similarity)\ncropped_mega_map_score\n\n0.3916774944167913\n\n\n\nplot_retrieval_results(dataset_query, dataset_database, cropped_mega_similarity, crop_out=True, mode=\"mistakes\", num_results=4, num_queries=5)\n\n\n\n\n\n\n\n\n\n\nTest Cropped out newts on MiewID\n\nmiew_id_cropped_query = miew_id_extractor(CroppingImageDataset(dataset_query.df, root=dataset_query.root, transform=dataset_query.transform))\nmiew_id_cropped_database = miew_id_extractor(CroppingImageDataset(dataset_database.df, root=dataset_database.root, transform=dataset_database.transform))\n\n100%|█████████████████████████████████████████████████████████████████| 7/7 [00:13&lt;00:00,  1.88s/it]\n100%|███████████████████████████████████████████████████████████████| 33/33 [00:51&lt;00:00,  1.55s/it]\n\n\n\nmiew_id_cropped_similarity = similarity_function(miew_id_cropped_query, miew_id_cropped_database)\nmiew_id_cropped_predictions_top_5, miew_id_cropped_scores_top_5, _ = top_5_classifier(miew_id_cropped_similarity)\n\n\nmiew_id_cropped_accuracy_top_1 = np.mean(dataset_query.labels_string == miew_id_cropped_predictions_top_5[:, 0])\nmiew_id_cropped_accuracy_top_5 = np.mean(np.any(miew_id_cropped_predictions_top_5 == dataset_query.labels_string[:, np.newaxis], axis=1))\n\nmiew_id_cropped_accuracy_top_1, miew_id_cropped_accuracy_top_5\n\n(0.6714285714285714, 0.7571428571428571)\n\n\n\nmiew_id_cropped_map_score = calculate_map(dataset_query.labels_string, dataset_database.labels_string, miew_id_cropped_similarity)\nmiew_id_cropped_map_score\n\n0.3966437532673124\n\n\n\nplot_retrieval_results(dataset_query, dataset_database, miew_id_cropped_similarity, crop_out=True, mode=\"mistakes\", num_results=4, num_queries=5)\n\n\n\n\n\n\n\n\n\n\nCreate a dataframe of the results\n\nresults = pd.DataFrame({\n    \"model\": [\"MegaDescriptor-L-384\", \"MiewID\", \"MegaDescriptor-L-384 (cropped)\", \"MiewID (cropped)\"],\n    \"accuracy_top_5\": [accuracy_top_5, miew_id_accuracy_top_5, cropped_mega_accuracy_top_5, miew_id_cropped_accuracy_top_5],\n    \"accuracy_top_1\": [accuracy_top_1, miew_id_accuracy_top_1, cropped_mega_accuracy_top_1, miew_id_cropped_accuracy_top_1],\n    \"map_score\": [map_score, miew_id_map_score, cropped_mega_map_score, miew_id_cropped_map_score]\n})\n\nresults\n\n\n\n\n\n\n\n\nmodel\naccuracy_top_5\naccuracy_top_1\nmap_score\n\n\n\n\n0\nMegaDescriptor-L-384\n0.971429\n0.852381\n0.620877\n\n\n1\nMiewID\n0.976190\n0.933333\n0.702289\n\n\n2\nMegaDescriptor-L-384 (cropped)\n0.776190\n0.628571\n0.391677\n\n\n3\nMiewID (cropped)\n0.757143\n0.671429\n0.396644\n\n\n\n\n\n\n\n\nresults.set_index(\"model\").transpose().plot.bar(figsize=(10, 5), rot=0)\n\n\n\n\n\n\n\n\n\nimport nbdev\nnbdev.export.nbdev_export()",
    "crumbs": [
      "Newt Current"
    ]
  },
  {
    "objectID": "attribution.html",
    "href": "attribution.html",
    "title": "Attribution–the attribution toolkit",
    "section": "",
    "text": "import os\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as T\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport kaggle\nimport timm\nfrom pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nimport pandas as pd\nimport cv2\nfrom captum.attr import IntegratedGradients, Occlusion, FeaturePermutation\nfrom scipy.ndimage import gaussian_filter\n# from captum.attr._utils.masking import_mask # Corrected import\n\ndevice = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n# Download dataset from Kaggle only if it does not exist\ndataset_dir = './data/barhill'\nif not os.path.exists(dataset_dir):\n    kaggle.api.dataset_download_files('mshahoyi/barhills-processed', path='./data', unzip=True)\n    print(\"Dataset downloaded and unzipped.\")\nelse:\n    print(\"Dataset already exists. Skipping download.\")\n# Load the pretrained MegaDescriptor model\nmodel_name = 'hf-hub:BVRA/MegaDescriptor-T-224'\nmodel = timm.create_model(model_name, num_classes=0, pretrained=True).to(device)\nmodel.eval()\n# Define image transformations\ntransform = T.Compose([\n    T.Resize((224, 224)),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n# Load metadata\nmetadata_path = './data/barhill/gallery_and_probes.csv'\ndf = pd.read_csv(metadata_path)\n# Select two random newts\nunique_newts = df['newt_id'].unique()\nnp.random.seed(42)\nrandom_newts = np.random.choice(unique_newts, 2, replace=False)\n# random_newts[0] and random_newts[1] are guaranteed to be different newt IDs\n# (assuming there are at least 2 unique newts in your dataset).\nprint(f\"Selected newts: {random_newts}\")\n# Get sample images for each newt\nnewt1_images = df[df['newt_id'] == random_newts[0]]['image_path'].values[:2]\nnewt2_images = df[df['newt_id'] == random_newts[1]]['image_path'].values[:2]\n\nprint(f\"Newt 1 images: {newt1_images}\")\nprint(f\"Newt 2 images: {newt2_images}\")\n# Plot the selected images for visual confirmation\nfig, axes = plt.subplots(2, 2, figsize=(10, 10))\nfig.suptitle(\"Selected Images for Analysis\", fontsize=16)\n\n# Load and preprocess images\ndef get_full_image_path(rel_path):\n    return os.path.join('./data', rel_path)\n\n\n# Newt 1, Image 1\nimg_n1_i1 = Image.open(get_full_image_path(newt1_images[0])).convert('RGB')\naxes[0, 0].imshow(img_n1_i1)\naxes[0, 0].set_title(f\"Newt {random_newts[0]} - Image 1\\n{newt1_images[0]}\")\naxes[0, 0].axis('off')\n\n# Newt 1, Image 2\nif len(newt1_images) &gt; 1:\n    img_n1_i2 = Image.open(get_full_image_path(newt1_images[1])).convert('RGB')\n    axes[0, 1].imshow(img_n1_i2)\n    axes[0, 1].set_title(f\"Newt {random_newts[0]} - Image 2\\n{newt1_images[1]}\")\n    axes[0, 1].axis('off')\nelse:\n    axes[0, 1].axis('off') # Hide subplot if no second image\n    axes[0, 1].text(0.5, 0.5, 'No second image', ha='center', va='center')\n\n\n# Newt 2, Image 1\nimg_n2_i1 = Image.open(get_full_image_path(newt2_images[0])).convert('RGB')\naxes[1, 0].imshow(img_n2_i1)\naxes[1, 0].set_title(f\"Newt {random_newts[1]} - Image 1\\n{newt2_images[0]}\")\naxes[1, 0].axis('off')\n\n# Newt 2, Image 2\nif len(newt2_images) &gt; 1:\n    img_n2_i2 = Image.open(get_full_image_path(newt2_images[1])).convert('RGB')\n    axes[1, 1].imshow(img_n2_i2)\n    axes[1, 1].set_title(f\"Newt {random_newts[1]} - Image 2\\n{newt2_images[1]}\")\n    axes[1, 1].axis('off')\nelse:\n    axes[1, 1].axis('off') # Hide subplot if no second image\n    axes[1, 1].text(0.5, 0.5, 'No second image', ha='center', va='center')\n\nplt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\nplt.show()\ndef load_and_preprocess_image(image_path):\n    img = Image.open(image_path).convert('RGB')\n    input_tensor = transform(img)\n    return img, input_tensor.unsqueeze(0)\nnewt1_img1, newt1_tensor1 = load_and_preprocess_image(get_full_image_path(newt1_images[0]))\nnewt1_img2, newt1_tensor2 = load_and_preprocess_image(get_full_image_path(newt1_images[1]))\nnewt2_img1, newt2_tensor1 = load_and_preprocess_image(get_full_image_path(newt2_images[0]))\nnewt2_img2, newt2_tensor2 = load_and_preprocess_image(get_full_image_path(newt2_images[1]))\nclass SimilarityModel(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n        \n    def forward(self, x1, x2):\n        # Get features from both images\n        features1 = self.backbone(x1)\n        features2 = self.backbone(x2)\n        \n        # Calculate cosine similarity\n        similarity = torch.nn.functional.cosine_similarity(features1, features2)\n        return similarity\n# Create the similarity model\nsimilarity_model = SimilarityModel(model).to(device)\nsimilarity_model.eval()",
    "crumbs": [
      "Attribution--the attribution toolkit"
    ]
  },
  {
    "objectID": "attribution.html#occlusion-sensitivity",
    "href": "attribution.html#occlusion-sensitivity",
    "title": "Attribution–the attribution toolkit",
    "section": "Occlusion Sensitivity",
    "text": "Occlusion Sensitivity\n\nsource\n\nmy_occlusion_sensitivity\n\n my_occlusion_sensitivity (model, image1, image2, patch_size=16, stride=8,\n                           occlusion_value=0, device=None)\n\n*Perform occlusion sensitivity test on the first image to see which regions affect similarity with the second image.\nArgs: model: The similarity model image1: First image tensor (to be occluded) - shape [1, C, H, W] image2: Second image tensor - shape [1, C, H, W] patch_size: Size of the occlusion patch stride: Stride for moving the occlusion patch occlusion_value: Value used for occlusion (default: 0)\nReturns: Sensitivity map showing which regions, when occluded, affect similarity the most*\n\ndef occlusion_sensitivity(model, image1, image2, patch_size=16, stride=8, occlusion_value=0):\n    \"\"\"\n    Perform occlusion sensitivity test on the first image to see which regions\n    affect similarity with the second image using Captum.\n    \n    Args:\n        model: The similarity model\n        image1: First image tensor (to be occluded) - shape [1, C, H, W]\n        image2: Second image tensor - shape [1, C, H, W]\n        patch_size: Size of the occlusion patch\n        stride: Stride for moving the occlusion patch\n        occlusion_value: Value used for occlusion (default: 0)\n        \n    Returns:\n        Sensitivity map showing which regions, when occluded, affect similarity the most\n    \"\"\"    \n    # Move tensors to the right device\n    image1 = image1.to(device)\n    image2 = image2.to(device)\n    \n    # Create a wrapper function for the model that takes a single input\n    # This needs to be an nn.Module for Captum's hooks\n    class ModelWrapper(nn.Module):\n        def __init__(self, similarity_model_instance, fixed_image_tensor):\n            super().__init__()\n            self.similarity_model_instance = similarity_model_instance\n            self.fixed_image_tensor = fixed_image_tensor\n            self.similarity_model_instance.eval() # Ensure eval mode\n        \n        def forward(self, x):\n            return self.similarity_model_instance(x, self.fixed_image_tensor)\n\n    wrapped_model_for_captum = ModelWrapper(model, image2).to(device)\n    wrapped_model_for_captum.eval()\n    \n    # Initialize the Occlusion attribution method\n    occlusion_attr = Occlusion( # Renamed to avoid conflict with captum.attr.Occlusion\n        wrapped_model_for_captum\n    )\n    \n    # Compute attributions\n    attributions = occlusion_attr.attribute(\n        image1,\n        strides=(3, stride, stride),  # (channels, height, width)\n        sliding_window_shapes=(3, patch_size, patch_size),\n        baselines=occlusion_value,\n        target=None,  # Corrected: Use None for scalar output per batch item\n    )\n    \n    # Convert attributions to sensitivity map\n    # The output of occlusion.attribute is typically [N, C, H, W]\n    # We want to see the impact, so taking the absolute difference or sum can be useful.\n    # Here, let's consider the sum of attributions across channels.\n    # A common way to interpret occlusion is that a large magnitude (positive or negative)\n    # in attribution for a region means occluding it changed the output significantly.\n    # The sign indicates direction. If baseline is 0, and output drops, attribution might be negative.\n    # Let's sum attributions and then take absolute for magnitude of change.\n    # Or, if we want to see \"what makes the score drop\", we might not take abs if original_score - perturbed_score is calculated.\n    # Captum's Occlusion gives attribution of occluded region towards output.\n    # A simple way to get a per-pixel map is to average over the channel dimension.\n    \n    sensitivity_map = attributions.squeeze(0).abs().mean(dim=0).cpu().detach() # .detach() is good practice\n    \n    # Normalize the sensitivity map for visualization\n    if sensitivity_map.max() &gt; 0:\n        sensitivity_map = (sensitivity_map - sensitivity_map.min()) / (sensitivity_map.max() - sensitivity_map.min())\n    \n    return sensitivity_map.numpy()\n\n\ndef visualize_occlusion_sensitivity(image, sensitivity_map, title):\n    \"\"\"\n    Visualize the occlusion sensitivity map overlaid on the original image.\n    \n    Args:\n        image: Original PIL image\n        sensitivity_map: The computed sensitivity map\n        title: Title for the plot\n    \"\"\"\n    # Resize sensitivity map to match image dimensions\n    resized_map = cv2.resize(sensitivity_map, (image.size[0], image.size[1]))\n    \n    # Convert PIL image to numpy array and normalize\n    img_array = np.array(image) / 255.0\n    \n    # Create a heatmap visualization\n    heatmap = cv2.applyColorMap(np.uint8(255 * resized_map), cv2.COLORMAP_JET)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0\n    \n    # Overlay the heatmap on the image\n    overlay = 0.7 * img_array + 0.3 * heatmap\n    overlay = overlay / np.max(overlay)\n    \n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(resized_map, cmap='jet')\n    plt.title(\"Sensitivity Map\")\n    plt.colorbar(fraction=0.046, pad=0.04)\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(overlay)\n    plt.title(f\"Overlay - {title}\")\n    plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n\n# Perform occlusion sensitivity testing on same newt pair\nprint(\"Performing occlusion sensitivity test for same newt...\")\nsensitivity_map_same = occlusion_sensitivity(\n    similarity_model, \n    newt1_tensor1, \n    newt1_tensor2, \n    patch_size=16, \n    stride=8\n)\n\n\n# Visualize occlusion sensitivity results\nvisualize_occlusion_sensitivity(\n    newt1_img1,\n    sensitivity_map_same,\n    f\"Same Newt {random_newts[0]} - Regions Important for Similarity\"\n)\n\n\n# Perform MY occlusion sensitivity testing on same newt pair\nprint(\"Performing MY occlusion sensitivity test for same newts...\")\nsensitivity_map_same = my_occlusion_sensitivity(\n    similarity_model,\n    newt1_tensor1,  \n    newt1_tensor2,  \n    patch_size=16,\n    stride=8\n)\n\n# Visualize occlusion sensitivity results\nvisualize_occlusion_sensitivity(\n    newt1_img1,\n    sensitivity_map_same,\n    f\"Same Newt {random_newts[0]} - Regions Important for Similarity\"\n)\n\n\n# Perform occlusion sensitivity testing on different newt pair\nprint(\"Performing occlusion sensitivity test for different newts...\")\nsensitivity_map_diff = occlusion_sensitivity(\n    similarity_model,\n    newt1_tensor1,  # Image of newt_ID_A (this one will be occluded)\n    newt2_tensor1,  # Image of newt_ID_B (this is the reference for similarity)\n    patch_size=16,\n    stride=8\n)\n\n# Visualize occlusion sensitivity results\nvisualize_occlusion_sensitivity(\n    newt1_img1,\n    sensitivity_map_diff,\n    f\"Different Newts {random_newts[0]} vs {random_newts[1]} - Regions Important for Similarity\"\n)\n\n\n# Perform MY occlusion sensitivity testing on different newt pair\nprint(\"Performing MY occlusion sensitivity test for different newts...\")\nsensitivity_map_diff = my_occlusion_sensitivity(\n    similarity_model,\n    newt1_tensor1,  # Image of newt_ID_A (this one will be occluded)\n    newt2_tensor1,  # Image of newt_ID_B (this is the reference for similarity)\n    patch_size=16,\n    stride=8\n)\n\n# Visualize occlusion sensitivity results\nvisualize_occlusion_sensitivity(\n    newt1_img1,\n    sensitivity_map_diff,\n    f\"Different Newts {random_newts[0]} vs {random_newts[1]} - Regions Important for Similarity\"\n)",
    "crumbs": [
      "Attribution--the attribution toolkit"
    ]
  },
  {
    "objectID": "attribution.html#integrated-gradients",
    "href": "attribution.html#integrated-gradients",
    "title": "Attribution–the attribution toolkit",
    "section": "Integrated Gradients",
    "text": "Integrated Gradients\n\ndef integrated_gradients_similarity(model_instance, image1_tensor, image2_tensor, n_steps=50, target_output_idx=None):\n    \"\"\"\n    Compute Integrated Gradients for the first image with respect to the similarity\n    score with the second image.\n    \n    Args:\n        model_instance: The SimilarityModel instance (which is an nn.Module).\n        image1_tensor: Tensor of the first image (to attribute). Shape [1, C, H, W].\n        image2_tensor: Tensor of the second image (fixed reference). Shape [1, C, H, W].\n        n_steps: Number of steps for the integration.\n        target_output_idx: If model outputs multiple values, specify index. For scalar output, can be None.\n\n    Returns:\n        Attributions for image1_tensor.\n    \"\"\"\n    model_instance.eval() # Ensure the main model is in eval mode\n    image1_tensor = image1_tensor.to(device)\n    image2_tensor = image2_tensor.to(device)\n\n    # Ensure tensors require gradients\n    image1_tensor.requires_grad_()\n\n    # Define a wrapper nn.Module for Captum\n    class ModelWrapper(nn.Module):\n        def __init__(self, similarity_model_instance, fixed_image_tensor):\n            super().__init__()\n            self.similarity_model_instance = similarity_model_instance\n            self.fixed_image_tensor = fixed_image_tensor\n            # Ensure the passed model instance is also in eval mode if it wasn't already\n            self.similarity_model_instance.eval() \n        \n        def forward(self, img1_input):\n            return self.similarity_model_instance(img1_input, self.fixed_image_tensor)\n\n    wrapped_model = ModelWrapper(model_instance, image2_tensor).to(device)\n    wrapped_model.eval() \n\n    ig = IntegratedGradients(wrapped_model)\n    \n    baseline = torch.zeros_like(image1_tensor).to(device)\n    \n    attributions = ig.attribute(image1_tensor,\n                                baselines=baseline,\n                                target=target_output_idx, \n                                n_steps=n_steps,\n                                return_convergence_delta=False) \n    return attributions\n\n\ndef visualize_integrated_gradients(image_pil, attributions_tensor, title):\n    \"\"\"\n    Visualize Integrated Gradients attributions.\n    \"\"\"\n    # Convert attributions to numpy array and take the sum across color channels\n    attributions_np = attributions_tensor.squeeze().cpu().detach().numpy()\n    attributions_np = np.transpose(attributions_np, (1, 2, 0))\n    attribution_map = np.sum(np.abs(attributions_np), axis=2) # Sum absolute attributions across channels\n    \n    # Normalize the attribution map for visualization\n    if np.max(attribution_map) &gt; 0:\n        attribution_map = (attribution_map - np.min(attribution_map)) / (np.max(attribution_map) - np.min(attribution_map))\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n    fig.suptitle(title, fontsize=16)\n    \n    axes[0].imshow(image_pil)\n    axes[0].set_title(\"Original Image\")\n    axes[0].axis('off')\n    \n    im = axes[1].imshow(attribution_map, cmap='inferno') # 'inferno' or 'viridis' are good choices\n    axes[1].set_title(\"Integrated Gradients Attribution\")\n    axes[1].axis('off')\n    fig.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n    \n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.show()\n\n\n# Perform Integrated Gradients for the same newt pair\n# We are interested in how image1 contributes to similarity with image2\nprint(\"Performing Integrated Gradients for same newt (image1 vs image2)...\")\nattributions_same_newt_img1 = integrated_gradients_similarity(\n    similarity_model,\n    newt1_tensor1, # Image to attribute\n    newt1_tensor2  # Fixed reference image\n)\nvisualize_integrated_gradients(\n    newt1_img1, # PIL image corresponding to newt1_tensor1\n    attributions_same_newt_img1,\n    f\"IG: Newt {random_newts[0]} (Img 1) vs Newt {random_newts[0]} (Img 2)\"\n)\n\n# Perform Integrated Gradients for the different newt pair\n# We are interested in how image1 (from newt A) contributes to similarity with image1 (from newt B)\nprint(\"\\nPerforming Integrated Gradients for different newts (newt A img1 vs newt B img1)...\")\nattributions_diff_newt_img1 = integrated_gradients_similarity(\n    similarity_model,\n    newt1_tensor1, # Image to attribute (from first newt)\n    newt2_tensor1  # Fixed reference image (from second newt)\n)\nvisualize_integrated_gradients(\n    newt1_img1, # PIL image corresponding to newt1_tensor1\n    attributions_diff_newt_img1,\n    f\"IG: Newt {random_newts[0]} (Img 1) vs Newt {random_newts[1]} (Img 1)\"\n)",
    "crumbs": [
      "Attribution--the attribution toolkit"
    ]
  },
  {
    "objectID": "attribution.html#blur-perturbation",
    "href": "attribution.html#blur-perturbation",
    "title": "Attribution–the attribution toolkit",
    "section": "Blur Perturbation",
    "text": "Blur Perturbation\n\ndef blur_perturbation_similarity(model_instance, image1_tensor, image2_tensor, patch_size=16, stride=8, blur_sigma=5):\n    \"\"\"\n    Perform perturbation-based saliency by blurring patches of image1 and observing\n    the change in similarity with image2.\n    \n    Args:\n        model_instance: The SimilarityModel instance.\n        image1_tensor: Tensor of the first image (to be perturbed). Shape [1, C, H, W].\n        image2_tensor: Tensor of the second image (fixed reference). Shape [1, C, H, W].\n        patch_size: Size of the patch to blur.\n        stride: Stride for moving the patch.\n        blur_sigma: Sigma for Gaussian blur.\n        \n    Returns:\n        Sensitivity map (higher values mean blurring that region decreased similarity more).\n    \"\"\"\n    model_instance.eval()\n    image1_tensor_cpu = image1_tensor.cpu() # Work with CPU tensor for easier numpy conversion and blurring\n    image2_tensor_dev = image2_tensor.to(device) # Keep image2 on device for model input\n\n    # Get the original similarity score\n    with torch.no_grad():\n        original_similarity = model_instance(image1_tensor.to(device), image2_tensor_dev).item()\n    \n    # Get image dimensions\n    _, c, h, w = image1_tensor_cpu.shape\n    \n    # Initialize sensitivity map\n    sensitivity_map = torch.zeros((h, w), device='cpu')\n    \n    # Create a blurred version of the entire image1 (used for replacing patches)\n    # Convert tensor to numpy for blurring: (C, H, W)\n    image1_numpy = image1_tensor_cpu.squeeze(0).numpy() \n    blurred_image1_numpy = np.zeros_like(image1_numpy)\n    for channel_idx in range(c):\n        blurred_image1_numpy[channel_idx, :, :] = gaussian_filter(image1_numpy[channel_idx, :, :], sigma=blur_sigma)\n    \n    # Compute number of patches\n    n_h_patches = (h - patch_size) // stride + 1\n    n_w_patches = (w - patch_size) // stride + 1\n    \n    total_patches = n_h_patches * n_w_patches\n    patch_count = 0\n    \n    print(f\"Starting blur perturbation: {total_patches} patches to process...\")\n    for i in range(0, h - patch_size + 1, stride):\n        for j in range(0, w - patch_size + 1, stride):\n            perturbed_image_numpy = image1_numpy.copy()\n            \n            # Replace the patch with the corresponding patch from the blurred image\n            perturbed_image_numpy[:, i:i+patch_size, j:j+patch_size] = \\\n                blurred_image1_numpy[:, i:i+patch_size, j:j+patch_size]\n            \n            # Convert back to tensor and move to device\n            perturbed_image_tensor = torch.from_numpy(perturbed_image_numpy).unsqueeze(0).to(device)\n            \n            with torch.no_grad():\n                perturbed_similarity = model_instance(perturbed_image_tensor, image2_tensor_dev).item()\n            \n            sensitivity = original_similarity - perturbed_similarity\n            sensitivity_map[i:i+patch_size, j:j+patch_size] += sensitivity # Accumulate if patches overlap\n            \n            patch_count += 1\n            if patch_count % 20 == 0 or patch_count == total_patches:\n                print(f\"Processed {patch_count}/{total_patches} patches...\", end='\\r')\n    \n    print(f\"\\nCompleted blur perturbation.\")\n    \n    # Normalize the sensitivity map\n    if sensitivity_map.abs().max() &gt; 0: # Check against absolute max to handle negative sensitivities too\n         # Center around 0 then scale, or just scale positive changes\n        if sensitivity_map.max() &gt; sensitivity_map.min() and not (sensitivity_map.max() == 0 and sensitivity_map.min() == 0) :\n            sensitivity_map = (sensitivity_map - sensitivity_map.min()) / (sensitivity_map.max() - sensitivity_map.min())\n        elif sensitivity_map.max() &gt; 0 : # if all values are same and positive\n             sensitivity_map = sensitivity_map / sensitivity_map.max()\n\n\n    return sensitivity_map.numpy()\n\n\n# We can reuse visualize_occlusion_sensitivity, let's call it visualize_perturbation_map\n# or just use it as is if the title parameter is sufficient.\n# For consistency, I'll use the existing visualize_occlusion_sensitivity function.\n\n# Perform Blur Perturbation for the same newt pair\nprint(\"Performing Blur Perturbation for same newt (image1 vs image2)...\")\nblur_map_same_newt = blur_perturbation_similarity(\n    similarity_model,\n    newt1_tensor1, \n    newt1_tensor2,\n    patch_size=24, # Larger patch might be more informative for blur\n    stride=12,\n    blur_sigma=5\n)\nvisualize_occlusion_sensitivity( # Reusing the visualization function\n    newt1_img1,\n    blur_map_same_newt,\n    f\"Blur Perturbation: Newt {random_newts[0]} (Img 1) vs Newt {random_newts[0]} (Img 2)\"\n)\n\n# Perform Blur Perturbation for the different newt pair\nprint(\"\\nPerforming Blur Perturbation for different newts (newt A img1 vs newt B img1)...\")\nblur_map_diff_newt = blur_perturbation_similarity(\n    similarity_model,\n    newt1_tensor1, \n    newt2_tensor1,\n    patch_size=24,\n    stride=12,\n    blur_sigma=5\n)\nvisualize_occlusion_sensitivity( # Reusing the visualization function\n    newt1_img1,\n    blur_map_diff_newt,\n    f\"Blur Perturbation: Newt {random_newts[0]} (Img 1) vs Newt {random_newts[1]} (Img 1)\"\n)",
    "crumbs": [
      "Attribution--the attribution toolkit"
    ]
  },
  {
    "objectID": "baselines.html",
    "href": "baselines.html",
    "title": "Baselines",
    "section": "",
    "text": "import os\nimport sys\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom wildlife_datasets import analysis, datasets, splits\nimport pycocotools.mask as mask_util\nfrom wildlife_tools.data import ImageDataset\nfrom sklearn.metrics import average_precision_score\nimport numpy as np\nimport timm\nfrom transformers import AutoModel\nimport torch\nimport numpy as np\nfrom wildlife_tools.inference import TopkClassifier, KnnClassifier\nfrom wildlife_tools.features import DeepFeatures\nimport torchvision.transforms as T\nfrom PIL import Image\nimport kaggle\nimport pandas as pd\nfrom wildlife_tools.data import ImageDataset, FeatureDataset, FeatureDatabase\nfrom gcn_reid.segmentation import decode_rle_mask\nfrom gcn_reid.newt_dataset import upload_to_kaggle\nfrom pathlib import Path\nfrom gcn_reid.newt_dataset import download_kaggle_dataset\nfrom tqdm import tqdm\nfrom transformers import AutoImageProcessor, AutoModel\nimport cv2\n\n2025-06-26 16:41:47.199241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750956107.222767   89844 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750956107.229954   89844 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\ndataset_name = 'mshahoyi/gcn-id-2024'\ndataset_path = Path('data/gcn-id-2024')\ndownload_kaggle_dataset(dataset_name, dataset_path)\n\nDataset already exists at data/gcn-id-2024\n\n\nPosixPath('data/gcn-id-2024')\nmega = timm.create_model('hf-hub:BVRA/MegaDescriptor-L-384', pretrained=True, num_classes=0)\nmiewid = AutoModel.from_pretrained(\"conservationxlabs/miewid-msv2\", trust_remote_code=True)",
    "crumbs": [
      "Baselines"
    ]
  },
  {
    "objectID": "baselines.html#run-both-models-on-all-test-sets-and-save-the-results",
    "href": "baselines.html#run-both-models-on-all-test-sets-and-save-the-results",
    "title": "Baselines",
    "section": "Run both models on all test sets and save the results",
    "text": "Run both models on all test sets and save the results\nArtifacts are a dataframe like the newt dataframe but that contains two new columns representing the mega and miewid embeddings.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmega_extractor = DeepFeatures(mega, device=device, batch_size=32, num_workers=4)\nmiewid_extractor = DeepFeatures(miewid, device=device, batch_size=32, num_workers=4)\n\n\ndf = pd.read_csv(dataset_path / 'metadata.csv')\nmask = df.is_hard_test_query.notna() | df.is_least_similar_test_query.notna() | df.is_random_test_query.notna()\ndf = df[mask & ~df.is_video].reset_index(drop=True).rename(columns={\"file_name\": \"image_name\", \"file_path\": \"path\"})\ndf\n\n\n\n\n\n\n\n\nreference_id\npath\nimage_name\nis_video\nidentity\ncreation_date\nbbox\nsegmentation_mask_rle\nis_hard_test_query\nis_hard_val_query\nis_least_similar_test_query\nis_least_similar_val_query\nis_random_test_query\nis_random_val_query\n\n\n\n\n0\nGCN34-P3-S2\nnewts/1/IMG_2532.JPEG\nIMG_2532.JPEG\nFalse\n1\n2024-05-10 08:37:21+00:00\n[14.939163208007812, 507.19061279296875, 1066....\n2048x1536:Sd`03ko14N0000000bNKcRN0^O5om1KcRN1]...\nNaN\nFalse\nNaN\nNaN\nTrue\nNaN\n\n\n1\nGCN34-P3-S2\nnewts/1/IMG_2530.JPEG\nIMG_2530.JPEG\nFalse\n1\n2024-05-10 08:37:19+00:00\n[288.80975341796875, 363.1075439453125, 1062.7...\n2048x1536:[ajb03;31K_n1:YQN10O4Knm1h0lQN_O2O0M...\nNaN\nFalse\nNaN\nNaN\nFalse\nNaN\n\n\n2\nGCN34-P3-S2\nnewts/1/IMG_2531.JPEG\nIMG_2531.JPEG\nFalse\n1\n2024-05-10 08:37:20+00:00\n[288.86181640625, 521.5284423828125, 1159.4096...\n2048x1536:Pcdb07^o1d0D7H=E5K5L5J5K3M4M3M10001N...\nNaN\nFalse\nNaN\nNaN\nFalse\nNaN\n\n\n3\nGCN34-P3-S2\nnewts/1/IMG_2533.JPEG\nIMG_2533.JPEG\nFalse\n1\n2024-05-10 08:37:23+00:00\n[489.2838134765625, 169.9361572265625, 1132.72...\n2048x1536:X`Vo06do1;H;dNH]RN&gt;[m1e1]O5M4K4M3M3L...\nNaN\nFalse\nNaN\nNaN\nFalse\nNaN\n\n\n4\nGCN34-P3-S2\nnewts/1/IMG_2534.JPEG\nIMG_2534.JPEG\nFalse\n1\n2024-05-10 08:37:24+00:00\n[365.6585388183594, 454.51068115234375, 1005.9...\n2048x1536:SmZd03lo13M3M2O1O1N2`QNJTm16gRN3Vm1M...\nNaN\nTrue\nNaN\nNaN\nFalse\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n418\nGCN7-P3-S6\nnewts/202/IMG_3618.JPEG\nIMG_3618.JPEG\nFalse\n202\n2024-06-07 08:17:00+00:00\n[173.46243286132812, 251.09988403320312, 1007....\n2046x1538:]UV;2m18ek14RSNJ_O159;@8:j0KRe10^YN2...\nFalse\nNaN\nFalse\nNaN\nNaN\nNaN\n\n\n419\nGCN7-P3-S6\nnewts/202/IMG_3617.JPEG\nIMG_3617.JPEG\nFalse\n202\n2024-06-07 08:16:56+00:00\n[333.4060974121094, 442.3371887207031, 1123.58...\n2046x1538:Rlde0g0km1G_RNDOQ1ol1POoRN\\2kl1`0J5T...\nFalse\nNaN\nFalse\nNaN\nNaN\nNaN\n\n\n420\nGCN7-P3-S6\nnewts/202/IMG_3616.JPEG\nIMG_3616.JPEG\nFalse\n202\n2024-06-07 08:16:55+00:00\n[372.7743225097656, 699.0594482421875, 1003.42...\n2046x1538:k_lg0;4Kan1c1SO`0D;G8J7H7L4K5L4M4L3M...\nTrue\nNaN\nFalse\nNaN\nNaN\nNaN\n\n\n421\nGCN7-P3-S6\nnewts/202/IMG_3615.JPEG\nIMG_3615.JPEG\nFalse\n202\n2024-06-07 08:16:54+00:00\n[414.04083251953125, 1346.5162353515625, 966.7...\n2046x1538:Ph`j0&lt;So1h0B?[Oc0Al0WO8I9Bc0C&lt;C6K6I6...\nFalse\nNaN\nTrue\nNaN\nNaN\nNaN\n\n\n422\nGCN7-P3-S6\nnewts/202/IMG_3619.JPEG\nIMG_3619.JPEG\nFalse\n202\n2024-06-07 08:17:01+00:00\n[581.1024780273438, 81.09144592285156, 1273.64...\n2046x1538:nRlU12ao1n0POP1gjNaNk:l1gD[NR;k1iD[N...\nFalse\nNaN\nFalse\nNaN\nNaN\nNaN\n\n\n\n\n423 rows × 14 columns\n\n\n\n\nmega_transform = T.Compose([T.Resize(384),\n                            T.CenterCrop(384),\n                            T.ToTensor(), \n                            T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]) \n\nmiewid_transform = T.Compose([\n    T.Resize(400),\n    T.CenterCrop(400),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nmega_transform_rotated = T.Compose([T.Resize(384),\n                            T.CenterCrop(384),\n                            T.RandomRotation([90, 90]),  # Add 90 degree clockwise rotation\n                            T.ToTensor(), \n                            T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]) \n\nmiewid_transform_rotated = T.Compose([\n    T.Resize(400),\n    T.CenterCrop(400),\n    T.RandomRotation([90, 90]),  # Add 90 degree clockwise rotation\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\nsource\n\nget_cropped_newt\n\n get_cropped_newt (path, rle)\n\n\nsource\n\n\nget_cropping_image_dataset\n\n get_cropping_image_dataset ()\n\n\nCroppingImageDataset = get_cropping_image_dataset()\n\nmega_cropping_dataset = CroppingImageDataset(df, root=dataset_path, transform=mega_transform, crop_out=True)\nmiewid_cropping_dataset = CroppingImageDataset(df, root=dataset_path, transform=miewid_transform, crop_out=True)\nmega_cropping_dataset_rotated = CroppingImageDataset(df, root=dataset_path, transform=mega_transform_rotated, crop_out=True)\nmiewid_cropping_dataset_rotated = CroppingImageDataset(df, root=dataset_path, transform=miewid_transform_rotated, crop_out=True)\n\nmega_dataset = ImageDataset(df, root=dataset_path, transform=mega_transform)\nmiewid_dataset = ImageDataset(df, root=dataset_path, transform=miewid_transform)\nmega_dataset_rotated = ImageDataset(df, root=dataset_path, transform=mega_transform_rotated)\nmiewid_dataset_rotated = ImageDataset(df, root=dataset_path, transform=miewid_transform_rotated)\n\n\nnum_images = 1\nfor i in range(num_images):\n    plt.subplot(1, num_images, i+1)\n    x, y = next(iter(mega_cropping_dataset_rotated))\n    plt.imshow(x.permute(1, 2, 0))\n    plt.axis('off')\n    plt.tight_layout()\n    plt.savefig('mega_images.png')\n\n\n\n\n\n\n\n\n\nartifacts_path = Path('artifacts')\nartifacts_path.mkdir(exist_ok=True)\nartifacts_name = 'baseline_features.csv'\n\n\nif not (artifacts_path/artifacts_name).exists():\n    mega_results = mega_extractor(mega_dataset)\n    miewid_results = miewid_extractor(miewid_dataset)\n    mega_results_cropped = mega_extractor(mega_cropping_dataset)\n    miewid_results_cropped = miewid_extractor(miewid_cropping_dataset)\n    mega_results_cropped_rotated = mega_extractor(mega_cropping_dataset_rotated)\n    miewid_results_cropped_rotated = miewid_extractor(miewid_cropping_dataset_rotated)\n    mega_results_rotated = mega_extractor(mega_dataset_rotated)\n    miewid_results_rotated = miewid_extractor(miewid_dataset_rotated)\n\n    df['mega_features'] = [features.tolist() for features in mega_results.features]\n    df['miewid_features'] = [features.tolist() for features in miewid_results.features]\n    df['mega_features_cropped'] = [features.tolist() for features in mega_results_cropped.features]\n    df['miewid_features_cropped'] = [features.tolist() for features in miewid_results_cropped.features]\n    df['mega_features_cropped_rotated'] = [features.tolist() for features in mega_results_cropped_rotated.features]\n    df['miewid_features_cropped_rotated'] = [features.tolist() for features in miewid_results_cropped_rotated.features]\n    df['mega_features_rotated'] = [features.tolist() for features in mega_results_rotated.features]\n    df['miewid_features_rotated'] = [features.tolist() for features in miewid_results_rotated.features]\n    df.to_csv(artifacts_path/artifacts_name, index=False)\nelse: \n    df = pd.read_csv(artifacts_path/artifacts_name)\n    df['mega_features'] = df['mega_features'].apply(eval)\n    df['miewid_features'] = df['miewid_features'].apply(eval)\n    df['mega_features_cropped'] = df['mega_features_cropped'].apply(eval)\n    df['miewid_features_cropped'] = df['miewid_features_cropped'].apply(eval)\n    df['mega_features_cropped_rotated'] = df['mega_features_cropped_rotated'].apply(eval)\n    df['miewid_features_cropped_rotated'] = df['miewid_features_cropped_rotated'].apply(eval)\n    df['mega_features_rotated'] = df['mega_features_rotated'].apply(eval)\n    df['miewid_features_rotated'] = df['miewid_features_rotated'].apply(eval)",
    "crumbs": [
      "Baselines"
    ]
  },
  {
    "objectID": "dataset_prep.html",
    "href": "dataset_prep.html",
    "title": "Newt Dataset Preparation",
    "section": "",
    "text": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport shutil\nfrom pathlib import Path\nfrom wildlife_datasets import datasets, analysis\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom PIL.ExifTags import TAGS\nfrom PIL import Image\nimport os\nimport exifread\nfrom pymediainfo import MediaInfo\n\n\n# Set pandas display options to show all columns and wide output\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\n\nsource\n\ndownload_kaggle_dataset\n\n download_kaggle_dataset (dataset_name, download_path)\n\n\ndownload_kaggle_dataset(\"mshahoyi/bar-hill-surveys\", \"./data/barhill-unprocessed\")\n\nDataset already exists at ./data/barhill-unprocessed\n\n\n'./data/barhill-unprocessed'\n\n\n\ndata_root = Path(\"./data/barhill-unprocessed\")/'Bar Hill Surveys 2024'\nwalk = list(os.walk(data_root))\nwalk[:4]\n\n[('data/barhill-unprocessed/Bar Hill Surveys 2024',\n  ['Survey 5 06_06_24',\n   'Survey 7 12_06_24',\n   'Survey 2 10_05_24',\n   'Survey 1 09_05_24',\n   'Survey 6 07_06_24',\n   'Survey 3 16_05_24',\n   'Survey 8 13_06_24',\n   'Survey 4 17_05_24'],\n  ['Bar Hill GCN Survey Results 2024.xlsx',\n   'ARU Research poster A1 (003) Ecoacoustics researching at Cambridge crematorium_edit (002).png',\n   'GCN Surveys at Cambridge Crematorium 2024.docx']),\n ('data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24',\n  ['Pond 4', 'Pond 3', 'Pond 2'],\n  []),\n ('data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4',\n  ['GCN1-P4-S5'],\n  []),\n ('data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5',\n  [],\n  ['IMG_3558.MOV',\n   'IMG_3551.MOV',\n   'IMG_3553.MOV',\n   'IMG_3555.JPEG',\n   'IMG_3556.JPEG',\n   'IMG_3556.MOV',\n   'IMG_3554.JPEG',\n   'IMG_3557.JPEG',\n   'IMG_3552.MOV',\n   'IMG_3551.JPEG',\n   'IMG_3557.MOV',\n   'IMG_3552.JPEG',\n   'IMG_3555.MOV',\n   'IMG_3553.JPEG',\n   'IMG_3554.MOV',\n   'IMG_3558.JPEG'])]\n\n\n\ngcns = [x for x in walk if 'gcn' in os.path.basename(x[0]).lower()]\ngcns[:2]\n\n[('data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5',\n  [],\n  ['IMG_3558.MOV',\n   'IMG_3551.MOV',\n   'IMG_3553.MOV',\n   'IMG_3555.JPEG',\n   'IMG_3556.JPEG',\n   'IMG_3556.MOV',\n   'IMG_3554.JPEG',\n   'IMG_3557.JPEG',\n   'IMG_3552.MOV',\n   'IMG_3551.JPEG',\n   'IMG_3557.MOV',\n   'IMG_3552.JPEG',\n   'IMG_3555.MOV',\n   'IMG_3553.JPEG',\n   'IMG_3554.MOV',\n   'IMG_3558.JPEG']),\n ('data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5',\n  [],\n  ['IMG_3564.JPEG',\n   'IMG_3565.MOV',\n   'IMG_3565.JPEG',\n   'IMG_3563.MOV',\n   'IMG_3561.MOV',\n   'IMG_3566.JPEG',\n   'IMG_3564.MOV',\n   'IMG_3562.MOV',\n   'IMG_3561.JPEG',\n   'IMG_3563.JPEG',\n   'IMG_3566.MOV',\n   'IMG_3562.JPEG'])]\n\n\n\ndata = [(os.path.basename(root), list(map(lambda f: os.path.join(root, f), files))) for root, _, files in gcns]\n\ndict(data[:2])\n\n{'GCN1-P4-S5': ['data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3558.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3551.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3553.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3555.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3556.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3556.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3554.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3557.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3552.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3551.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3557.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3552.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3555.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3553.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3554.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 4/GCN1-P4-S5/IMG_3558.JPEG'],\n 'GCN2-P3-S5': ['data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3564.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3565.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3565.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3563.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3561.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3566.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3564.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3562.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3561.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3563.JPEG',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3566.MOV',\n  'data/barhill-unprocessed/Bar Hill Surveys 2024/Survey 5 06_06_24/Pond 3/GCN2-P3-S5/IMG_3562.JPEG']}\n\n\n\nmetadata = pd.DataFrame(data).explode(1)\nmetadata.columns = [\"reference_id\", \"file_path\"]\nmetadata.shape\n\n(2504, 2)\n\n\n\nmetadata.head()\n\n\n\n\n\n\n\n\nidentity\nfile_path\n\n\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\n\n\n\n\n\n\n\n\nmetadata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 2504 entries, 0 to 206\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   identity   2504 non-null   object\n 1   file_path  2504 non-null   object\ndtypes: object(2)\nmemory usage: 58.7+ KB\n\n\n\nmetadata['file_name'] = metadata['file_path'].apply(lambda x: os.path.basename(x))\nmetadata['is_video'] = metadata['file_name'].apply(lambda x: 'mov' in x.lower())\nmetadata.head()\n\n\n\n\n\n\n\n\nidentity\nfile_path\nfile_name\nis_video\n\n\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_3558.MOV\nTrue\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_3551.MOV\nTrue\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_3553.MOV\nTrue\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_3555.JPEG\nFalse\n\n\n0\nGCN1-P4-S5\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_3556.JPEG\nFalse\n\n\n\n\n\n\n\n\nmapper = {reference_id: i+1 for i, reference_id in enumerate(metadata.reference_id.unique())}\nmetadata['identity'] = metadata.reference_id.map(mapper)\nmetadata\n\n\noutput_dir = Path(\"./data/gcns-processed\")\nshutil.rmtree(output_dir, ignore_errors=True)\nPath(output_dir).mkdir(exist_ok=True)\n\n\nclass UnprocessedNewtsDataset(datasets.WildlifeDataset):\n    def create_catalogue(self) -&gt; pd.DataFrame:\n        return metadata[~metadata.is_video].rename(columns={\"file_name\": \"image_name\", \"file_path\": \"path\"})\n\n\ndataset = UnprocessedNewtsDataset('.')\nplt.figure(figsize=(7, 7))\ndataset.plot_grid()\nplt.savefig(output_dir/'grid.png')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSplit the dataset\n\nplt.figure(figsize=(3.5, 3))\nplt.title(\"Number of images per identity\")\nanalysis.display_statistics(dataset.df)\nplt.savefig(output_dir/'distribution.png')\n\nNumber of identitites            204\nNumber of all animals            1252\nNumber of animals with one image 0\nNumber of unidentified animals   0\n\n\n\n\n\n\n\n\n\n\nn_files = len(metadata)\nn_images = len(metadata[~metadata.is_video])\nn_videos = len(metadata[metadata.is_video])\nn_identities = len(metadata.identity.unique())\nstats = {\n    \"n_files\": n_files,\n    \"n_images\": n_images,\n    \"n_videos\": n_videos,\n    \"n_identities\": n_identities\n}\npd.DataFrame(stats, index=[0]).to_csv(output_dir/'statistics.csv', index=False)\nstats\n\nSplit: time-unaware disjoint-set\nSamples: train/test/unassigned/total = 625/627/0/1252\nClasses: train/test/unassigned/total = 110/94/0/204\nSamples: train only/test only        = 625/627\nClasses: train only/test only/joint  = 110/94/0\n\nFraction of train set     = 49.92%\nFraction of test set only = 50.08%\nSplit: time-unaware disjoint-set\nSamples: train/test/unassigned/total = 312/315/0/627\nClasses: train/test/unassigned/total = 50/44/0/94\nSamples: train only/test only        = 312/315\nClasses: train only/test only/joint  = 50/44/0\n\nFraction of train set     = 49.76%\nFraction of test set only = 50.24%\nTrain: 625, Test: 312, Validation: 315\n\n\n\nmetadata_new = metadata.copy().reset_index(drop=True)\n\nfor i, row in tqdm(metadata_new.iterrows()):\n    new_path = Path('newts')/str(row.identity)/row.file_name\n    Path(output_dir/new_path).parent.mkdir(parents=True, exist_ok=True)\n    shutil.copy(row.file_path, output_dir/new_path)\n    metadata_new.loc[i, 'file_path'] = new_path\n\n\n\n\n\n\n\n\nidentity\npath\nimage_name\nis_video\n\n\n\n\n0\nGCN1-P1-S2\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_2312.JPEG\nFalse\n\n\n1\nGCN1-P1-S2\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_2310.JPEG\nFalse\n\n\n2\nGCN1-P1-S2\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_2309.JPEG\nFalse\n\n\n3\nGCN1-P1-S2\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_2311.JPEG\nFalse\n\n\n4\nGCN1-P1-S2\ndata/barhill-unprocessed/Bar Hill Surveys 2024...\nIMG_2313.JPEG\nFalse\n\n\n\n\n\n\n\n\n\nExtract the images time of capture\n\ndef get_image_creation_date(image_path):\n    with open(image_path, 'rb') as f:\n        tags = exifread.process_file(f, stop_tag=\"EXIF DateTimeOriginal\")\n        date_tag = tags.get(\"EXIF DateTimeOriginal\")\n        if date_tag:\n            return pd.to_datetime(str(date_tag), format='%Y:%m:%d %H:%M:%S', utc=True)\n    return None\n\ndef get_video_creation_date(video_path):\n    media_info = MediaInfo.parse(video_path)\n    for track in media_info.tracks:\n        if track.track_type == \"General\":\n            date = (\n                track.tagged_date or\n                track.recorded_date or\n                track.encoded_date\n            )\n            if date:\n                return pd.to_datetime(date).floor('s')\n    return None\n\ndef get_creation_date(row):\n    file_path = os.path.join(output_dir, row.file_path)\n    is_video = row.is_video\n\n    if is_video: return get_video_creation_date(file_path)\n    return get_image_creation_date(file_path)\n\n\nmetadata_new['creation_date'] = pd.NA\n\nfor i, row in tqdm(metadata_new.iterrows(), total=len(metadata_new)):\n    creation_date = get_creation_date(row)\n    metadata_new.at[i, 'creation_date'] = creation_date\n\n\nmetadata_new\n\n2503it [00:06, 380.40it/s]\n\n\n\n\n\n\n\n\n\nidentity\nfile_path\nfile_name\nis_video\nsplit\n\n\n\n\n0\nGCN1-P4-S5\ntest/GCN1-P4-S5/IMG_3558.JPEG\nIMG_3558.MOV\nTrue\ntest\n\n\n0\nGCN1-P4-S5\ntest/GCN1-P4-S5/IMG_3558.JPEG\nIMG_3551.MOV\nTrue\ntest\n\n\n0\nGCN1-P4-S5\ntest/GCN1-P4-S5/IMG_3558.JPEG\nIMG_3553.MOV\nTrue\ntest\n\n\n0\nGCN1-P4-S5\ntest/GCN1-P4-S5/IMG_3558.JPEG\nIMG_3555.JPEG\nFalse\ntest\n\n\n0\nGCN1-P4-S5\ntest/GCN1-P4-S5/IMG_3558.JPEG\nIMG_3556.JPEG\nFalse\ntest\n\n\n\n\n\n\n\n\nmetadata_new.to_csv(output_dir/'metadata.csv', index=False)\nmetadata_new\n\n\n\nUpload to Kaggle\n\nsource\n\nupload_to_kaggle\n\n upload_to_kaggle (user_id, title, id, licenses, keywords, dataset_dir)\n\n\nupload_to_kaggle(user_id=\"mshahoyi\",\n                title=\"Barhill Great Crested Newts\", \n                id=\"barhill-newts-all\", \n                licenses=[{\"name\": \"CC0-1.0\"}], \n                keywords=[\"biology\", \"computer-vision\", \"animals\", \"great crested newts\"], \n                dataset_dir=\"./data/gcns-processed\")\n\n\nimport nbdev; nbdev.nbdev_export()",
    "crumbs": [
      "Newt Dataset Preparation"
    ]
  }
]