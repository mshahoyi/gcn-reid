{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce16e0d",
   "metadata": {},
   "source": [
    "# Splits\n",
    "> This notebook deals with creating splits for the newt dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wildlife_tools.similarity import CosineSimilarity\n",
    "from wildlife_datasets import analysis, datasets, splits\n",
    "import pycocotools.mask as mask_util\n",
    "from wildlife_tools.data import ImageDataset\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import timm\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from wildlife_tools.inference import TopkClassifier, KnnClassifier\n",
    "from wildlife_tools.features import DeepFeatures\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "from wildlife_tools.data import ImageDataset\n",
    "from gcn_reid.segmentation import decode_rle_mask\n",
    "from gcn_reid.newt_dataset import upload_to_kaggle\n",
    "from pathlib import Path\n",
    "from gcn_reid.newt_dataset import download_kaggle_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'mshahoyi/newts-segmented-new'\n",
    "dataset_path = Path('data/newts-segmented-new')\n",
    "download_kaggle_dataset(dataset_name, dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a69025",
   "metadata": {},
   "source": [
    "## Download and ready both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bde50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "dinov2_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "dinov2_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5430b3d",
   "metadata": {},
   "source": [
    "## Run both models on all images and save the results\n",
    "Artifacts are a dataframe like the newt dataframe but that contains two new columns representing the mega and miewid embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(dataset_path / 'metadata.csv')\n",
    "df = df_original.copy()\n",
    "df = df[~df.is_video].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_path = Path('artifacts')\n",
    "artifacts_path.mkdir(exist_ok=True)\n",
    "artifacts_name = 'metadata_with_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (artifacts_path/artifacts_name).exists():\n",
    "    batch_size = 64\n",
    "    batches = [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "    for i, batch in tqdm(enumerate(batches), total=len(batches)):\n",
    "        images = [Image.open(dataset_path / row['file_path']) for _, row in batch.iterrows()]\n",
    "        inputs = dinov2_processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = dinov2_model(**inputs)\n",
    "            last_hidden_states = outputs.last_hidden_state[:, 0, :] # select the CLS token embedding\n",
    "        features = pd.Series(last_hidden_states.cpu().tolist(), index=batch.index)\n",
    "        df.loc[batch.index, 'dinov2_features'] = features\n",
    "    df.to_csv(artifacts_path/artifacts_name, index=False)\n",
    "else: \n",
    "    df = pd.read_csv(artifacts_path/artifacts_name)\n",
    "    df['dinov2_features'] = df['dinov2_features'].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bba70e",
   "metadata": {},
   "source": [
    "## Get all cosine similarities and save the highest correct match and the highest incorrect match scores and indices\n",
    "We will have 8 new columns: mega_highest_correct_score, mega_highest_correct_idx, mega_highest_incorrect_score, mega_highest_incorrect_idx, miewid_highest_correct_score, miewid_highest_correct_idx, miewid_highest_incorrect_score, miewid_highest_incorrect_idx\n",
    "Convert string representation of features back to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d7e38f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "dinov2_features = np.array(df['dinov2_features'].tolist())\n",
    "\n",
    "# Calculate cosine similarities manually\n",
    "def cosine_similarity(a, b):\n",
    "    # Normalize the vectors\n",
    "    a_norm = a / np.linalg.norm(a, axis=1)[:, np.newaxis]\n",
    "    b_norm = b / np.linalg.norm(b, axis=1)[:, np.newaxis]\n",
    "    # Calculate similarity matrix\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "dinov2_similarities = cosine_similarity(dinov2_features, dinov2_features)\n",
    "\n",
    "dinov2_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2716f2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_highest_correct_and_incorrect_matches(df, similarities, i, row):\n",
    "    other_indices = np.arange(len(df))\n",
    "\n",
    "    # Get current newt ID\n",
    "    current_newt_id = row['identity']\n",
    "    \n",
    "    # Get similarities for this image\n",
    "    sims = similarities[i]\n",
    "\n",
    "    # Get masks for correct and incorrect matches\n",
    "    correct_mask = df['identity'] == current_newt_id\n",
    "    incorrect_mask = df['identity'] != current_newt_id\n",
    "\n",
    "    # Remove self from correct matches\n",
    "    correct_mask[i] = False\n",
    "\n",
    "    # Get highest correct and incorrect similarities\n",
    "    correct_sims = sims[correct_mask]\n",
    "    incorrect_sims = sims[incorrect_mask]\n",
    "\n",
    "    if correct_sims.size > 0:\n",
    "        highest_correct_idx = other_indices[correct_mask][np.argmax(correct_sims)]\n",
    "        highest_correct_score = np.max(correct_sims)\n",
    "    else:\n",
    "        highest_correct_idx = np.nan\n",
    "        highest_correct_score = np.nan\n",
    "\n",
    "    highest_incorrect_idx = other_indices[incorrect_mask][np.argmax(incorrect_sims)]\n",
    "    highest_incorrect_score = np.max(incorrect_sims)\n",
    "\n",
    "    return highest_correct_idx, highest_correct_score, highest_incorrect_idx, highest_incorrect_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9645599e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Test the get_highest_correct_and_incorrect_matches function\n",
    "def test_get_highest_correct_and_incorrect_matches():\n",
    "    # Create a small test dataset\n",
    "    test_df = pd.DataFrame({\n",
    "        'identity': ['A', 'A', 'A', 'B', 'B', 'C'],\n",
    "    })\n",
    "    \n",
    "    # Create a test similarity matrix\n",
    "    # Each row represents similarities to all other images\n",
    "    test_similarities = np.array([\n",
    "        [1.0, 0.8, 0.7, 0.9, 0.3, 0.2],  # Image 0 similarities\n",
    "        [0.8, 1.0, 0.9, 0.4, 0.5, 0.3],  # Image 1 similarities \n",
    "        [0.7, 0.9, 1.0, 0.3, 0.4, 0.6],  # Image 2 similarities\n",
    "        [0.9, 0.4, 0.3, 1.0, 0.8, 0.4],  # Image 3 similarities\n",
    "        [0.3, 0.5, 0.4, 0.8, 1.0, 0.5],  # Image 4 similarities\n",
    "        [0.2, 0.3, 0.6, 0.4, 0.5, 1.0],  # Image 5 similarities\n",
    "    ])\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        {\n",
    "            'idx': 0,  # Testing first image (identity A)\n",
    "            'expected': {\n",
    "                'correct_idx': 1,  # Should match with image 1 (identity A)\n",
    "                'correct_score': 0.8,\n",
    "                'incorrect_idx': 3,  # Should match with image 3 (identity B) \n",
    "                'incorrect_score': 0.9\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'idx': 3,  # Testing fourth image (identity B)\n",
    "            'expected': {\n",
    "                'correct_idx': 4,  # Should match with image 4 (identity B)\n",
    "                'correct_score': 0.8,\n",
    "                'incorrect_idx': 0,  # Should match with image 0 (identity A)\n",
    "                'incorrect_score': 0.9\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for test in test_cases:\n",
    "        idx = test['idx']\n",
    "        expected = test['expected']\n",
    "        \n",
    "        correct_idx, correct_score, incorrect_idx, incorrect_score = get_highest_correct_and_incorrect_matches(\n",
    "            test_df, test_similarities, idx, test_df.iloc[idx]\n",
    "        )\n",
    "        \n",
    "        # Assert the results match expected values\n",
    "        assert correct_idx == expected['correct_idx'], f\"Test failed for idx {idx}: Expected correct_idx {expected['correct_idx']}, got {correct_idx}\"\n",
    "        assert np.isclose(correct_score, expected['correct_score']), f\"Test failed for idx {idx}: Expected correct_score {expected['correct_score']}, got {correct_score}\"\n",
    "        assert incorrect_idx == expected['incorrect_idx'], f\"Test failed for idx {idx}: Expected incorrect_idx {expected['incorrect_idx']}, got {incorrect_idx}\"\n",
    "        assert np.isclose(incorrect_score, expected['incorrect_score']), f\"Test failed for idx {idx}: Expected incorrect_score {expected['incorrect_score']}, got {incorrect_score}\"\n",
    "    \n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# Run the tests\n",
    "test_get_highest_correct_and_incorrect_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072baa59",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for i, (k, row) in tqdm(enumerate(df.iterrows()), total=len(df)):\n",
    "    # Get current newt ID\n",
    "    dinov2_highest_correct_idx, dinov2_highest_correct_score, dinov2_highest_incorrect_idx, dinov2_highest_incorrect_score = get_highest_correct_and_incorrect_matches(df, dinov2_similarities, i, row)\n",
    "    \n",
    "    df.at[k, 'highest_correct_score'] = dinov2_highest_correct_score\n",
    "    df.at[k, 'highest_correct_idx'] = dinov2_highest_correct_idx\n",
    "    df.at[k, 'highest_incorrect_score'] = dinov2_highest_incorrect_score\n",
    "    df.at[k, 'highest_incorrect_idx'] = dinov2_highest_incorrect_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b061851",
   "metadata": {},
   "source": [
    "## Calculate the rightness score for each image and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rightness_score'] = df['highest_correct_score'] - df['highest_incorrect_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339928ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.highest_correct_score.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94b636",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot the 5 least correct images with their matches\n",
    "num_images = 1\n",
    "\n",
    "sorted_df = df.sort_values(by=['rightness_score'], ascending=True).reset_index(drop=True)\n",
    "for i, row in tqdm(sorted_df[:num_images].iterrows(), total=num_images):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Plot query image\n",
    "    query_path = dataset_path / row['file_path']\n",
    "    print(query_path)\n",
    "    axes[0].imshow(plt.imread(query_path))\n",
    "    axes[0].set_title(f'Query\\nID: {row[\"identity\"]} - {row.file_name}\\n{row.creation_date}')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Define matches to plot\n",
    "    matches = [\n",
    "        {'type': 'DINOv2 Correct', 'score_col': 'highest_correct_score', 'idx_col': 'highest_correct_idx', 'ax_idx': 1},\n",
    "        {'type': 'DINOv2 Incorrect', 'score_col': 'highest_incorrect_score', 'idx_col': 'highest_incorrect_idx', 'ax_idx': 2},\n",
    "    ]\n",
    "\n",
    "    # Plot each match\n",
    "    for match in matches:\n",
    "        match_row = df.iloc[int(row[match['idx_col']])]\n",
    "        match_path = dataset_path / match_row['file_path']\n",
    "        ax = axes[match['ax_idx']]\n",
    "        ax.imshow(plt.imread(match_path))\n",
    "        ax.set_title(f'{match[\"type\"]}\\nScore: {row[match[\"score_col\"]]:.3f}\\n{match_row.identity}/{match_row.file_name}\\n{row.creation_date}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(artifacts_path/f'least_correct_matches_rightness_score_{i}.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2a16e",
   "metadata": {},
   "source": [
    "## Sort images by rightness score in an ascending order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13cc65",
   "metadata": {},
   "source": [
    "## Mark query and database images\n",
    "Starting with the least right images, mark the query and database images. Skip images that are already marked (this means they are the database for another image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ind_test = 30\n",
    "n_ind_val = 30\n",
    "\n",
    "df_original['is_hard_test_query'] = pd.NA\n",
    "df_original['is_hard_val_query'] = pd.NA\n",
    "\n",
    "sorted_df = df.loc[df.groupby('identity')['rightness_score'].idxmin()].sort_values(by=['rightness_score'], ascending=True).head(n_ind_test + n_ind_val)\n",
    "sorted_df.identity.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64adda",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for count, (i, row) in enumerate(sorted_df.iterrows()):\n",
    "    col = 'is_hard_test_query' if count < n_ind_test else 'is_hard_val_query'\n",
    "\n",
    "    # Make other images of the same newt a database\n",
    "    df_original.loc[df_original['identity'] == row['identity'], col] = False\n",
    "\n",
    "    # Make the newt itself a query\n",
    "    df_original.loc[(df_original['identity'] == row['identity']) & (df_original.file_name == row['file_name']), col] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da35f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.is_hard_test_query.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.is_hard_val_query.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c388a",
   "metadata": {},
   "source": [
    "# Create least similar split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['is_least_similar_test_query'] = pd.NA\n",
    "df_original['is_least_similar_val_query'] = pd.NA\n",
    "\n",
    "least_similar_df = df.loc[df.groupby('identity')['highest_correct_score'].idxmin()].sort_values(by=['highest_correct_score'], ascending=True).head(n_ind_test + n_ind_val)\n",
    "least_similar_df.identity.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf02d99",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for count, (i, row) in enumerate(least_similar_df.iterrows()):\n",
    "    col = 'is_least_similar_test_query' if count < n_ind_test else 'is_least_similar_val_query'\n",
    "\n",
    "    # Make other images of the same newt a database\n",
    "    df_original.loc[df_original['identity'] == row['identity'], col] = False\n",
    "\n",
    "    # Make the newt itself a query\n",
    "    df_original.loc[(df_original['identity'] == row['identity']) & (df_original.file_name == row['file_name']), col] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.is_least_similar_test_query.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.is_least_similar_val_query.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756a776",
   "metadata": {},
   "source": [
    "# Create random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['is_random_test_query'] = pd.NA\n",
    "df_original['is_random_val_query'] = pd.NA\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "random_df = df.loc[df.groupby('identity').apply(lambda x: x.sample(n=1, random_state=rng).index[0], include_groups=False)].head(n_ind_test + n_ind_val)\n",
    "random_df.identity.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, (i, row) in enumerate(random_df.iterrows()):\n",
    "    col = 'is_random_test_query' if count < n_ind_test else 'is_random_val_query'\n",
    "\n",
    "    # Make other images of the same newt a database\n",
    "    df_original.loc[df_original['identity'] == row['identity'], col] = False\n",
    "\n",
    "    # Make the newt itself a query\n",
    "    df_original.loc[(df_original['identity'] == row['identity']) & (df_original.file_name == row['file_name']), col] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.is_random_test_query.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d869bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.is_random_val_query.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ac315",
   "metadata": {},
   "source": [
    "# Save the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69494638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.to_csv(dataset_path/'metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22cb6a",
   "metadata": {},
   "source": [
    "# Create Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff40bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_to_kaggle(\n",
    "    user_id='mshahoyi',\n",
    "    title='GCN-ID 2024',\n",
    "    id='gcn-id-2024',\n",
    "    licenses=[{\"name\": \"CC0-1.0\"}],\n",
    "    keywords=['gcn-id', '2024'],\n",
    "    dataset_dir=dataset_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b3261",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293ef59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
