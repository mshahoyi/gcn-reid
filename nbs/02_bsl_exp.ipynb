{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7086f0",
   "metadata": {},
   "source": [
    "# BSL Experiment\n",
    "> Finetuning MegaDescriptor with Background Supporession Loss (BSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp bsl_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde8fdd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timm\n",
    "from pathlib import Path\n",
    "import kaggle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from wildlife_datasets import loader, datasets, splits\n",
    "from wildlife_tools.data import ImageDataset\n",
    "from wildlife_tools.features import DeepFeatures\n",
    "from wildlife_tools.similarity import CosineSimilarity\n",
    "from wildlife_tools.inference import KnnClassifier\n",
    "from wildlife_tools.train import ArcFaceLoss, set_seed\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from gcn_reid.segmentation import decode_rle_mask, visualize_segmentation, visualize_segmentation_from_metadata\n",
    "from gcn_reid.attribution import my_occlusion_sensitivity\n",
    "import itertools\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and verify dataset\n",
    "def download_newt_dataset():\n",
    "    dataset_name = \"mshahoyi/barhill-newts-segmented\"\n",
    "    download_path = \"data/newt_dataset\"\n",
    "    \n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path, exist_ok=True)\n",
    "        kaggle.api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
    "        print(f\"Dataset downloaded to {download_path}\")\n",
    "    else:\n",
    "        print(f\"Dataset already exists at {download_path}\")\n",
    "    \n",
    "    return download_path\n",
    "\n",
    "dataset_path = download_newt_dataset()\n",
    "\n",
    "# Verify dataset structure\n",
    "print(f\"\\nDataset path: {dataset_path}\")\n",
    "print(\"Dataset contents:\")\n",
    "for item in os.listdir(dataset_path):\n",
    "    print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bb2f8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load and examine metadata\n",
    "metadata_path = os.path.join(dataset_path, \"metadata.csv\")\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Dataset contains {len(df)} images\")\n",
    "print(f\"Number of unique newts: {df['newt_id'].nunique()}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nNewt ID distribution:\")\n",
    "print(df['newt_id'].value_counts().head(10))\n",
    "\n",
    "# Test RLE decoding with a sample\n",
    "sample_row = df.iloc[0]\n",
    "print(f\"Testing RLE decoding with sample:\")\n",
    "print(f\"Image path: {sample_row['image_path']}\")\n",
    "print(f\"Newt ID: {sample_row['newt_id']}\")\n",
    "\n",
    "# Load sample image to get dimensions\n",
    "sample_img_path = Path(dataset_path) / sample_row['image_path']\n",
    "sample_img = Image.open(sample_img_path)\n",
    "print(f\"Image size: {sample_img.size}\")\n",
    "\n",
    "# Decode mask\n",
    "h, w = sample_img.size[1], sample_img.size[0]\n",
    "mask = decode_rle_mask(sample_row['segmentation_mask_rle'])\n",
    "print(f\"Mask shape: {mask.shape}\")\n",
    "print(f\"Mask unique values: {np.unique(mask)}\")\n",
    "print(f\"Mask coverage: {mask.sum() / mask.size:.2%}\")\n",
    "\n",
    "# Visualize sample\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(sample_img)\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "axes[1].set_title('Segmentation Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(sample_img)\n",
    "axes[2].imshow(mask, alpha=0.5, cmap='Reds')\n",
    "axes[2].set_title('Image + Mask Overlay')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e19a6d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create and test dataset splits\n",
    "def create_newt_splits(df, train_ratio=0.8, random_state=42):\n",
    "    \"\"\"Create disjoint splits ensuring each newt appears in only one split\"\"\"\n",
    "    unique_newts = df['newt_id'].unique()\n",
    "    \n",
    "    train_newts, test_newts = train_test_split(\n",
    "        unique_newts, \n",
    "        train_size=train_ratio, \n",
    "        random_state=random_state,\n",
    "        stratify=None\n",
    "    )\n",
    "    \n",
    "    df_train = df[df['newt_id'].isin(train_newts)].copy()\n",
    "    df_test = df[df['newt_id'].isin(test_newts)].copy()\n",
    "    \n",
    "    print(f\"Train split: {len(df_train)} images from {len(train_newts)} newts\")\n",
    "    print(f\"Test split: {len(df_test)} images from {len(test_newts)} newts\")\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = create_newt_splits(df)\n",
    "\n",
    "# Verify no overlap between train and test\n",
    "train_newts = set(df_train['newt_id'].unique())\n",
    "test_newts = set(df_test['newt_id'].unique())\n",
    "overlap = train_newts.intersection(test_newts)\n",
    "print(f\"Overlap between train and test newts: {len(overlap)} (should be 0)\")\n",
    "\n",
    "print(\"\\nTrain newt distribution (top 10):\")\n",
    "print(df_train['newt_id'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nTest newt distribution (top 10):\")\n",
    "print(df_test['newt_id'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test custom dataset class\n",
    "class NewtDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_path, transform=None, return_mask=True):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.root_path = Path(root_path)\n",
    "        self.transform = transform\n",
    "        self.return_mask = return_mask\n",
    "        self.labels_string = self.df['newt_id'].astype(str).tolist()\n",
    "        \n",
    "        # Create label mapping\n",
    "        unique_labels = sorted(self.df['newt_id'].unique())\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.labels = [self.label_to_idx[label] for label in self.df['newt_id']]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.root_path / row['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Get label\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Decode segmentation mask\n",
    "        mask = None\n",
    "        if self.return_mask and 'segmentation_mask_rle' in row:\n",
    "            h, w = image.size[1], image.size[0]\n",
    "            try:\n",
    "                decoded_mask = decode_rle_mask(row['segmentation_mask_rle'])\n",
    "                if decoded_mask is not None:\n",
    "                    mask = Image.fromarray(decoded_mask * 255).convert('L')\n",
    "                else:\n",
    "                    # Create a default mask (all foreground) when RLE decoding fails\n",
    "                    mask = Image.fromarray(np.ones((h, w), dtype=np.uint8) * 255).convert('L')\n",
    "            except Exception as e:\n",
    "                # Create a default mask if there's any error in decoding\n",
    "                h, w = image.size[1], image.size[0]\n",
    "                mask = Image.fromarray(np.ones((h, w), dtype=np.uint8) * 255).convert('L')\n",
    "                print(f\"Warning: Error decoding mask for image {idx}: {e}, using default full mask\")\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            if mask is not None:\n",
    "                # Apply same transform to both image and mask\n",
    "                seed = np.random.randint(2147483647)\n",
    "                \n",
    "                random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                image = self.transform(image)\n",
    "                \n",
    "                random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                mask = T.ToTensor()(mask)\n",
    "                mask = T.Resize(image.shape[-2:])(mask)\n",
    "            else:\n",
    "                image = self.transform(image)\n",
    "        \n",
    "        if mask is not None:\n",
    "            return image, label, mask.squeeze(0)\n",
    "        else:\n",
    "            return image, label\n",
    "\n",
    "# Test dataset creation\n",
    "transform_test = T.Compose([\n",
    "    T.Resize([224, 224]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset_small = NewtDataset(df_train.head(10), dataset_path, transform=transform_test, return_mask=True)\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset_small)}\")\n",
    "print(f\"Number of classes in test: {len(test_dataset_small.label_to_idx)}\")\n",
    "print(f\"Label mapping: {test_dataset_small.label_to_idx}\")\n",
    "\n",
    "# Test loading a sample\n",
    "sample_data = test_dataset_small[0]\n",
    "print(f\"Sample data shapes:\")\n",
    "print(f\"  Image: {sample_data[0].shape}\")\n",
    "print(f\"  Label: {sample_data[1]}\")\n",
    "print(f\"  Mask: {sample_data[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936fc9d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create full datasets with sanity checks\n",
    "transform_train = T.Compose([\n",
    "    T.Resize([224, 224]),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=180),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = NewtDataset(df_train, dataset_path, transform=transform_train, return_mask=True)\n",
    "test_dataset = NewtDataset(df_test, dataset_path, transform=transform_test, return_mask=True)\n",
    "\n",
    "print(f\"Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "print(f\"Number of classes: {len(train_dataset.label_to_idx)}\")\n",
    "\n",
    "# Verify datasets\n",
    "train_sample = train_dataset[0]\n",
    "test_sample = test_dataset[0]\n",
    "\n",
    "print(f\"\\nTrain sample shapes: image={train_sample[0].shape}, label={train_sample[1]}, mask={train_sample[2].shape}\")\n",
    "print(f\"Test sample shapes: image={test_sample[0].shape}, label={test_sample[1]}, mask={test_sample[2].shape}\")\n",
    "\n",
    "# Check label consistency\n",
    "print(f\"Train labels range: {min(train_dataset.labels)} to {max(train_dataset.labels)}\")\n",
    "print(f\"Test labels range: {min(test_dataset.labels)} to {max(test_dataset.labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26947618",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test model loading and feature extraction\n",
    "def test_megadescriptor_loading():\n",
    "    print(\"Testing MegaDescriptor loading...\")\n",
    "    \n",
    "    # Test loading the model\n",
    "    model_name = 'hf-hub:BVRA/MegaDescriptor-T-224'\n",
    "    backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "    \n",
    "    # Test forward pass\n",
    "    with torch.no_grad():\n",
    "        dummy_input = torch.randn(2, 3, 224, 224)\n",
    "        features = backbone(dummy_input)\n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"Input shape: {dummy_input.shape}\")\n",
    "        print(f\"Output features shape: {features.shape}\")\n",
    "        print(f\"Feature dimension: {features.shape[1]}\")\n",
    "    \n",
    "    return backbone, features.shape[1]\n",
    "\n",
    "backbone, embedding_size = test_megadescriptor_loading()\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b285f31",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create and test ArcFace loss\n",
    "def test_arcface_loss():\n",
    "    print(\"Testing ArcFace loss...\")\n",
    "    \n",
    "    num_classes = len(train_dataset.label_to_idx)\n",
    "    \n",
    "    # Create ArcFace loss\n",
    "    arcface_loss = ArcFaceLoss(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=embedding_size,\n",
    "        margin=0.5,\n",
    "        scale=64\n",
    "    )\n",
    "    \n",
    "    print(f\"ArcFace loss created for {num_classes} classes, embedding size {embedding_size}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    with torch.no_grad():\n",
    "        dummy_embeddings = torch.randn(4, embedding_size)\n",
    "        dummy_labels = torch.randint(0, num_classes, (4,))\n",
    "        \n",
    "        loss = arcface_loss(dummy_embeddings, dummy_labels)\n",
    "        print(f\"Test loss: {loss.item():.4f}\")\n",
    "        print(\"ArcFace loss working correctly!\")\n",
    "        \n",
    "    return arcface_loss\n",
    "\n",
    "arcface_loss = test_arcface_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9478f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Background Suppression ArcFace Loss\n",
    "class BackgroundSuppressionArcFaceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom loss that combines ArcFace loss with background suppression\n",
    "    Uses segmentation masks to focus learning on the newt regions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, embedding_size, margin=0.5, scale=64, alpha=1.0, beta=0.5):\n",
    "        super().__init__()\n",
    "        self.arcface_loss = ArcFaceLoss(\n",
    "            num_classes=num_classes,\n",
    "            embedding_size=embedding_size,\n",
    "            margin=margin,\n",
    "            scale=scale\n",
    "        )\n",
    "        self.alpha = alpha  # Weight for ArcFace loss\n",
    "        self.beta = beta    # Weight for background suppression loss\n",
    "        \n",
    "    def forward(self, embeddings, labels, masks, patch_features=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: Output embeddings from the backbone [B, embedding_size]\n",
    "            labels: Ground truth labels [B]\n",
    "            masks: Binary segmentation masks (1 for newt, 0 for background) [B, H, W]\n",
    "            patch_features: Intermediate feature maps for background suppression [B, C, Hf, Wf]\n",
    "        \"\"\"\n",
    "        # ArcFace loss on embeddings\n",
    "        arcface_loss = self.arcface_loss(embeddings, labels)\n",
    "        \n",
    "        # Background suppression loss\n",
    "        background_penalty = torch.tensor(0.0, device=embeddings.device)\n",
    "        \n",
    "        if patch_features is not None and masks is not None:\n",
    "            B, C, Hf, Wf = patch_features.shape\n",
    "\n",
    "            print(f\"Patch features shape: {patch_features.shape}\")\n",
    "            \n",
    "            # Resize masks to match feature map size\n",
    "            masks_resized = F.interpolate(\n",
    "                masks.unsqueeze(1).float(), \n",
    "                size=(Hf, Wf), \n",
    "                mode='nearest'\n",
    "            ).squeeze(1)\n",
    "            \n",
    "            # Background mask (1 for background, 0 for foreground)\n",
    "            background_mask = 1.0 - masks_resized\n",
    "            \n",
    "            # Compute L2 norm of patch features\n",
    "            patch_norm = patch_features.pow(2).sum(1).sqrt()  # [B, Hf, Wf]\n",
    "            \n",
    "            # Background suppression: penalize high activations in background regions\n",
    "            background_penalty = (patch_norm * background_mask).mean()\n",
    "        \n",
    "        total_loss = self.alpha * arcface_loss + self.beta * background_penalty\n",
    "        \n",
    "        return total_loss, arcface_loss, background_penalty\n",
    "\n",
    "# Test BSL Loss\n",
    "def test_bsl_loss():\n",
    "    print(\"Testing Background Suppression ArcFace Loss...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_classes = len(train_dataset.label_to_idx)\n",
    "    \n",
    "    bsl_loss = BackgroundSuppressionArcFaceLoss(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=embedding_size,\n",
    "        margin=0.5,\n",
    "        scale=64,\n",
    "        alpha=1.0,\n",
    "        beta=0.5\n",
    "    ).to(device)\n",
    "    \n",
    "    # Test with dummy data\n",
    "    with torch.no_grad():\n",
    "        # Get real data samples from training dataset\n",
    "        sample_batch = next(iter(DataLoader(train_dataset, batch_size=2, shuffle=True)))\n",
    "        images, labels, masks = sample_batch\n",
    "        images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "        \n",
    "        # Get embeddings and patch features from model\n",
    "        model.eval()\n",
    "        embeddings = model(images)\n",
    "        patch_features = model.patch_features\n",
    "        \n",
    "        total_loss, arcface_loss, bg_loss = bsl_loss(\n",
    "            embeddings, labels, masks, patch_features\n",
    "        )\n",
    "        \n",
    "        print(f\"Total loss: {total_loss.item():.4f}\")\n",
    "        print(f\"ArcFace loss: {arcface_loss.item():.4f}\")\n",
    "        print(f\"Background loss: {bg_loss.item():.4f}\")\n",
    "        \n",
    "    return bsl_loss\n",
    "\n",
    "bsl_loss = test_bsl_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401ef61",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = timm.create_model('hf-hub:BVRA/MegaDescriptor-T-224', pretrained=True, num_classes=0)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810bec9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create model with feature extraction hooks\n",
    "class MegaDescriptorWithBSL(nn.Module):\n",
    "    def __init__(self, num_classes, model_name='hf-hub:BVRA/MegaDescriptor-T-224'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained MegaDescriptor backbone\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Get feature dimension\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            features = self.backbone(dummy_input)\n",
    "            self.embedding_size = features.shape[1]\n",
    "        \n",
    "        # Store intermediate features for BSL\n",
    "        self.patch_features = None\n",
    "        \n",
    "        # Register hook to capture intermediate features\n",
    "        self._register_hooks()\n",
    "        \n",
    "    def _register_hooks(self):\n",
    "        \"\"\"Register hooks to capture intermediate feature maps\"\"\"\n",
    "        def hook_fn(module, input, output):\n",
    "            # Swin Transformer outputs features in [B, H, W, C] format\n",
    "            if len(output.shape) == 4:\n",
    "                B, H, W, C = output.shape\n",
    "                # Convert to [B, C, H, W] format for compatibility\n",
    "                self.patch_features = output.permute(0, 3, 1, 2)\n",
    "            elif len(output.shape) == 3:\n",
    "                # Some layers might output [B, N, C], try to reshape\n",
    "                B, N, C = output.shape\n",
    "                H = W = int(np.sqrt(N))\n",
    "                if H * W == N:\n",
    "                    self.patch_features = output.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Hook into one of the later Swin Transformer stages\n",
    "        # Stage 2 has 384 channels and good spatial resolution\n",
    "        # Stage 3 has 768 channels (final) but lower spatial resolution\n",
    "        \n",
    "        # Try to hook into stage 2 (layers.2) - 384 channels\n",
    "        if hasattr(self.backbone, 'layers') and len(self.backbone.layers) > 2:\n",
    "            target_stage = self.backbone.layers[2]  # Stage 2\n",
    "            print(f\"Hooking to Swin stage 2 with {384} channels\")\n",
    "            target_stage.register_forward_hook(hook_fn)\n",
    "            return\n",
    "        \n",
    "        # Fallback: try to hook into any layer with 'layers' in the name\n",
    "        hooked = False\n",
    "        for name, module in self.backbone.named_modules():\n",
    "            if 'layers.2' in name and not hooked:  # Prefer stage 2\n",
    "                print(f\"Hooking to layer: {name}\")\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                hooked = True\n",
    "                break\n",
    "            elif 'layers.1' in name and not hooked:  # Fallback to stage 1\n",
    "                print(f\"Hooking to layer: {name}\")\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                hooked = True\n",
    "                break\n",
    "        \n",
    "        if not hooked:\n",
    "            print(\"Warning: Could not find suitable Swin Transformer layer to hook\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Reset patch features\n",
    "        self.patch_features = None\n",
    "        \n",
    "        # Forward through backbone\n",
    "        embeddings = self.backbone(x)\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def get_patch_features(self):\n",
    "        \"\"\"Get the stored patch features for background suppression\"\"\"\n",
    "        return self.patch_features\n",
    "\n",
    "# Test model creation\n",
    "def test_model_creation():\n",
    "    print(\"Testing model creation...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_classes = len(train_dataset.label_to_idx)\n",
    "    \n",
    "    model = MegaDescriptorWithBSL(num_classes).to(device)\n",
    "    \n",
    "    print(f\"Model created with {model.embedding_size} embedding size\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    with torch.no_grad():\n",
    "        dummy_input = torch.randn(2, 3, 224, 224).to(device)\n",
    "        embeddings = model(dummy_input)\n",
    "        patch_features = model.get_patch_features()\n",
    "        \n",
    "        print(f\"Input shape: {dummy_input.shape}\")\n",
    "        print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        \n",
    "        if patch_features is not None:\n",
    "            print(f\"Patch features shape: {patch_features.shape}\")\n",
    "        else:\n",
    "            print(\"Warning: No patch features captured\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = test_model_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560ac9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a94e80",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test data loading with actual data\n",
    "def test_data_loading():\n",
    "    print(\"Testing data loading...\")\n",
    "    \n",
    "    # Create small data loaders for testing\n",
    "    small_train_dataset = NewtDataset(df_train.head(20), dataset_path, transform=transform_train, return_mask=True)\n",
    "    train_loader = DataLoader(small_train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "    \n",
    "    # Test loading one batch\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        if len(batch) == 3:\n",
    "            images, labels, masks = batch\n",
    "            print(f\"Batch {batch_idx}:\")\n",
    "            print(f\"  Images shape: {images.shape}\")\n",
    "            print(f\"  Labels: {labels}\")\n",
    "            print(f\"  Masks shape: {masks.shape}\")\n",
    "            print(f\"  Mask value ranges: {masks.min().item():.3f} to {masks.max().item():.3f}\")\n",
    "            \n",
    "            # Visualize one sample from batch\n",
    "            img = images[0]\n",
    "            mask = masks[0]\n",
    "            \n",
    "            # Denormalize image for visualization\n",
    "            img_denorm = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            img_denorm = torch.clamp(img_denorm, 0, 1)\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            axes[0].imshow(img_denorm.permute(1, 2, 0))\n",
    "            axes[0].set_title(f'Image (Label: {labels[0].item()})')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            axes[1].imshow(mask, cmap='gray')\n",
    "            axes[1].set_title('Mask')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            break\n",
    "    \n",
    "    return train_loader\n",
    "\n",
    "test_loader = test_data_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full training setup\n",
    "def test_training_setup():\n",
    "    print(\"Testing full training setup...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Model\n",
    "    num_classes = len(train_dataset.label_to_idx)\n",
    "    model = MegaDescriptorWithBSL(num_classes).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    bsl_loss = BackgroundSuppressionArcFaceLoss(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=model.embedding_size,\n",
    "        margin=0.5,\n",
    "        scale=64,\n",
    "        alpha=1.0,\n",
    "        beta=0.5\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    params = itertools.chain(model.parameters(), bsl_loss.parameters())\n",
    "    optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=1e-4)\n",
    "    \n",
    "    # Test one training step\n",
    "    model.train()\n",
    "    bsl_loss.train()\n",
    "    \n",
    "    # Get a small batch\n",
    "    small_dataset = NewtDataset(df_train.head(8), dataset_path, transform=transform_train, return_mask=True)\n",
    "    loader = DataLoader(small_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "    \n",
    "    for batch in loader:\n",
    "        images, labels, masks = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        print(f\"Batch shapes - Images: {images.shape}, Labels: {labels.shape}, Masks: {masks.shape}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embeddings = model(images)\n",
    "        patch_features = model.get_patch_features()\n",
    "        \n",
    "        print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        if patch_features is not None:\n",
    "            print(f\"Patch features shape: {patch_features.shape}\")\n",
    "        \n",
    "        # Compute loss\n",
    "        loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n",
    "        \n",
    "        print(f\"Losses - Total: {loss.item():.4f}, ArcFace: {arcface_loss.item():.4f}, BG: {bg_loss.item():.4f}\")\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(\"Training step completed successfully!\")\n",
    "        break\n",
    "    \n",
    "    return model, bsl_loss, optimizer\n",
    "\n",
    "model, bsl_loss, optimizer = test_training_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40299cb6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Now we can proceed with the actual training\n",
    "print(\"Setup complete! Ready for full training...\")\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset.label_to_idx)}\")\n",
    "print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969224ef",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test and define training epoch function with sanity checks\n",
    "def train_epoch(model, train_loader, bsl_loss, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    bsl_loss.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_arcface_loss = 0\n",
    "    total_bg_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        if len(batch) == 3:  # With masks\n",
    "            images, labels, masks = batch\n",
    "            masks = masks.to(device)\n",
    "        else:  # Without masks\n",
    "            images, labels = batch\n",
    "            masks = torch.ones(images.shape[0], images.shape[2], images.shape[3]).to(device)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embeddings = model(images)\n",
    "        patch_features = model.get_patch_features()\n",
    "        \n",
    "        # Compute BSL loss with ArcFace\n",
    "        loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        total_arcface_loss += arcface_loss.item()\n",
    "        total_bg_loss += bg_loss.item()\n",
    "        \n",
    "        # For accuracy calculation, get predictions from ArcFace weights\n",
    "        with torch.no_grad():\n",
    "            # Access the classifier weights from the pytorch_metric_learning ArcFace loss\n",
    "            W = bsl_loss.arcface_loss.loss.W  # The classifier weights\n",
    "            # Normalize embeddings and weights for cosine similarity\n",
    "            embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n",
    "            W_norm = F.normalize(W, p=2, dim=0)\n",
    "            # Compute logits as cosine similarity * scale\n",
    "            logits = F.linear(embeddings_norm, W_norm.T) * bsl_loss.arcface_loss.loss.scale\n",
    "            \n",
    "            _, predicted = logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Arc': f'{arcface_loss.item():.4f}',\n",
    "            'BG': f'{bg_loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_arcface_loss = total_arcface_loss / len(train_loader)\n",
    "    avg_bg_loss = total_bg_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, avg_arcface_loss, avg_bg_loss, accuracy\n",
    "\n",
    "# Test the training epoch function with a tiny dataset\n",
    "print(\"Testing training epoch function...\")\n",
    "\n",
    "# Create a tiny test dataset\n",
    "tiny_dataset = NewtDataset(df_train.head(16), dataset_path, transform=transform_train, return_mask=True)\n",
    "tiny_loader = DataLoader(tiny_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Test training epoch\n",
    "test_loss, test_arcface, test_bg, test_acc = train_epoch(\n",
    "    model, tiny_loader, bsl_loss, optimizer, device, epoch=0\n",
    ")\n",
    "\n",
    "print(f\"✅ Training epoch test passed!\")\n",
    "print(f\"   Loss: {test_loss:.4f} (ArcFace: {test_arcface:.4f}, BG: {test_bg:.4f})\")\n",
    "print(f\"   Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3060396",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test and define evaluation function\n",
    "def evaluate(model, test_loader, bsl_loss, device):\n",
    "    model.eval()\n",
    "    bsl_loss.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "            if len(batch) == 3:  # With masks\n",
    "                images, labels, _ = batch\n",
    "            else:  # Without masks\n",
    "                images, labels = batch\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Get embeddings\n",
    "            embeddings = model(images)\n",
    "            \n",
    "            # Get predictions from ArcFace weights\n",
    "            W = bsl_loss.arcface_loss.loss.W  # The classifier weights\n",
    "            # Normalize embeddings and weights for cosine similarity\n",
    "            embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n",
    "            W_norm = F.normalize(W, p=2, dim=0)\n",
    "            # Compute logits as cosine similarity * scale\n",
    "            logits = F.linear(embeddings_norm, W_norm.T) * bsl_loss.arcface_loss.loss.scale\n",
    "            \n",
    "            _, predicted = logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Test evaluation function\n",
    "print(\"Testing evaluation function...\")\n",
    "\n",
    "tiny_test_dataset = NewtDataset(df_test.head(16), dataset_path, transform=transform_test, return_mask=True)\n",
    "tiny_test_loader = DataLoader(tiny_test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "eval_acc = evaluate(model, tiny_test_loader, bsl_loss, device)\n",
    "print(f\"✅ Evaluation test passed!\")\n",
    "print(f\"   Test accuracy: {eval_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba2fb6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test occlusion sensitivity function with detailed checks\n",
    "def run_occlusion_sensitivity_test(model, bsl_loss, dataset, device, epoch, save_dir):\n",
    "    \"\"\"Run occlusion sensitivity on pairs of different newts to test similarity\"\"\"\n",
    "    print(f\"Starting occlusion sensitivity test for epoch {epoch}\")\n",
    "    \n",
    "    model.eval()\n",
    "    bsl_loss.eval()\n",
    "    \n",
    "    # Create save directory\n",
    "    epoch_dir = Path(save_dir) / f\"epoch_{epoch:03d}\"\n",
    "    epoch_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created directory: {epoch_dir}\")\n",
    "    \n",
    "    # Find pairs of different newts\n",
    "    newt_indices_by_id = {}\n",
    "    for idx in range(len(dataset)):\n",
    "        newt_id = dataset.labels_string[idx]\n",
    "        if newt_id not in newt_indices_by_id:\n",
    "            newt_indices_by_id[newt_id] = []\n",
    "        newt_indices_by_id[newt_id].append(idx)\n",
    "    \n",
    "    # Select 2 pairs of different newts\n",
    "    newt_ids = list(newt_indices_by_id.keys())\n",
    "    if len(newt_ids) < 2:\n",
    "        print(\"Not enough different newts for similarity testing\")\n",
    "        return\n",
    "    \n",
    "    # Create similarity model function\n",
    "    def similarity_model(image1, image2):\n",
    "        \"\"\"\n",
    "        Compute cosine similarity between two images using the trained model\n",
    "        \n",
    "        Args:\n",
    "            image1: First image tensor [1, C, H, W]\n",
    "            image2: Second image tensor [1, C, H, W] \n",
    "            \n",
    "        Returns:\n",
    "            Cosine similarity score as tensor\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Get embeddings for both images\n",
    "            emb1 = model(image1)\n",
    "            emb2 = model(image2)\n",
    "            \n",
    "            # Compute cosine similarity\n",
    "            emb1_norm = F.normalize(emb1, p=2, dim=1)\n",
    "            emb2_norm = F.normalize(emb2, p=2, dim=1)\n",
    "            similarity = F.cosine_similarity(emb1_norm, emb2_norm, dim=1)\n",
    "            \n",
    "            return similarity\n",
    "    \n",
    "    # Test 2 pairs\n",
    "    for pair_idx in range(2):\n",
    "        try:\n",
    "            # Select two different newts\n",
    "            newt_id1, newt_id2 = random.sample(newt_ids, 2)\n",
    "            \n",
    "            # Get one image from each newt\n",
    "            idx1 = random.choice(newt_indices_by_id[newt_id1])\n",
    "            idx2 = random.choice(newt_indices_by_id[newt_id2])\n",
    "            \n",
    "            print(f\"  Processing pair {pair_idx+1}: Newt {newt_id1} (idx {idx1}) vs Newt {newt_id2} (idx {idx2})\")\n",
    "            \n",
    "            # Get the images\n",
    "            if len(dataset[idx1]) == 3:\n",
    "                image1, label1, _ = dataset[idx1]\n",
    "            else:\n",
    "                image1, label1 = dataset[idx1]\n",
    "                \n",
    "            if len(dataset[idx2]) == 3:\n",
    "                image2, label2, _ = dataset[idx2]\n",
    "            else:\n",
    "                image2, label2 = dataset[idx2]\n",
    "            \n",
    "            print(f\"    Image1: {image1.shape}, Label1: {label1}\")\n",
    "            print(f\"    Image2: {image2.shape}, Label2: {label2}\")\n",
    "            \n",
    "            # Convert images to tensors for similarity computation (add batch dimension)\n",
    "            image1_tensor = image1.unsqueeze(0).to(device)  # [1, C, H, W]\n",
    "            image2_tensor = image2.unsqueeze(0).to(device)  # [1, C, H, W]\n",
    "            \n",
    "            # Test baseline similarity\n",
    "            baseline_similarity = similarity_model(image1_tensor, image2_tensor).item()\n",
    "            print(f\"    Baseline similarity: {baseline_similarity:.4f}\")\n",
    "            \n",
    "            # Run occlusion sensitivity using your function with tensors\n",
    "            print(f\"    Running occlusion sensitivity...\")\n",
    "            occlusion_map = my_occlusion_sensitivity(\n",
    "                similarity_model, \n",
    "                image1_tensor, \n",
    "                image2_tensor, \n",
    "                patch_size=16, \n",
    "                stride=8, \n",
    "                occlusion_value=0.5, \n",
    "                device=device\n",
    "            )\n",
    "            print(f\"    Occlusion map shape: {occlusion_map.shape}, range [{occlusion_map.min():.3f}, {occlusion_map.max():.3f}]\")\n",
    "            \n",
    "            # Convert images to numpy for visualization only\n",
    "            img1_np = image1.cpu().numpy().transpose(1, 2, 0)\n",
    "            img1_np = (img1_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "            img1_np = np.clip(img1_np, 0, 1)\n",
    "            \n",
    "            img2_np = image2.cpu().numpy().transpose(1, 2, 0)\n",
    "            img2_np = (img2_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "            img2_np = np.clip(img2_np, 0, 1)\n",
    "            \n",
    "            # Save visualization\n",
    "            save_path = epoch_dir / f\"similarity_pair_{pair_idx+1}_newt_{newt_id1}_vs_{newt_id2}.png\"\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "            \n",
    "            # Original images\n",
    "            axes[0,0].imshow(img1_np)\n",
    "            axes[0,0].set_title(f'Image 1: Newt {newt_id1}\\n(Index {idx1})')\n",
    "            axes[0,0].axis('off')\n",
    "            \n",
    "            axes[0,1].imshow(img2_np)\n",
    "            axes[0,1].set_title(f'Image 2: Newt {newt_id2}\\n(Index {idx2})')\n",
    "            axes[0,1].axis('off')\n",
    "            \n",
    "            # Occlusion sensitivity overlay\n",
    "            axes[1,0].imshow(img1_np)\n",
    "            axes[1,0].imshow(occlusion_map, cmap='hot', alpha=0.6)\n",
    "            axes[1,0].set_title(f'Occlusion Sensitivity on Image 1\\n(Similarity: {baseline_similarity:.3f})')\n",
    "            axes[1,0].axis('off')\n",
    "            \n",
    "            # Pure occlusion map\n",
    "            im = axes[1,1].imshow(occlusion_map, cmap='hot')\n",
    "            axes[1,1].set_title('Occlusion Sensitivity Map')\n",
    "            axes[1,1].axis('off')\n",
    "            plt.colorbar(im, ax=axes[1,1])\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"    ✅ Saved similarity occlusion test to {save_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ Error in similarity occlusion test for pair {pair_idx}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(f\"Completed occlusion sensitivity test for epoch {epoch}\")\n",
    "    model.train()\n",
    "    bsl_loss.train()\n",
    "\n",
    "# Test occlusion sensitivity function\n",
    "print(\"Testing occlusion sensitivity function...\")\n",
    "\n",
    "test_occlusion_dir = Path(\"data/test_occlusion\")\n",
    "test_occlusion_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_occlusion_sensitivity_test(\n",
    "    model, bsl_loss, tiny_test_dataset, device, epoch=-1, save_dir=test_occlusion_dir\n",
    ")\n",
    "\n",
    "print(\"✅ Occlusion sensitivity test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up full training configuration with verification\n",
    "def setup_full_training():\n",
    "    print(\"Setting up full training configuration...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "    print(\"✅ Seed set for reproducibility\")\n",
    "    \n",
    "    # Model\n",
    "    num_classes = len(train_dataset.label_to_idx)\n",
    "    model = MegaDescriptorWithBSL(num_classes).to(device)\n",
    "    print(f\"✅ Model created with {model.embedding_size} embedding size for {num_classes} classes\")\n",
    "    \n",
    "    # Loss function with ArcFace + Background suppression\n",
    "    bsl_loss = BackgroundSuppressionArcFaceLoss(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=model.embedding_size,\n",
    "        margin=0.5,\n",
    "        scale=64,\n",
    "        alpha=1.0,    # ArcFace weight\n",
    "        beta=0.5      # Background suppression weight\n",
    "    ).to(device)\n",
    "    print(f\"✅ BSL loss created (alpha={1.0}, beta={0.5})\")\n",
    "    \n",
    "    # Optimizer for both model and ArcFace parameters\n",
    "    params = itertools.chain(model.parameters(), bsl_loss.parameters())\n",
    "    optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=1e-4)\n",
    "    print(f\"✅ Optimizer created with lr=1e-4\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "    print(\"✅ Cosine annealing scheduler created\")\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=16, \n",
    "        shuffle=True, \n",
    "        num_workers=2,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=16, \n",
    "        shuffle=False, \n",
    "        num_workers=2,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "    print(f\"✅ Data loaders created: {len(train_loader)} train batches, {len(test_loader)} test batches\")\n",
    "    \n",
    "    # Create directories for saving\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    occlusion_dir = Path(\"data/occlusion_maps\")\n",
    "    occlusion_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✅ Directories created: data/, {occlusion_dir}\")\n",
    "    \n",
    "    # Test one forward pass with real data\n",
    "    print(\"Testing forward pass with real data...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            images, labels, masks = batch\n",
    "            images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "            \n",
    "            embeddings = model(images)\n",
    "            patch_features = model.get_patch_features()\n",
    "            loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n",
    "            \n",
    "            print(f\"✅ Forward pass successful:\")\n",
    "            print(f\"   Batch shape: {images.shape}\")\n",
    "            print(f\"   Embeddings: {embeddings.shape}\")\n",
    "            print(f\"   Patch features: {patch_features.shape if patch_features is not None else None}\")\n",
    "            print(f\"   Losses: total={loss.item():.4f}, arcface={arcface_loss.item():.4f}, bg={bg_loss.item():.4f}\")\n",
    "            break\n",
    "    \n",
    "    return model, bsl_loss, optimizer, scheduler, train_loader, test_loader, device, occlusion_dir\n",
    "\n",
    "# Setup training with verification\n",
    "model, bsl_loss, optimizer, scheduler, train_loader, test_loader, device, occlusion_dir = setup_full_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767d7e5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test one complete epoch to verify everything works\n",
    "print(\"=\" * 60)\n",
    "print(\"TESTING ONE COMPLETE EPOCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize best accuracy for testing\n",
    "best_acc = 0\n",
    "\n",
    "# Create a subset for testing\n",
    "test_train_dataset = NewtDataset(df_train.head(64), dataset_path, transform=transform_train, return_mask=True)\n",
    "test_train_loader = DataLoader(test_train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "test_test_dataset = NewtDataset(df_test.head(32), dataset_path, transform=transform_test, return_mask=True)\n",
    "test_test_loader = DataLoader(test_test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Running test training epoch...\")\n",
    "train_loss, arcface_loss, bg_loss, train_acc = train_epoch(\n",
    "    model, test_train_loader, bsl_loss, optimizer, device, epoch=0\n",
    ")\n",
    "\n",
    "print(\"Running test evaluation...\")\n",
    "test_acc = evaluate(model, test_test_loader, bsl_loss, device)\n",
    "\n",
    "print(\"Testing scheduler step...\")\n",
    "old_lr = optimizer.param_groups[0]['lr']\n",
    "scheduler.step()\n",
    "new_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "print(f\"✅ Complete epoch test passed!\")\n",
    "print(f\"   Train Loss: {train_loss:.4f} (ArcFace: {arcface_loss:.4f}, BG: {bg_loss:.4f})\")\n",
    "print(f\"   Train Acc:  {train_acc:.2f}%\")\n",
    "print(f\"   Test Acc:   {test_acc:.2f}% {'🌟 BEST!' if test_acc > best_acc else ''}\")\n",
    "print(f\"   Best Acc:   {best_acc:.2f}%\")\n",
    "print(f\"   LR:         {old_lr:.2e} → {new_lr:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44879469",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test training visualization with actual results\n",
    "def test_training_visualization_with_actual_results(train_loss, arcface_loss, bg_loss, train_acc, test_acc, lr):\n",
    "    print(\"Testing training visualization with actual results...\")\n",
    "    \n",
    "    # Use actual training results\n",
    "    epochs = [0]  # Just one epoch for testing\n",
    "    train_losses = [train_loss]\n",
    "    arcface_losses = [arcface_loss]\n",
    "    bg_losses = [bg_loss]\n",
    "    train_accs = [train_acc]\n",
    "    test_accs = [test_acc]\n",
    "    lrs = [lr]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0,0].plot(epochs, train_losses, label='Total Loss', marker='o', markersize=8)\n",
    "    axes[0,0].plot(epochs, arcface_losses, label='ArcFace Loss', marker='s', markersize=8)\n",
    "    axes[0,0].plot(epochs, bg_losses, label='Background Loss', marker='^', markersize=8)\n",
    "    axes[0,0].set_title('Training Losses (Actual Results)')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True)\n",
    "    axes[0,0].set_xlabel('Epoch')\n",
    "    axes[0,0].set_ylabel('Loss')\n",
    "    axes[0,0].set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    axes[0,1].plot(epochs, train_accs, label='Train Acc', marker='o', markersize=8)\n",
    "    axes[0,1].plot(epochs, test_accs, label='Test Acc', marker='s', markersize=8)\n",
    "    axes[0,1].set_title('Accuracy (Actual Results)')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True)\n",
    "    axes[0,1].set_xlabel('Epoch')\n",
    "    axes[0,1].set_ylabel('Accuracy (%)')\n",
    "    axes[0,1].set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # Loss breakdown\n",
    "    axes[1,0].plot(epochs, arcface_losses, label='ArcFace', marker='o', markersize=8)\n",
    "    axes[1,0].plot(epochs, bg_losses, label='Background Suppression', marker='s', markersize=8)\n",
    "    axes[1,0].set_title('Loss Components (Actual Results)')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True)\n",
    "    axes[1,0].set_xlabel('Epoch')\n",
    "    axes[1,0].set_ylabel('Loss')\n",
    "    axes[1,0].set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # Learning rate\n",
    "    axes[1,1].plot(epochs, lrs, marker='o', markersize=8)\n",
    "    axes[1,1].set_title('Learning Rate (Actual)')\n",
    "    axes[1,1].grid(True)\n",
    "    axes[1,1].set_xlabel('Epoch')\n",
    "    axes[1,1].set_ylabel('Learning Rate')\n",
    "    axes[1,1].set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # Add actual values as text - fix the max() calls\n",
    "    max_loss = max(train_loss, arcface_loss, bg_loss)  # Compare actual values, not lists\n",
    "    max_acc = max(train_acc, test_acc)  # Compare actual values, not lists\n",
    "    \n",
    "    axes[0,0].text(0, max_loss, f'Total: {train_loss:.4f}\\nArcFace: {arcface_loss:.4f}\\nBG: {bg_loss:.4f}', \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    axes[0,1].text(0, max_acc, f'Train: {train_acc:.2f}%\\nTest: {test_acc:.2f}%', \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/actual_training_test_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Training visualization with actual results completed!\")\n",
    "    print(f\"   Results saved to: data/actual_training_test_results.png\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f} (ArcFace: {arcface_loss:.4f}, BG: {bg_loss:.4f})\")\n",
    "    print(f\"   Accuracies: Train {train_acc:.2f}%, Test {test_acc:.2f}%\")\n",
    "    print(f\"   Learning Rate: {lr:.2e}\")\n",
    "\n",
    "# Test with actual results from the training epoch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING VISUALIZATION WITH ACTUAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_training_visualization_with_actual_results(\n",
    "    train_loss=train_loss,\n",
    "    arcface_loss=arcface_loss, \n",
    "    bg_loss=bg_loss,\n",
    "    train_acc=train_acc,\n",
    "    test_acc=test_acc,\n",
    "    lr=new_lr  # Use the learning rate after scheduler step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training function with comprehensive testing\n",
    "def train_newt_reid_with_bsl():\n",
    "    print(\"🚀 STARTING COMPREHENSIVE TRAINING\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    num_epochs = 5\n",
    "    best_acc = 0\n",
    "    train_history = []\n",
    "    \n",
    "    # Initial sanity check\n",
    "    print(\"Performing initial sanity checks...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            images, labels, masks = batch\n",
    "            images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "            embeddings = model(images)\n",
    "            patch_features = model.get_patch_features()\n",
    "            loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n",
    "            print(f\"✅ Initial forward pass: Loss={loss.item():.4f}\")\n",
    "            break\n",
    "    \n",
    "    print(\"Starting training loop...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'='*20} EPOCH {epoch+1}/{num_epochs} {'='*20}\")\n",
    "        \n",
    "        # Training\n",
    "        print(\"Training...\")\n",
    "        train_loss, arcface_loss, bg_loss, train_acc = train_epoch(\n",
    "            model, train_loader, bsl_loss, optimizer, device, epoch\n",
    "        )\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"Evaluating...\")\n",
    "        test_acc = evaluate(model, test_loader, bsl_loss, device)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save training history\n",
    "        epoch_data = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'arcface_loss': arcface_loss,\n",
    "            'bg_loss': bg_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'lr': current_lr\n",
    "        }\n",
    "        train_history.append(epoch_data)\n",
    "        \n",
    "        # Occlusion sensitivity testing every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Running occlusion sensitivity test...\")\n",
    "            run_occlusion_sensitivity_test(model, bsl_loss, test_dataset, device, epoch, occlusion_dir)\n",
    "        \n",
    "        # Save best model\n",
    "        is_best = test_acc > best_acc\n",
    "        if is_best:\n",
    "            best_acc = test_acc\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'loss_state_dict': bsl_loss.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_acc': best_acc,\n",
    "                'embedding_size': model.embedding_size,\n",
    "                'num_classes': len(train_dataset.label_to_idx),\n",
    "                'train_history': train_history\n",
    "            }\n",
    "            torch.save(checkpoint, 'data/best_newt_reid_bsl_model.pth')\n",
    "            print(f\"💾 NEW BEST MODEL SAVED! Accuracy: {best_acc:.2f}%\")\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\n📊 EPOCH {epoch} SUMMARY:\")\n",
    "        print(f\"   Train Loss: {train_loss:.4f} (ArcFace: {arcface_loss:.4f}, BG: {bg_loss:.4f})\")\n",
    "        print(f\"   Train Acc:  {train_acc:.2f}%\")\n",
    "        print(f\"   Test Acc:   {test_acc:.2f}% {'🌟 BEST!' if is_best else ''}\")\n",
    "        print(f\"   Best Acc:   {best_acc:.2f}%\")\n",
    "        print(f\"   LR:         {old_lr:.2e} → {current_lr:.2e}\")\n",
    "        \n",
    "        # Visualization every 5 epochs\n",
    "        if epoch > 0 and epoch % 5 == 0:\n",
    "            print(\"Creating training visualizations...\")\n",
    "            \n",
    "            epochs = [h['epoch'] for h in train_history]\n",
    "            train_losses = [h['train_loss'] for h in train_history]\n",
    "            arcface_losses = [h['arcface_loss'] for h in train_history]\n",
    "            bg_losses = [h['bg_loss'] for h in train_history]\n",
    "            train_accs = [h['train_acc'] for h in train_history]\n",
    "            test_accs = [h['test_acc'] for h in train_history]\n",
    "            lrs = [h['lr'] for h in train_history]\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "            \n",
    "            # Loss curves\n",
    "            axes[0,0].plot(epochs, train_losses, label='Total Loss', marker='o')\n",
    "            axes[0,0].plot(epochs, arcface_losses, label='ArcFace Loss', marker='s')\n",
    "            axes[0,0].plot(epochs, bg_losses, label='Background Loss', marker='^')\n",
    "            axes[0,0].set_title('Training Losses')\n",
    "            axes[0,0].legend()\n",
    "            axes[0,0].grid(True)\n",
    "            \n",
    "            # Accuracy curves\n",
    "            axes[0,1].plot(epochs, train_accs, label='Train Acc', marker='o')\n",
    "            axes[0,1].plot(epochs, test_accs, label='Test Acc', marker='s')\n",
    "            axes[0,1].set_title('Accuracy')\n",
    "            axes[0,1].legend()\n",
    "            axes[0,1].grid(True)\n",
    "            \n",
    "            # Loss breakdown\n",
    "            axes[1,0].plot(epochs, arcface_losses, label='ArcFace', marker='o')\n",
    "            axes[1,0].plot(epochs, bg_losses, label='Background Suppression', marker='s')\n",
    "            axes[1,0].set_title('Loss Components')\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True)\n",
    "            \n",
    "            # Learning rate\n",
    "            axes[1,1].plot(epochs, lrs, marker='o')\n",
    "            axes[1,1].set_title('Learning Rate')\n",
    "            axes[1,1].set_yscale('log')\n",
    "            axes[1,1].grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'data/training_progress_epoch_{epoch}.png', dpi=150, bbox_inches='tight')\n",
    "            plt.show()\n",
    "    \n",
    "    print(f\"\\n🎉 TRAINING COMPLETED!\")\n",
    "    print(f\"📈 Best test accuracy: {best_acc:.2f}%\")\n",
    "    print(f\"💾 Model saved to: data/best_newt_reid_bsl_model.pth\")\n",
    "    print(f\"🔍 Occlusion maps saved to: {occlusion_dir}\")\n",
    "    \n",
    "    return model, bsl_loss, train_history\n",
    "\n",
    "print(\"✅ All tests passed! Ready to start main training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2466a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final pre-training verification\n",
    "print(\"FINAL PRE-TRAINING VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check GPU memory if available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"GPU Memory Free: {torch.cuda.memory_reserved(0) / 1e9:.1f} GB\")\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {len(train_dataset.label_to_idx)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")\n",
    "\n",
    "# Final forward pass test\n",
    "print(\"Final forward pass test...\")\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(train_loader))\n",
    "    images, labels, masks = test_batch\n",
    "    images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "    \n",
    "    embeddings = model(images)\n",
    "    patch_features = model.get_patch_features()\n",
    "    loss, arcface_loss, bg_loss = bsl_loss(embeddings, labels, masks, patch_features)\n",
    "    \n",
    "    print(f\"✅ Final test successful!\")\n",
    "    print(f\"   Batch size: {images.shape[0]}\")\n",
    "    print(f\"   Total loss: {loss.item():.4f}\")\n",
    "    print(f\"   Memory usage: {torch.cuda.memory_allocated(0) / 1e6:.1f} MB\" if torch.cuda.is_available() else \"CPU mode\")\n",
    "\n",
    "print(\"\\n🚀 READY TO START TRAINING!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the actual training!\n",
    "trained_model, trained_bsl_loss, history = train_newt_reid_with_bsl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0fec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
